{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "2903c6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "#tf.config.optimizer.set_jit(False)\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "import random\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "#import matplotlib\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from keras.constraints import Constraint\n",
    "from keras.layers import Layer\n",
    "from keras import backend as K\n",
    "\n",
    "import jax\n",
    "import jax.nn as nn\n",
    "from jax.random import normal\n",
    "from jax.experimental import sparse\n",
    "#from sparse import bcoo_concatenate\n",
    "from jax.tree_util import tree_map\n",
    "import jaxlib\n",
    "import jax.numpy as jnp\n",
    "import haiku as hk\n",
    "import optax\n",
    "from jax import jit\n",
    "from functools import partial\n",
    "import functools\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from optax import GradientTransformation\n",
    "\n",
    "from utils import constrained_gradients, StateProbBound, StateProbFolded, Between, between\n",
    "from linear import custom_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "4ab67728",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9e754c",
   "metadata": {},
   "source": [
    "# Define arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "6ae91fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = '/Users/pierredemetz/UCL_work/Crick/doubledeepms/Results//Data/mochi/GRB2-SH3/mochi__fit_tmodel_3state_sparse_dimsum128_subsample100p//dataset_train.txt'\n",
    "data_valid = '/Users/pierredemetz/UCL_work/Crick/doubledeepms/Results//Data/mochi/GRB2-SH3/mochi__fit_tmodel_3state_sparse_dimsum128_subsample100p//dataset_valid.txt' \n",
    "data_obs = '/Users/pierredemetz/UCL_work/Crick/doubledeepms/Results//Data/mochi/GRB2-SH3/mochi__fit_tmodel_3state_sparse_dimsum128_subsample100p//dataset_all.txt' \n",
    "o = '/Users/pierredemetz/UCL_work/Crick/doubledeepms/Results//Data/mochi/GRB2-SH3/mochi__fit_tmodel_3state_sparse_dimsum128_subsample100p/ '\n",
    "e = 100 \n",
    "l1_regularization_factor = 0 \n",
    "l2_regularization_factor = 0 \n",
    "p = 1000 \n",
    "num_samples= 128,256,512,1024 \n",
    "learning_rate= 0.001 \n",
    "num_resamplings= 10 \n",
    "num_models= 1 \n",
    "random_seed= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "168c27ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"data_train\": \"'/Users/pierredemetz/UCL_work/Crick/doubledeepms/Results//Data/mochi/GRB2-SH3/mochi__fit_tmodel_3state_sparse_dimsum128_subsample100p//dataset_train.txt'\",\n",
    "    \"data_valid\": \"/Users/pierredemetz/UCL_work/Crick/doubledeepms/Results//Data/mochi/GRB2-SH3/mochi__fit_tmodel_3state_sparse_dimsum128_subsample100p//dataset_valid.txt\",\n",
    "    \"data_obs\": \"/Users/pierredemetz/UCL_work/Crick/doubledeepms/Results//Data/mochi/GRB2-SH3/mochi__fit_tmodel_3state_sparse_dimsum128_subsample100p//dataset_all.txt\",\n",
    "    \"output_directory\": \"/Users/pierredemetz/UCL_work/Crick/doubledeepms/Results//Data/mochi/GRB2-SH3/mochi__fit_tmodel_3state_sparse_dimsum128_subsample100p/\",\n",
    "    \"number_additive_traits\": 1,\n",
    "    \"l1_regularization_factor\": \"0.0001,0.001,0.01,0.1\",\n",
    "    \"l2_regularization_factor\": \"0.0001,0.001,0.01,0.1\",\n",
    "    \"num_epochs_grid\": 10,\n",
    "    \"num_epochs\": 10,\n",
    "    \"num_samples\": \"128,256,512,1024\",\n",
    "    \"learning_rate\": \"0.0001,0.001,0.01,0.1\",\n",
    "    \"num_resamplings\": 10,\n",
    "    \"early_stopping\": False,\n",
    "    \"num_models\": 2,\n",
    "    \"random_seed\": 1\n",
    "}\n",
    "\n",
    "data_train_file = args[\"data_train\"]\n",
    "data_valid_file = args[\"data_valid\"]\n",
    "data_obs_file = args[\"data_obs\"]\n",
    "output_directory = args[\"output_directory\"]\n",
    "number_additive_traits = args[\"number_additive_traits\"]\n",
    "num_epochs_grid = args[\"num_epochs_grid\"]\n",
    "num_epochs = args[\"num_epochs\"]\n",
    "num_resamplings = args[\"num_resamplings\"]\n",
    "early_stopping = args[\"early_stopping\"]\n",
    "num_models = args[\"num_models\"]\n",
    "random_seed = args[\"random_seed\"]\n",
    "\n",
    "#Grid search arguments\n",
    "l1 = [float(i) for i in args[\"l1_regularization_factor\"].split(\",\")]\n",
    "l2 = [float(i) for i in args[\"l2_regularization_factor\"].split(\",\")]\n",
    "batch_size = [int(i) for i in args[\"num_samples\"].split(\",\")]\n",
    "learn_rate = [float(i) for i in args[\"learning_rate\"].split(\",\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c015a351",
   "metadata": {},
   "source": [
    "# Load model data jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "5d051fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_data_jax(file_dict):\n",
    "    data_dict = {}\n",
    "    for name in file_dict.keys():\n",
    "        # Initialize\n",
    "        data_dict[name] = {}\n",
    "\n",
    "        # Read the entire file once\n",
    "        df = pd.read_csv(file_dict[name])\n",
    "\n",
    "        # Column names\n",
    "        ALL_COLUMNS = list(df.columns)\n",
    "        SELECT_COLUMNS = [col for col in ALL_COLUMNS if col.startswith(\"dataset_\")]\n",
    "        FOLD_COLUMNS = [col for col in ALL_COLUMNS if col.startswith(\"fold_\") or col == \"WT\"]\n",
    "        BIND_COLUMNS = [col for col in ALL_COLUMNS if col.startswith(\"bind_\") or col == \"WT\"]\n",
    "        TARGET_COLUMN = \"fitness\"\n",
    "        TARGET_SD_COLUMN = \"fitness_sd\"\n",
    "        SEQUENCE_COLUMN = \"variant_sequence\"\n",
    "        TRAINING_SET_COLUMN = \"training_set\"\n",
    "\n",
    "        # Save (sparse) tensors\n",
    "        data_dict[name][\"select\"] = jnp.array(df[SELECT_COLUMNS], dtype=jnp.float32)\n",
    "        data_dict[name][\"fold\"] = jnp.array(df[FOLD_COLUMNS], dtype=jnp.float32)\n",
    "        data_dict[name][\"bind\"] = jnp.array(df[BIND_COLUMNS], dtype=jnp.float32)\n",
    "        data_dict[name][\"target\"] = jnp.array(df[TARGET_COLUMN], dtype=jnp.float32)\n",
    "        data_dict[name][\"target_sd\"] = jnp.array(df[TARGET_SD_COLUMN], dtype=jnp.float32)\n",
    "\n",
    "        # Save remaining columns\n",
    "        if SEQUENCE_COLUMN in df.columns:\n",
    "            data_dict[name][\"sequence\"] = np.array(df[SEQUENCE_COLUMN].values)\n",
    "        if TRAINING_SET_COLUMN in df.columns:\n",
    "            data_dict[name][\"training_set\"] = jnp.expand_dims(jnp.array(df[TRAINING_SET_COLUMN].values), axis=-1)\n",
    "\n",
    "        data_dict[name][\"fold_colnames\"] = np.array([col.replace(\"fold_\", \"\") for col in FOLD_COLUMNS])\n",
    "        data_dict[name][\"bind_colnames\"] = np.array([col.replace(\"bind_\", \"\") for col in BIND_COLUMNS])\n",
    "\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "fe45ce8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_file = '/Users/pierredemetz/UCL_work/Crick/doubledeepms/Results//Data/mochi/GRB2-SH3/mochi__fit_tmodel_3state_sparse_dimsum128_subsample100p//dataset_train.txt'\n",
    "\n",
    "data_valid_file = '/Users/pierredemetz/UCL_work/Crick/doubledeepms/Results//Data/mochi/GRB2-SH3/mochi__fit_tmodel_3state_sparse_dimsum128_subsample100p//dataset_valid.txt' \n",
    "\n",
    "data_obs_file = '/Users/pierredemetz/UCL_work/Crick/doubledeepms/Results//Data/mochi/GRB2-SH3/mochi__fit_tmodel_3state_sparse_dimsum128_subsample100p//dataset_all.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "7d92613e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the rng\n",
    "random_seed = 42\n",
    "rng = jax.random.PRNGKey(random_seed)\n",
    "\n",
    "#Load model data\n",
    "model_data_jax = load_model_data_jax({\n",
    "    \"train\": data_train_file,\n",
    "    \"valid\": data_valid_file,\n",
    "    \"obs\": data_obs_file\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "9cd0e843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'select': DeviceArray([[0., 1.],\n",
       "              [0., 1.],\n",
       "              [1., 0.],\n",
       "              ...,\n",
       "              [1., 0.],\n",
       "              [1., 0.],\n",
       "              [0., 1.]], dtype=float32),\n",
       " 'fold': DeviceArray([[1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              ...,\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " 'bind': DeviceArray([[1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              ...,\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " 'target': DeviceArray([-0.33598602, -0.8518485 , -1.0957463 , ..., -0.26487023,\n",
       "              -1.166961  , -0.66433465], dtype=float32),\n",
       " 'target_sd': DeviceArray([0.11158013, 0.17281719, 0.09720125, ..., 0.22753495,\n",
       "              0.36643863, 0.15336636], dtype=float32),\n",
       " 'sequence': array(['0000000000000000000000000000000000000000000000000L000000',\n",
       "        '00000000I0000000000000000000000000000000Q000000000000000',\n",
       "        '000000000000000000000000000000000000000V000000W000000000', ...,\n",
       "        '000000000M0000000000000000000000000000000000000000000S00',\n",
       "        '000000000000000000K0000000000000000T00000000000000000000',\n",
       "        '000000000N0000000000000000000000000000000000S00000000000'],\n",
       "       dtype=object),\n",
       " 'training_set': DeviceArray([[1],\n",
       "              [1],\n",
       "              [1],\n",
       "              ...,\n",
       "              [1],\n",
       "              [1],\n",
       "              [1]], dtype=int32),\n",
       " 'fold_colnames': array(['WT', 'T1A', 'T1C', ..., 'N56V', 'N56W', 'N56Y'], dtype='<U4'),\n",
       " 'bind_colnames': array(['WT', 'T1A', 'T1E', 'T1G', 'T1I', 'T1K', 'T1L', 'T1M', 'T1N',\n",
       "        'T1P', 'T1R', 'T1S', 'T1V', 'Y2A', 'Y2C', 'Y2D', 'Y2F', 'Y2H',\n",
       "        'Y2I', 'Y2K', 'Y2L', 'Y2N', 'Y2Q', 'Y2R', 'Y2S', 'Y2T', 'Y2W',\n",
       "        'V3A', 'V3C', 'V3D', 'V3E', 'V3F', 'V3G', 'V3H', 'V3I', 'V3L',\n",
       "        'V3N', 'V3P', 'V3S', 'V3T', 'V3Y', 'Q4E', 'Q4G', 'Q4H', 'Q4K',\n",
       "        'Q4L', 'Q4M', 'Q4N', 'Q4P', 'Q4R', 'Q4S', 'Q4T', 'Q4V', 'Q4W',\n",
       "        'Q4Y', 'A5D', 'A5E', 'A5G', 'A5I', 'A5N', 'A5P', 'A5S', 'A5T',\n",
       "        'A5V', 'A5Y', 'L6C', 'L6F', 'L6H', 'L6I', 'L6N', 'L6P', 'L6Q',\n",
       "        'L6R', 'L6S', 'L6V', 'L6Y', 'F7A', 'F7C', 'F7H', 'F7I', 'F7L',\n",
       "        'F7M', 'F7N', 'F7P', 'F7S', 'F7T', 'F7V', 'F7Y', 'D8A', 'D8C',\n",
       "        'D8E', 'D8F', 'D8G', 'D8H', 'D8I', 'D8K', 'D8N', 'D8Q', 'D8R',\n",
       "        'D8S', 'D8T', 'D8V', 'D8Y', 'F9A', 'F9C', 'F9H', 'F9I', 'F9L',\n",
       "        'F9M', 'F9N', 'F9P', 'F9S', 'F9T', 'F9V', 'F9Y', 'D10A', 'D10C',\n",
       "        'D10E', 'D10F', 'D10G', 'D10H', 'D10I', 'D10K', 'D10L', 'D10N',\n",
       "        'D10S', 'D10T', 'D10V', 'D10Y', 'P11A', 'P11D', 'P11F', 'P11H',\n",
       "        'P11I', 'P11L', 'P11N', 'P11Q', 'P11R', 'P11S', 'P11T', 'P11Y',\n",
       "        'Q12A', 'Q12D', 'Q12E', 'Q12G', 'Q12H', 'Q12K', 'Q12L', 'Q12M',\n",
       "        'Q12N', 'Q12P', 'Q12R', 'Q12T', 'Q12V', 'Q12W', 'Q12Y', 'E13A',\n",
       "        'E13D', 'E13G', 'E13K', 'E13L', 'E13M', 'E13N', 'E13Q', 'E13R',\n",
       "        'E13V', 'E13Y', 'D14A', 'D14C', 'D14E', 'D14F', 'D14G', 'D14H',\n",
       "        'D14I', 'D14K', 'D14L', 'D14N', 'D14Q', 'D14R', 'D14S', 'D14V',\n",
       "        'D14Y', 'G15A', 'G15C', 'G15D', 'G15E', 'G15I', 'G15K', 'G15L',\n",
       "        'G15Q', 'G15R', 'G15S', 'G15V', 'G15W', 'E16A', 'E16D', 'E16G',\n",
       "        'E16K', 'E16L', 'E16M', 'E16N', 'E16Q', 'E16R', 'E16V', 'E16W',\n",
       "        'E16Y', 'L17A', 'L17H', 'L17I', 'L17K', 'L17M', 'L17P', 'L17Q',\n",
       "        'L17R', 'L17S', 'L17T', 'L17V', 'L17W', 'G18A', 'G18C', 'G18D',\n",
       "        'G18E', 'G18F', 'G18H', 'G18I', 'G18N', 'G18R', 'G18S', 'G18T',\n",
       "        'G18V', 'G18W', 'G18Y', 'F19C', 'F19H', 'F19I', 'F19L', 'F19M',\n",
       "        'F19N', 'F19P', 'F19R', 'F19S', 'F19T', 'F19V', 'F19Y', 'R20A',\n",
       "        'R20C', 'R20D', 'R20F', 'R20G', 'R20H', 'R20I', 'R20L', 'R20N',\n",
       "        'R20P', 'R20Q', 'R20S', 'R20T', 'R20W', 'R20Y', 'R21A', 'R21C',\n",
       "        'R21E', 'R21G', 'R21H', 'R21I', 'R21K', 'R21L', 'R21M', 'R21P',\n",
       "        'R21Q', 'R21S', 'R21T', 'R21V', 'R21W', 'G22A', 'G22C', 'G22D',\n",
       "        'G22E', 'G22I', 'G22K', 'G22L', 'G22Q', 'G22R', 'G22S', 'G22V',\n",
       "        'G22W', 'D23A', 'D23C', 'D23E', 'D23F', 'D23G', 'D23H', 'D23I',\n",
       "        'D23K', 'D23L', 'D23N', 'D23S', 'D23V', 'D23Y', 'F24A', 'F24C',\n",
       "        'F24D', 'F24G', 'F24H', 'F24I', 'F24L', 'F24M', 'F24N', 'F24P',\n",
       "        'F24R', 'F24S', 'F24T', 'F24V', 'F24W', 'F24Y', 'I25A', 'I25D',\n",
       "        'I25F', 'I25H', 'I25K', 'I25L', 'I25M', 'I25N', 'I25P', 'I25R',\n",
       "        'I25S', 'I25T', 'I25V', 'I25Y', 'H26A', 'H26C', 'H26D', 'H26E',\n",
       "        'H26F', 'H26G', 'H26I', 'H26K', 'H26L', 'H26N', 'H26P', 'H26Q',\n",
       "        'H26R', 'H26S', 'H26T', 'H26V', 'H26Y', 'V27A', 'V27C', 'V27D',\n",
       "        'V27E', 'V27F', 'V27G', 'V27H', 'V27I', 'V27L', 'V27M', 'V27N',\n",
       "        'V27S', 'V27T', 'V27Y', 'M28A', 'M28E', 'M28F', 'M28G', 'M28I',\n",
       "        'M28K', 'M28L', 'M28N', 'M28P', 'M28Q', 'M28R', 'M28S', 'M28T',\n",
       "        'M28V', 'M28W', 'M28Y', 'D29A', 'D29C', 'D29E', 'D29F', 'D29G',\n",
       "        'D29H', 'D29I', 'D29K', 'D29L', 'D29N', 'D29P', 'D29S', 'D29V',\n",
       "        'D29Y', 'N30A', 'N30C', 'N30D', 'N30E', 'N30F', 'N30G', 'N30H',\n",
       "        'N30I', 'N30K', 'N30M', 'N30R', 'N30S', 'N30T', 'N30V', 'N30Y',\n",
       "        'S31A', 'S31E', 'S31F', 'S31I', 'S31K', 'S31L', 'S31P', 'S31Q',\n",
       "        'S31R', 'S31T', 'S31V', 'S31W', 'S31Y', 'D32A', 'D32C', 'D32E',\n",
       "        'D32F', 'D32G', 'D32H', 'D32I', 'D32K', 'D32N', 'D32S', 'D32T',\n",
       "        'D32V', 'D32Y', 'P33A', 'P33C', 'P33D', 'P33F', 'P33G', 'P33H',\n",
       "        'P33I', 'P33K', 'P33L', 'P33N', 'P33Q', 'P33R', 'P33S', 'P33T',\n",
       "        'P33V', 'P33Y', 'N34A', 'N34C', 'N34D', 'N34E', 'N34F', 'N34G',\n",
       "        'N34H', 'N34I', 'N34K', 'N34L', 'N34Q', 'N34R', 'N34S', 'N34T',\n",
       "        'N34V', 'N34Y', 'W35A', 'W35C', 'W35E', 'W35F', 'W35G', 'W35K',\n",
       "        'W35L', 'W35M', 'W35Q', 'W35R', 'W35S', 'W35T', 'W35V', 'W35Y',\n",
       "        'W36C', 'W36F', 'W36G', 'W36K', 'W36L', 'W36M', 'W36Q', 'W36R',\n",
       "        'W36S', 'W36T', 'W36V', 'W36Y', 'K37D', 'K37E', 'K37G', 'K37I',\n",
       "        'K37L', 'K37M', 'K37N', 'K37Q', 'K37R', 'K37S', 'K37T', 'K37V',\n",
       "        'K37Y', 'G38A', 'G38C', 'G38D', 'G38E', 'G38I', 'G38K', 'G38L',\n",
       "        'G38Q', 'G38R', 'G38S', 'G38T', 'G38V', 'G38W', 'A39C', 'A39D',\n",
       "        'A39E', 'A39F', 'A39G', 'A39I', 'A39N', 'A39P', 'A39S', 'A39T',\n",
       "        'A39V', 'A39Y', 'C40F', 'C40G', 'C40H', 'C40I', 'C40L', 'C40N',\n",
       "        'C40R', 'C40S', 'C40W', 'C40Y', 'H41C', 'H41D', 'H41E', 'H41F',\n",
       "        'H41G', 'H41I', 'H41K', 'H41L', 'H41N', 'H41P', 'H41Q', 'H41R',\n",
       "        'H41S', 'H41T', 'H41V', 'H41Y', 'G42A', 'G42C', 'G42D', 'G42E',\n",
       "        'G42F', 'G42K', 'G42L', 'G42M', 'G42Q', 'G42R', 'G42S', 'G42T',\n",
       "        'G42V', 'G42W', 'Q43D', 'Q43E', 'Q43H', 'Q43K', 'Q43L', 'Q43M',\n",
       "        'Q43N', 'Q43P', 'Q43R', 'Q43V', 'Q43W', 'Q43Y', 'T44A', 'T44C',\n",
       "        'T44D', 'T44F', 'T44G', 'T44I', 'T44K', 'T44M', 'T44N', 'T44P',\n",
       "        'T44R', 'T44S', 'T44V', 'T44Y', 'G45A', 'G45C', 'G45D', 'G45E',\n",
       "        'G45F', 'G45H', 'G45I', 'G45L', 'G45N', 'G45P', 'G45R', 'G45S',\n",
       "        'G45T', 'G45V', 'G45W', 'G45Y', 'M46A', 'M46E', 'M46F', 'M46I',\n",
       "        'M46K', 'M46L', 'M46N', 'M46R', 'M46S', 'M46T', 'M46V', 'M46W',\n",
       "        'F47C', 'F47D', 'F47H', 'F47I', 'F47L', 'F47N', 'F47P', 'F47S',\n",
       "        'F47T', 'F47V', 'F47Y', 'P48A', 'P48F', 'P48H', 'P48I', 'P48L',\n",
       "        'P48N', 'P48Q', 'P48R', 'P48S', 'P48T', 'P48Y', 'R49A', 'R49C',\n",
       "        'R49D', 'R49F', 'R49G', 'R49H', 'R49I', 'R49L', 'R49N', 'R49P',\n",
       "        'R49Q', 'R49S', 'R49T', 'R49W', 'R49Y', 'N50C', 'N50D', 'N50E',\n",
       "        'N50F', 'N50G', 'N50H', 'N50I', 'N50K', 'N50L', 'N50M', 'N50Q',\n",
       "        'N50R', 'N50S', 'N50T', 'N50V', 'N50Y', 'Y51C', 'Y51D', 'Y51F',\n",
       "        'Y51H', 'Y51I', 'Y51K', 'Y51L', 'Y51N', 'Y51Q', 'Y51R', 'Y51S',\n",
       "        'Y51T', 'Y51V', 'Y51W', 'V52A', 'V52C', 'V52D', 'V52E', 'V52F',\n",
       "        'V52G', 'V52I', 'V52L', 'V52M', 'V52N', 'V52P', 'V52S', 'V52T',\n",
       "        'V52Y', 'T53A', 'T53D', 'T53F', 'T53G', 'T53I', 'T53K', 'T53M',\n",
       "        'T53N', 'T53P', 'T53R', 'T53S', 'T53V', 'T53Y', 'P54A', 'P54D',\n",
       "        'P54F', 'P54H', 'P54I', 'P54L', 'P54N', 'P54Q', 'P54R', 'P54S',\n",
       "        'P54T', 'P54V', 'P54Y', 'V55A', 'V55D', 'V55E', 'V55F', 'V55G',\n",
       "        'V55I', 'V55K', 'V55L', 'V55M', 'V55P', 'V55Q', 'V55R', 'V55S',\n",
       "        'V55T', 'N56C', 'N56D', 'N56E', 'N56F', 'N56G', 'N56H', 'N56I',\n",
       "        'N56K', 'N56M', 'N56Q', 'N56R', 'N56S', 'N56T', 'N56V', 'N56Y'],\n",
       "       dtype='<U4')}"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data_jax['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc8ddd2",
   "metadata": {},
   "source": [
    "# Resample training data jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "376089a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_training_data_jax(tensor_dict, n_resamplings, rng):\n",
    "    # Resample observed fitness from error distribution\n",
    "\n",
    "    observed_fitness = tensor_dict[\"target\"]\n",
    "    observed_fitness_sd = tensor_dict[\"target_sd\"]\n",
    "\n",
    "    observed_fitness_resample = jnp.array(\n",
    "    [jnp.array(\n",
    "      [observed_fitness[i]+(observed_fitness_sd[i] * jax.random.normal(rng, shape=(1,))) for i in range(len(observed_fitness))])\n",
    "    for j in range(n_resamplings)]\n",
    "    )\n",
    "    print('here')\n",
    "    #Save new data\n",
    "\n",
    "    tensor_dict[\"target\"] = jax.device_put(jnp.expand_dims(observed_fitness_resample.ravel(), -1))\n",
    "\n",
    "    select_tensors = [tensor_dict[\"select\"] for i in range(n_resamplings)]  # Assuming n_resamplings is defined\n",
    "    tensor_dict[\"select\"] = jnp.concatenate(select_tensors, axis=0)\n",
    "\n",
    "    fold_matrices = [tensor_dict[\"fold\"] for i in range(n_resamplings)]\n",
    "    tensor_dict[\"fold\"] = jnp.concatenate(fold_matrices, axis=0)\n",
    "\n",
    "    bind_matrices = [tensor_dict[\"bind\"] for i in range(n_resamplings)]\n",
    "    tensor_dict[\"bind\"] = jnp.concatenate(bind_matrices, axis=0)\n",
    "\n",
    "    return tensor_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "a5febd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    }
   ],
   "source": [
    "#Resample training data\n",
    "num_resamplings = 1\n",
    "\n",
    "#create the rng\n",
    "random_seed = 42\n",
    "rng = jax.random.PRNGKey(random_seed)\n",
    "\n",
    "if num_resamplings!=0:\n",
    "    model_data_jax[\"train\"] = resample_training_data_jax(\n",
    "        tensor_dict = model_data_jax[\"train\"],\n",
    "        n_resamplings = num_resamplings,\n",
    "        rng = rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "f76c3e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'select': DeviceArray([[0., 1.],\n",
       "              [0., 1.],\n",
       "              [1., 0.],\n",
       "              ...,\n",
       "              [1., 0.],\n",
       "              [1., 0.],\n",
       "              [0., 1.]], dtype=float32),\n",
       " 'fold': DeviceArray([[1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              ...,\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " 'bind': DeviceArray([[1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              ...,\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " 'target': DeviceArray([[-0.35659617],\n",
       "              [-0.88376987],\n",
       "              [-1.1137005 ],\n",
       "              ...,\n",
       "              [-0.3068986 ],\n",
       "              [-1.2346464 ],\n",
       "              [-0.69266325]], dtype=float32),\n",
       " 'target_sd': DeviceArray([0.11158013, 0.17281719, 0.09720125, ..., 0.22753495,\n",
       "              0.36643863, 0.15336636], dtype=float32),\n",
       " 'sequence': array(['0000000000000000000000000000000000000000000000000L000000',\n",
       "        '00000000I0000000000000000000000000000000Q000000000000000',\n",
       "        '000000000000000000000000000000000000000V000000W000000000', ...,\n",
       "        '000000000M0000000000000000000000000000000000000000000S00',\n",
       "        '000000000000000000K0000000000000000T00000000000000000000',\n",
       "        '000000000N0000000000000000000000000000000000S00000000000'],\n",
       "       dtype=object),\n",
       " 'training_set': DeviceArray([[1],\n",
       "              [1],\n",
       "              [1],\n",
       "              ...,\n",
       "              [1],\n",
       "              [1],\n",
       "              [1]], dtype=int32),\n",
       " 'fold_colnames': array(['WT', 'T1A', 'T1C', ..., 'N56V', 'N56W', 'N56Y'], dtype='<U4'),\n",
       " 'bind_colnames': array(['WT', 'T1A', 'T1E', 'T1G', 'T1I', 'T1K', 'T1L', 'T1M', 'T1N',\n",
       "        'T1P', 'T1R', 'T1S', 'T1V', 'Y2A', 'Y2C', 'Y2D', 'Y2F', 'Y2H',\n",
       "        'Y2I', 'Y2K', 'Y2L', 'Y2N', 'Y2Q', 'Y2R', 'Y2S', 'Y2T', 'Y2W',\n",
       "        'V3A', 'V3C', 'V3D', 'V3E', 'V3F', 'V3G', 'V3H', 'V3I', 'V3L',\n",
       "        'V3N', 'V3P', 'V3S', 'V3T', 'V3Y', 'Q4E', 'Q4G', 'Q4H', 'Q4K',\n",
       "        'Q4L', 'Q4M', 'Q4N', 'Q4P', 'Q4R', 'Q4S', 'Q4T', 'Q4V', 'Q4W',\n",
       "        'Q4Y', 'A5D', 'A5E', 'A5G', 'A5I', 'A5N', 'A5P', 'A5S', 'A5T',\n",
       "        'A5V', 'A5Y', 'L6C', 'L6F', 'L6H', 'L6I', 'L6N', 'L6P', 'L6Q',\n",
       "        'L6R', 'L6S', 'L6V', 'L6Y', 'F7A', 'F7C', 'F7H', 'F7I', 'F7L',\n",
       "        'F7M', 'F7N', 'F7P', 'F7S', 'F7T', 'F7V', 'F7Y', 'D8A', 'D8C',\n",
       "        'D8E', 'D8F', 'D8G', 'D8H', 'D8I', 'D8K', 'D8N', 'D8Q', 'D8R',\n",
       "        'D8S', 'D8T', 'D8V', 'D8Y', 'F9A', 'F9C', 'F9H', 'F9I', 'F9L',\n",
       "        'F9M', 'F9N', 'F9P', 'F9S', 'F9T', 'F9V', 'F9Y', 'D10A', 'D10C',\n",
       "        'D10E', 'D10F', 'D10G', 'D10H', 'D10I', 'D10K', 'D10L', 'D10N',\n",
       "        'D10S', 'D10T', 'D10V', 'D10Y', 'P11A', 'P11D', 'P11F', 'P11H',\n",
       "        'P11I', 'P11L', 'P11N', 'P11Q', 'P11R', 'P11S', 'P11T', 'P11Y',\n",
       "        'Q12A', 'Q12D', 'Q12E', 'Q12G', 'Q12H', 'Q12K', 'Q12L', 'Q12M',\n",
       "        'Q12N', 'Q12P', 'Q12R', 'Q12T', 'Q12V', 'Q12W', 'Q12Y', 'E13A',\n",
       "        'E13D', 'E13G', 'E13K', 'E13L', 'E13M', 'E13N', 'E13Q', 'E13R',\n",
       "        'E13V', 'E13Y', 'D14A', 'D14C', 'D14E', 'D14F', 'D14G', 'D14H',\n",
       "        'D14I', 'D14K', 'D14L', 'D14N', 'D14Q', 'D14R', 'D14S', 'D14V',\n",
       "        'D14Y', 'G15A', 'G15C', 'G15D', 'G15E', 'G15I', 'G15K', 'G15L',\n",
       "        'G15Q', 'G15R', 'G15S', 'G15V', 'G15W', 'E16A', 'E16D', 'E16G',\n",
       "        'E16K', 'E16L', 'E16M', 'E16N', 'E16Q', 'E16R', 'E16V', 'E16W',\n",
       "        'E16Y', 'L17A', 'L17H', 'L17I', 'L17K', 'L17M', 'L17P', 'L17Q',\n",
       "        'L17R', 'L17S', 'L17T', 'L17V', 'L17W', 'G18A', 'G18C', 'G18D',\n",
       "        'G18E', 'G18F', 'G18H', 'G18I', 'G18N', 'G18R', 'G18S', 'G18T',\n",
       "        'G18V', 'G18W', 'G18Y', 'F19C', 'F19H', 'F19I', 'F19L', 'F19M',\n",
       "        'F19N', 'F19P', 'F19R', 'F19S', 'F19T', 'F19V', 'F19Y', 'R20A',\n",
       "        'R20C', 'R20D', 'R20F', 'R20G', 'R20H', 'R20I', 'R20L', 'R20N',\n",
       "        'R20P', 'R20Q', 'R20S', 'R20T', 'R20W', 'R20Y', 'R21A', 'R21C',\n",
       "        'R21E', 'R21G', 'R21H', 'R21I', 'R21K', 'R21L', 'R21M', 'R21P',\n",
       "        'R21Q', 'R21S', 'R21T', 'R21V', 'R21W', 'G22A', 'G22C', 'G22D',\n",
       "        'G22E', 'G22I', 'G22K', 'G22L', 'G22Q', 'G22R', 'G22S', 'G22V',\n",
       "        'G22W', 'D23A', 'D23C', 'D23E', 'D23F', 'D23G', 'D23H', 'D23I',\n",
       "        'D23K', 'D23L', 'D23N', 'D23S', 'D23V', 'D23Y', 'F24A', 'F24C',\n",
       "        'F24D', 'F24G', 'F24H', 'F24I', 'F24L', 'F24M', 'F24N', 'F24P',\n",
       "        'F24R', 'F24S', 'F24T', 'F24V', 'F24W', 'F24Y', 'I25A', 'I25D',\n",
       "        'I25F', 'I25H', 'I25K', 'I25L', 'I25M', 'I25N', 'I25P', 'I25R',\n",
       "        'I25S', 'I25T', 'I25V', 'I25Y', 'H26A', 'H26C', 'H26D', 'H26E',\n",
       "        'H26F', 'H26G', 'H26I', 'H26K', 'H26L', 'H26N', 'H26P', 'H26Q',\n",
       "        'H26R', 'H26S', 'H26T', 'H26V', 'H26Y', 'V27A', 'V27C', 'V27D',\n",
       "        'V27E', 'V27F', 'V27G', 'V27H', 'V27I', 'V27L', 'V27M', 'V27N',\n",
       "        'V27S', 'V27T', 'V27Y', 'M28A', 'M28E', 'M28F', 'M28G', 'M28I',\n",
       "        'M28K', 'M28L', 'M28N', 'M28P', 'M28Q', 'M28R', 'M28S', 'M28T',\n",
       "        'M28V', 'M28W', 'M28Y', 'D29A', 'D29C', 'D29E', 'D29F', 'D29G',\n",
       "        'D29H', 'D29I', 'D29K', 'D29L', 'D29N', 'D29P', 'D29S', 'D29V',\n",
       "        'D29Y', 'N30A', 'N30C', 'N30D', 'N30E', 'N30F', 'N30G', 'N30H',\n",
       "        'N30I', 'N30K', 'N30M', 'N30R', 'N30S', 'N30T', 'N30V', 'N30Y',\n",
       "        'S31A', 'S31E', 'S31F', 'S31I', 'S31K', 'S31L', 'S31P', 'S31Q',\n",
       "        'S31R', 'S31T', 'S31V', 'S31W', 'S31Y', 'D32A', 'D32C', 'D32E',\n",
       "        'D32F', 'D32G', 'D32H', 'D32I', 'D32K', 'D32N', 'D32S', 'D32T',\n",
       "        'D32V', 'D32Y', 'P33A', 'P33C', 'P33D', 'P33F', 'P33G', 'P33H',\n",
       "        'P33I', 'P33K', 'P33L', 'P33N', 'P33Q', 'P33R', 'P33S', 'P33T',\n",
       "        'P33V', 'P33Y', 'N34A', 'N34C', 'N34D', 'N34E', 'N34F', 'N34G',\n",
       "        'N34H', 'N34I', 'N34K', 'N34L', 'N34Q', 'N34R', 'N34S', 'N34T',\n",
       "        'N34V', 'N34Y', 'W35A', 'W35C', 'W35E', 'W35F', 'W35G', 'W35K',\n",
       "        'W35L', 'W35M', 'W35Q', 'W35R', 'W35S', 'W35T', 'W35V', 'W35Y',\n",
       "        'W36C', 'W36F', 'W36G', 'W36K', 'W36L', 'W36M', 'W36Q', 'W36R',\n",
       "        'W36S', 'W36T', 'W36V', 'W36Y', 'K37D', 'K37E', 'K37G', 'K37I',\n",
       "        'K37L', 'K37M', 'K37N', 'K37Q', 'K37R', 'K37S', 'K37T', 'K37V',\n",
       "        'K37Y', 'G38A', 'G38C', 'G38D', 'G38E', 'G38I', 'G38K', 'G38L',\n",
       "        'G38Q', 'G38R', 'G38S', 'G38T', 'G38V', 'G38W', 'A39C', 'A39D',\n",
       "        'A39E', 'A39F', 'A39G', 'A39I', 'A39N', 'A39P', 'A39S', 'A39T',\n",
       "        'A39V', 'A39Y', 'C40F', 'C40G', 'C40H', 'C40I', 'C40L', 'C40N',\n",
       "        'C40R', 'C40S', 'C40W', 'C40Y', 'H41C', 'H41D', 'H41E', 'H41F',\n",
       "        'H41G', 'H41I', 'H41K', 'H41L', 'H41N', 'H41P', 'H41Q', 'H41R',\n",
       "        'H41S', 'H41T', 'H41V', 'H41Y', 'G42A', 'G42C', 'G42D', 'G42E',\n",
       "        'G42F', 'G42K', 'G42L', 'G42M', 'G42Q', 'G42R', 'G42S', 'G42T',\n",
       "        'G42V', 'G42W', 'Q43D', 'Q43E', 'Q43H', 'Q43K', 'Q43L', 'Q43M',\n",
       "        'Q43N', 'Q43P', 'Q43R', 'Q43V', 'Q43W', 'Q43Y', 'T44A', 'T44C',\n",
       "        'T44D', 'T44F', 'T44G', 'T44I', 'T44K', 'T44M', 'T44N', 'T44P',\n",
       "        'T44R', 'T44S', 'T44V', 'T44Y', 'G45A', 'G45C', 'G45D', 'G45E',\n",
       "        'G45F', 'G45H', 'G45I', 'G45L', 'G45N', 'G45P', 'G45R', 'G45S',\n",
       "        'G45T', 'G45V', 'G45W', 'G45Y', 'M46A', 'M46E', 'M46F', 'M46I',\n",
       "        'M46K', 'M46L', 'M46N', 'M46R', 'M46S', 'M46T', 'M46V', 'M46W',\n",
       "        'F47C', 'F47D', 'F47H', 'F47I', 'F47L', 'F47N', 'F47P', 'F47S',\n",
       "        'F47T', 'F47V', 'F47Y', 'P48A', 'P48F', 'P48H', 'P48I', 'P48L',\n",
       "        'P48N', 'P48Q', 'P48R', 'P48S', 'P48T', 'P48Y', 'R49A', 'R49C',\n",
       "        'R49D', 'R49F', 'R49G', 'R49H', 'R49I', 'R49L', 'R49N', 'R49P',\n",
       "        'R49Q', 'R49S', 'R49T', 'R49W', 'R49Y', 'N50C', 'N50D', 'N50E',\n",
       "        'N50F', 'N50G', 'N50H', 'N50I', 'N50K', 'N50L', 'N50M', 'N50Q',\n",
       "        'N50R', 'N50S', 'N50T', 'N50V', 'N50Y', 'Y51C', 'Y51D', 'Y51F',\n",
       "        'Y51H', 'Y51I', 'Y51K', 'Y51L', 'Y51N', 'Y51Q', 'Y51R', 'Y51S',\n",
       "        'Y51T', 'Y51V', 'Y51W', 'V52A', 'V52C', 'V52D', 'V52E', 'V52F',\n",
       "        'V52G', 'V52I', 'V52L', 'V52M', 'V52N', 'V52P', 'V52S', 'V52T',\n",
       "        'V52Y', 'T53A', 'T53D', 'T53F', 'T53G', 'T53I', 'T53K', 'T53M',\n",
       "        'T53N', 'T53P', 'T53R', 'T53S', 'T53V', 'T53Y', 'P54A', 'P54D',\n",
       "        'P54F', 'P54H', 'P54I', 'P54L', 'P54N', 'P54Q', 'P54R', 'P54S',\n",
       "        'P54T', 'P54V', 'P54Y', 'V55A', 'V55D', 'V55E', 'V55F', 'V55G',\n",
       "        'V55I', 'V55K', 'V55L', 'V55M', 'V55P', 'V55Q', 'V55R', 'V55S',\n",
       "        'V55T', 'N56C', 'N56D', 'N56E', 'N56F', 'N56G', 'N56H', 'N56I',\n",
       "        'N56K', 'N56M', 'N56Q', 'N56R', 'N56S', 'N56T', 'N56V', 'N56Y'],\n",
       "       dtype='<U4')}"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data_jax[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5207689",
   "metadata": {},
   "source": [
    "# Shuffle Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "cad7f147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_weights(rng, params):\n",
    "    def _shuffle_array(rng, arr):\n",
    "        flat_arr = arr.ravel()\n",
    "        shuffled_flat_arr = jax.random.permutation(rng, flat_arr)\n",
    "        return jnp.reshape(shuffled_flat_arr, arr.shape)\n",
    "    \n",
    "    leaves, _ = jax.tree_util.tree_flatten(params)\n",
    "    rngs = jax.random.split(rng, len(leaves))\n",
    "    new_params = jax.tree_util.tree_map(_shuffle_array, rngs, params)\n",
    "    return new_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d48b53",
   "metadata": {},
   "source": [
    "# Create model Jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "7878c2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_fn(number_additive_traits, l1, l2, rng):\n",
    "\n",
    "    def model_fn(inputs_select, inputs_folding, inputs_binding):\n",
    "\n",
    "        input_layer_select_folding = jnp.expand_dims(inputs_select[:, 0], -1)\n",
    "        input_layer_select_binding = jnp.expand_dims(inputs_select[:, 1], -1)\n",
    "\n",
    "        folding_additive_trait_layer = hk.Linear(number_additive_traits,\n",
    "                                                 w_init=hk.initializers.VarianceScaling(1.0, \"fan_avg\",\n",
    "                                                                                        \"truncated_normal\"),\n",
    "                                                 with_bias=False\n",
    "                                                 )(inputs_folding)\n",
    "\n",
    "        folding_nonlinear_layer = StateProbFolded()(folding_additive_trait_layer)\n",
    "\n",
    "        folding_additive_layer = hk.Linear(number_additive_traits,\n",
    "                                           w_init=hk.initializers.VarianceScaling(1.0, \"fan_avg\", \"truncated_normal\"),\n",
    "                                           with_bias=False  # ,\n",
    "                                           # kernel_regularizer=hk.regularizers.L1L2(l1=l1, l2=l2)\n",
    "                                           )(folding_nonlinear_layer)\n",
    "\n",
    "        # binding\n",
    "        binding_additive_trait_layer = hk.Linear(number_additive_traits,\n",
    "                                                 w_init=hk.initializers.VarianceScaling(1.0, \"fan_avg\",\n",
    "                                                                                        \"truncated_normal\"),\n",
    "                                                 with_bias=False\n",
    "                                                 )(inputs_binding)\n",
    "\n",
    "        binding_nonlinear_layer = StateProbBound()(binding_additive_trait_layer, folding_additive_trait_layer)\n",
    "\n",
    "        binding_additive_layer = hk.Linear(number_additive_traits,\n",
    "                                           w_init=hk.initializers.VarianceScaling(1.0, \"fan_avg\", \"truncated_normal\"),\n",
    "                                           with_bias=False\n",
    "                                           )(binding_nonlinear_layer)\n",
    "\n",
    "        # output\n",
    "        multiplicative_layer_folding = folding_additive_layer * input_layer_select_folding\n",
    "        multiplicative_layer_binding = binding_additive_layer * input_layer_select_binding\n",
    "        output_layer = multiplicative_layer_folding + multiplicative_layer_binding\n",
    "\n",
    "        return output_layer\n",
    "\n",
    "    return model_fn\n",
    "\n",
    "\n",
    "def create_model_jax(rng, learn_rate, l1, l2, input_dim_select, input_dim_folding, input_dim_binding,\n",
    "                     number_additive_traits):\n",
    "    # Create model\n",
    "    model_fn = create_model_fn(number_additive_traits, l1, l2, rng)\n",
    "    model = hk.without_apply_rng(hk.transform(model_fn))\n",
    "\n",
    "    # Create optimizer\n",
    "    opt = optax.chain(\n",
    "        optax.adam(learn_rate),\n",
    "        constrained_gradients(['folding_additive', 'binding_additive'], 0, 1e3),\n",
    "    )\n",
    "\n",
    "    # Create regularizer\n",
    "    # regularizer = hk.regularizers.L1L2(l1=l1, l2=l2)\n",
    "\n",
    "    return model, opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4d0433",
   "metadata": {},
   "source": [
    "# Grid Search Jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "e7a18282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(input_data, batch_size, rng):\n",
    "    \"\"\"Generate batches for training.\n",
    "\n",
    "    Args:\n",
    "        input_data: A dictionary of NumPy arrays containing the input data.\n",
    "        batch_size: The batch size.\n",
    "        rng: A JAX PRNGKey.\n",
    "\n",
    "    Yields:\n",
    "        A tuple of (select, fold, bind, target) batches.\n",
    "    \"\"\"\n",
    "    num_samples = input_data['select'].shape[0]\n",
    "    indices = jnp.arange(num_samples)\n",
    "\n",
    "    # Shuffle the training data.\n",
    "    rng, _ = jax.random.split(rng)\n",
    "    indices = jax.random.permutation(rng, indices)\n",
    "\n",
    "    # Generate batches.\n",
    "    for start_idx in range(0, num_samples, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, num_samples)\n",
    "        batch_indices = indices[start_idx:end_idx]\n",
    "\n",
    "        batch_select = input_data['select'][batch_indices]\n",
    "        batch_fold = input_data['fold'][batch_indices]\n",
    "        batch_bind = input_data['bind'][batch_indices]\n",
    "        batch_target = input_data['target'][batch_indices]\n",
    "\n",
    "        yield batch_select, batch_fold, batch_bind, batch_target\n",
    "        \n",
    "def fit_model_grid_jax(param_dict, input_data, n_epochs, rng, testing=False):\n",
    "    # Summarize results\n",
    "    print(\"Grid search using %s\" % (param_dict))\n",
    "\n",
    "    rng_init, rng_batches = jax.random.split(rng)\n",
    "\n",
    "    # Create model\n",
    "    model, optimizer = create_model_jax(\n",
    "        rng=rng_init,\n",
    "        learn_rate=param_dict['learning_rate'],\n",
    "        l1=param_dict['l1_regularization_factor'],\n",
    "        l2=param_dict['l2_regularization_factor'],\n",
    "        input_dim_select=input_data['train']['select'].shape[1],\n",
    "        input_dim_folding=input_data['train']['fold'].shape[1],\n",
    "        input_dim_binding=input_data['train']['bind'].shape[1],\n",
    "        number_additive_traits=param_dict['number_additive_traits'])\n",
    "\n",
    "    @jax.jit\n",
    "    def loss_fn(params, inputs_select, inputs_folding, inputs_binding, target):\n",
    "        output = model.apply(params, inputs_select, inputs_folding, inputs_binding)\n",
    "        loss = jnp.mean(jnp.abs(output - target))\n",
    "\n",
    "        # Apply L1 and L2 regularization\n",
    "        l1_loss = 0\n",
    "        l2_loss = 0\n",
    "        for p in jax.tree_util.tree_leaves(params):\n",
    "            if p.ndim > 1:  # exclude bias parameters\n",
    "                l1_loss += jnp.sum(jnp.abs(p))\n",
    "                l2_loss += jnp.sum(jnp.square(p))\n",
    "        loss = loss + param_dict['l1_regularization_factor'] * l1_loss + param_dict[\n",
    "            'l2_regularization_factor'] * l2_loss\n",
    "\n",
    "        return loss\n",
    "\n",
    "    @jax.jit\n",
    "    def update(params, opt_state, inputs_select, inputs_folding, inputs_binding, target):\n",
    "        grads = jax.grad(loss_fn)(params, inputs_select, inputs_folding, inputs_binding, target)\n",
    "        updates, new_opt_state = optimizer.update(grads, opt_state)\n",
    "        # print('update done')\n",
    "        new_params = optax.apply_updates(params, updates)\n",
    "        return new_params, new_opt_state\n",
    "\n",
    "    params = model.init(rng, input_data['train']['select'], input_data['train']['fold'], input_data['train']['bind'])\n",
    "    opt_state = optimizer.init(params)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_data in generate_batches(input_data['train'], param_dict['num_samples'], rng_batches):\n",
    "            inputs_select, inputs_folding, inputs_binding, target = batch_data\n",
    "            params, opt_state = update(params, opt_state, inputs_select, inputs_folding, inputs_binding, target)\n",
    "        val_loss = loss_fn(params, input_data['valid']['select'], input_data['valid']['fold'],\n",
    "                           input_data['valid']['bind'], input_data['valid']['target'])\n",
    "        print('epoch done')\n",
    "    if testing == True:\n",
    "        return val_loss.item(), model, model_weights\n",
    "    return val_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "da7cab5e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search using {'num_samples': 128, 'learning_rate': 0.0001, 'l1_regularization_factor': 0.0001, 'l2_regularization_factor': 0.0001, 'number_additive_traits': 1}\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "Grid search using {'num_samples': 128, 'learning_rate': 0.0001, 'l1_regularization_factor': 0.0001, 'l2_regularization_factor': 0.001, 'number_additive_traits': 1}\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "Grid search using {'num_samples': 128, 'learning_rate': 0.0001, 'l1_regularization_factor': 0.0001, 'l2_regularization_factor': 0.01, 'number_additive_traits': 1}\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "Best: 0.438236 using {'num_samples': 128, 'learning_rate': 0.0001, 'l1_regularization_factor': 0.0001, 'l2_regularization_factor': 0.01, 'number_additive_traits': 1}\n"
     ]
    }
   ],
   "source": [
    "#Fit model\n",
    "if len(l1) == 1 and len(l2) == 1 and len(batch_size) == 1 and len(learn_rate) == 1:\n",
    "    best_params = {\n",
    "        \"num_samples\": batch_size[0],\n",
    "        \"learning_rate\": learn_rate[0],\n",
    "        \"l1_regularization_factor\": l1[0],\n",
    "        \"l2_regularization_factor\": l2[0],\n",
    "        \"number_additive_traits\": 1\n",
    "    }\n",
    "else:\n",
    "    parameter_grid = [{\n",
    "        \"num_samples\": i,\n",
    "        \"learning_rate\": j,\n",
    "        \"l1_regularization_factor\": k,\n",
    "        \"l2_regularization_factor\": l,\n",
    "        \"number_additive_traits\": 1\n",
    "    } for i in batch_size for j in learn_rate for k in l1 for l in l2]\n",
    "\n",
    "    rng = jax.random.PRNGKey(random_seed)\n",
    "    rngs = jax.random.split(rng, len(parameter_grid[:3]))\n",
    "    #print(len(parameter_grid))\n",
    "    grid_results = [fit_model_grid_jax(params, model_data_jax, num_epochs_grid, rng_key) for params, rng_key in zip(parameter_grid[], rngs)]\n",
    "\n",
    "    best_params = parameter_grid[np.argmin(grid_results)]\n",
    "\n",
    "    print(\"Best: %f using %s\" % (min(grid_results), best_params))\n",
    "\n",
    "num_samples = best_params['num_samples']\n",
    "learning_rate = best_params['learning_rate']\n",
    "l1_regularization_factor = best_params['l1_regularization_factor']\n",
    "l2_regularization_factor = best_params['l2_regularization_factor']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe348083",
   "metadata": {},
   "source": [
    "# Fitting final model and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "e144ac4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_weights(rng, params):\n",
    "    def _shuffle_array(rng, arr):\n",
    "        flat_arr = arr.ravel()\n",
    "        shuffled_flat_arr = jax.random.permutation(rng, flat_arr)\n",
    "        return jnp.reshape(shuffled_flat_arr, arr.shape)\n",
    "\n",
    "    leaves, _ = jax.tree_util.tree_flatten(params)\n",
    "    rngs = jax.random.split(rng, len(leaves))\n",
    "    zipped_args = zip_longest(leaves, rngs, fillvalue=None)\n",
    "    new_leaves = [(_shuffle_array(rng, leaf) if leaf is not None else leaf) for leaf, rng in zipped_args]\n",
    "    new_params = jax.tree_util.tree_unflatten(_, new_leaves)\n",
    "    \n",
    "    return new_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "be6520f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(weights, opt_state, param_dict, input_data, n_epochs, rng):\n",
    "    print(\"Grid search using %s\" % (param_dict))\n",
    "\n",
    "    rng_init, rng_batches = jax.random.split(rng)\n",
    "\n",
    "    @jax.jit\n",
    "    def loss_fn(params, inputs_select, inputs_folding, inputs_binding, target):\n",
    "        output = model.apply(params, inputs_select, inputs_folding, inputs_binding)\n",
    "        loss = jnp.mean(jnp.abs(output - target))\n",
    "        return loss\n",
    "\n",
    "    @jax.jit\n",
    "    def update(weights, opt_state, inputs_select, inputs_folding, inputs_binding, target):\n",
    "        grads = jax.grad(loss_fn)(weights, inputs_select, inputs_folding, inputs_binding, target)\n",
    "        updates, new_opt_state = optimizer.update(grads, opt_state)\n",
    "        weights = optax.apply_updates(weights, updates)\n",
    "        return weights, new_opt_state\n",
    "\n",
    "    history = []\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        for batch_data in generate_batches(input_data['train'], param_dict['num_samples'], rng_batches):\n",
    "            inputs_select, inputs_folding, inputs_binding, target = batch_data\n",
    "            weights, opt_state = update(weights, opt_state, inputs_select, inputs_folding, inputs_binding, target)\n",
    "            \n",
    "        val_loss = loss_fn(weights, input_data['valid']['select'], input_data['valid']['fold'],\n",
    "                           input_data['valid']['bind'], input_data['valid']['target'])\n",
    "        history.append(val_loss.item())\n",
    "        print('epoch done')\n",
    "\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "b47ded3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Output model directory already exists.\n",
      "Warning: Output plot directory already exists.\n"
     ]
    }
   ],
   "source": [
    "#Output model directory\n",
    "model_directory = os.path.join(output_directory, \"whole_model\")\n",
    "#Create output model directory\n",
    "try:\n",
    "  os.mkdir(model_directory)\n",
    "except FileExistsError:\n",
    "  print(\"Warning: Output model directory already exists.\")\n",
    "\n",
    "#Output plot directory\n",
    "plot_directory = os.path.join(output_directory, \"plots\")\n",
    "#Create output plot directory\n",
    "try:\n",
    "  os.mkdir(plot_directory)\n",
    "except FileExistsError:\n",
    "  print(\"Warning: Output plot directory already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "253c157b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import model_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "4138065a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search using {'num_samples': 128, 'learning_rate': 0.0001, 'l1_regularization_factor': 0.0001, 'l2_regularization_factor': 0.01, 'number_additive_traits': 1}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[445], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m shuffled_weights \u001b[38;5;241m=\u001b[39m shuffle_weights(rng, weights)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#Fit the model on best params\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m history, model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshuffled_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_data_jax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m#save model\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m#model.save(os.path.join(model_directory, 'my_model_'+str(model_count)))\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m handle:\n",
      "File \u001b[0;32m~/UCL_work/Crick/doubledeepms/inst/python/training.py:58\u001b[0m, in \u001b[0;36mmodel_training\u001b[0;34m(weights, opt_state, param_dict, input_data, n_epochs, rng)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_data \u001b[38;5;129;01min\u001b[39;00m generate_batches(input_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m], param_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_samples\u001b[39m\u001b[38;5;124m'\u001b[39m], rng_batches):\n\u001b[1;32m     57\u001b[0m     inputs_select, inputs_folding, inputs_binding, target \u001b[38;5;241m=\u001b[39m batch_data\n\u001b[0;32m---> 58\u001b[0m     weights, opt_state \u001b[38;5;241m=\u001b[39m \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_select\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_folding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_binding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m loss_fn(weights, input_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselect\u001b[39m\u001b[38;5;124m'\u001b[39m], input_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     61\u001b[0m                    input_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbind\u001b[39m\u001b[38;5;124m'\u001b[39m], input_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     62\u001b[0m history\u001b[38;5;241m.\u001b[39mappend(val_loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "    \u001b[0;31m[... skipping hidden 11 frame]\u001b[0m\n",
      "File \u001b[0;32m~/UCL_work/Crick/doubledeepms/inst/python/training.py:48\u001b[0m, in \u001b[0;36mmodel_training.<locals>.update\u001b[0;34m(weights, opt_state, inputs_select, inputs_folding, inputs_binding, target)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;129m@jax\u001b[39m\u001b[38;5;241m.\u001b[39mjit\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(weights, opt_state, inputs_select, inputs_folding, inputs_binding, target):\n\u001b[0;32m---> 48\u001b[0m     grads \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_select\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_folding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_binding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     updates, new_opt_state \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mupdate(grads, opt_state)\n\u001b[1;32m     50\u001b[0m     weights \u001b[38;5;241m=\u001b[39m optax\u001b[38;5;241m.\u001b[39mapply_updates(weights, updates)\n",
      "    \u001b[0;31m[... skipping hidden 19 frame]\u001b[0m\n",
      "File \u001b[0;32m~/UCL_work/Crick/doubledeepms/inst/python/training.py:42\u001b[0m, in \u001b[0;36mmodel_training.<locals>.loss_fn\u001b[0;34m(params, inputs_select, inputs_folding, inputs_binding, target)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@jax\u001b[39m\u001b[38;5;241m.\u001b[39mjit\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_fn\u001b[39m(params, inputs_select, inputs_folding, inputs_binding, target):\n\u001b[0;32m---> 42\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mapply(params, inputs_select, inputs_folding, inputs_binding)\n\u001b[1;32m     43\u001b[0m     loss \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mmean(jnp\u001b[38;5;241m.\u001b[39mabs(output \u001b[38;5;241m-\u001b[39m target))\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "num_samples = best_params['num_samples']\n",
    "learning_rate = best_params['learning_rate']\n",
    "l1_regularization_factor = best_params['l1_regularization_factor']\n",
    "l2_regularization_factor = best_params['l2_regularization_factor']\n",
    "number_additive_traits = best_params['number_additive_traits']\n",
    "\n",
    "#######################################################################\n",
    "## BUILD FINAL NEURAL NETWORK ##\n",
    "#######################################################################\n",
    "\n",
    "#create the rng\n",
    "random_seed = 42\n",
    "rng = jax.random.PRNGKey(random_seed)\n",
    "num_models = 2 \n",
    "\n",
    "model, optimizer = create_model_jax(\n",
    "    rng=rng,\n",
    "    learn_rate=learning_rate,\n",
    "    l1=l1_regularization_factor,\n",
    "    l2=l2_regularization_factor,\n",
    "    input_dim_select=model_data_jax['train']['select'].shape[1],\n",
    "    input_dim_folding=model_data_jax['train']['fold'].shape[1],\n",
    "    input_dim_binding=model_data_jax['train']['bind'].shape[1],\n",
    "    number_additive_traits=number_additive_traits\n",
    ")\n",
    "\n",
    "weights = model.init(rng, model_data_jax['train']['select'], model_data_jax['train']['fold'], model_data_jax['train']['bind'])\n",
    "opt_state = optimizer.init(weights)\n",
    "\n",
    "for model_count in range(num_models):\n",
    "\n",
    "    #Shuffle model weights\n",
    "    shuffled_weights = shuffle_weights(rng, weights)\n",
    "\n",
    "    #Fit the model on best params\n",
    "    history, model = model_training(model, optimizer, shuffled_weights, opt_state, best_params, model_data_jax, num_epochs_grid, rng)\n",
    "    \n",
    "    #save model\n",
    "    #model.save(os.path.join(model_directory, 'my_model_'+str(model_count)))\n",
    "    with open(f'weights_{model_count}.pickle', 'wb') as handle:\n",
    "        pickle.dump(shuffled_weights, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    #load model\n",
    "    #model = load_model(os.path.join(model_directory, 'my_model_'+str(model_count)))\n",
    "    with open(f'weights_{model_count}.pickle', 'rb') as handle:\n",
    "        shuffled_weights_reloaded = pickle.load(handle)\n",
    "        \n",
    "    print(history)\n",
    "    #Plot model performance per epoch\n",
    "    my_figure = plt.figure(figsize = (8,8))\n",
    "    plt.plot(np.log(history))\n",
    "    plt.xlabel('Number of epochs')\n",
    "    plt.ylabel('Mean Absolute Error (MAE) on testing data')\n",
    "    plt.show()\n",
    "    my_figure.savefig(os.path.join(plot_directory, \"model_performance_perepoch_\"+str(model_count)+\".pdf\"), bbox_inches='tight')\n",
    "    \n",
    "    #######################################################################\n",
    "    ## SAVE OBSERVATIONS, PREDICTIONS & ADDITIVE TRAIT VALUES ##\n",
    "    #######################################################################\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225c980f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
