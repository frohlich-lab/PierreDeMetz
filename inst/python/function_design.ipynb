{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "2903c6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "#tf.config.optimizer.set_jit(False)\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "import random\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "#import matplotlib\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from keras.constraints import Constraint\n",
    "from keras.layers import Layer\n",
    "from keras import backend as K\n",
    "\n",
    "import jax\n",
    "import jax.nn as nn\n",
    "from jax.random import normal\n",
    "from jax.experimental import sparse\n",
    "#from sparse import bcoo_concatenate\n",
    "from jax.tree_util import tree_map\n",
    "import jaxlib\n",
    "import jax.numpy as jnp\n",
    "import haiku as hk\n",
    "import optax\n",
    "from jax import jit\n",
    "from functools import partial\n",
    "import functools\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from optax import GradientTransformation\n",
    "\n",
    "from utils import constrained_gradients, StateProbBound, StateProbFolded, Between, between\n",
    "from linear import custom_linear\n",
    "from training import model_training, shuffle_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "1a441096",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6fed5b",
   "metadata": {},
   "source": [
    "# Define arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "45a1e918",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = '/Users/pierredemetz/UCL_work/Crick/doubledeepms/Results//Data/mochi/GRB2-SH3/mochi__fit_tmodel_3state_sparse_dimsum128_subsample100p//dataset_train.txt'\n",
    "data_valid = '/Users/pierredemetz/UCL_work/Crick/doubledeepms/Results//Data/mochi/GRB2-SH3/mochi__fit_tmodel_3state_sparse_dimsum128_subsample100p//dataset_valid.txt' \n",
    "data_obs = '/Users/pierredemetz/UCL_work/Crick/doubledeepms/Results//Data/mochi/GRB2-SH3/mochi__fit_tmodel_3state_sparse_dimsum128_subsample100p//dataset_all.txt' \n",
    "o = '/Users/pierredemetz/UCL_work/Crick/doubledeepms/Results//Data/mochi/GRB2-SH3/mochi__fit_tmodel_3state_sparse_dimsum128_subsample100p/ '\n",
    "e = 100 \n",
    "l1_regularization_factor = 0 \n",
    "l2_regularization_factor = 0 \n",
    "p = 1000 \n",
    "num_samples= 128,256,512,1024 \n",
    "learning_rate= 0.001 \n",
    "num_resamplings= 10 \n",
    "num_models= 1 \n",
    "random_seed= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "877923ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"data_train\": \"'/Users/pierredemetz/UCL_work/Crick/doubledeepms/Results//Data/mochi/GRB2-SH3/mochi__fit_tmodel_3state_sparse_dimsum128_subsample100p//dataset_train.txt'\",\n",
    "    \"data_valid\": \"/Users/pierredemetz/UCL_work/Crick/doubledeepms/Results//Data/mochi/GRB2-SH3/mochi__fit_tmodel_3state_sparse_dimsum128_subsample100p//dataset_valid.txt\",\n",
    "    \"data_obs\": \"/Users/pierredemetz/UCL_work/Crick/doubledeepms/Results//Data/mochi/GRB2-SH3/mochi__fit_tmodel_3state_sparse_dimsum128_subsample100p//dataset_all.txt\",\n",
    "    \"output_directory\": \"/Users/pierredemetz/UCL_work/Crick/doubledeepms/Results//Data/mochi/GRB2-SH3/mochi__fit_tmodel_3state_sparse_dimsum128_subsample100p/\",\n",
    "    \"number_additive_traits\": 1,\n",
    "    \"l1_regularization_factor\": \"0.0001,0.001,0.01,0.1\",\n",
    "    \"l2_regularization_factor\": \"0.0001,0.001,0.01,0.1\",\n",
    "    \"num_epochs_grid\": 10,\n",
    "    \"num_epochs\": 10,\n",
    "    \"num_samples\": \"128,256,512,1024\",\n",
    "    \"learning_rate\": \"0.0001,0.001,0.01,0.1\",\n",
    "    \"num_resamplings\": 10,\n",
    "    \"early_stopping\": False,\n",
    "    \"num_models\": 2,\n",
    "    \"random_seed\": 1\n",
    "}\n",
    "\n",
    "data_train_file = args[\"data_train\"]\n",
    "data_valid_file = args[\"data_valid\"]\n",
    "data_obs_file = args[\"data_obs\"]\n",
    "output_directory = args[\"output_directory\"]\n",
    "number_additive_traits = args[\"number_additive_traits\"]\n",
    "num_epochs_grid = args[\"num_epochs_grid\"]\n",
    "num_epochs = args[\"num_epochs\"]\n",
    "num_resamplings = args[\"num_resamplings\"]\n",
    "early_stopping = args[\"early_stopping\"]\n",
    "num_models = args[\"num_models\"]\n",
    "random_seed = args[\"random_seed\"]\n",
    "\n",
    "#Grid search arguments\n",
    "l1 = [float(i) for i in args[\"l1_regularization_factor\"].split(\",\")]\n",
    "l2 = [float(i) for i in args[\"l2_regularization_factor\"].split(\",\")]\n",
    "batch_size = [int(i) for i in args[\"num_samples\"].split(\",\")]\n",
    "learn_rate = [float(i) for i in args[\"learning_rate\"].split(\",\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cea3327",
   "metadata": {},
   "source": [
    "# Load model data jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "11d1015e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_data_jax(file_dict):\n",
    "    data_dict = {}\n",
    "    for name in file_dict.keys():\n",
    "        # Initialize\n",
    "        data_dict[name] = {}\n",
    "\n",
    "        # Read the entire file once\n",
    "        df = pd.read_csv(file_dict[name])\n",
    "\n",
    "        # Column names\n",
    "        ALL_COLUMNS = list(df.columns)\n",
    "        SELECT_COLUMNS = [col for col in ALL_COLUMNS if col.startswith(\"dataset_\")]\n",
    "        FOLD_COLUMNS = [col for col in ALL_COLUMNS if col.startswith(\"fold_\") or col == \"WT\"]\n",
    "        BIND_COLUMNS = [col for col in ALL_COLUMNS if col.startswith(\"bind_\") or col == \"WT\"]\n",
    "        TARGET_COLUMN = \"fitness\"\n",
    "        TARGET_SD_COLUMN = \"fitness_sd\"\n",
    "        SEQUENCE_COLUMN = \"variant_sequence\"\n",
    "        TRAINING_SET_COLUMN = \"training_set\"\n",
    "\n",
    "        # Save (sparse) tensors\n",
    "        data_dict[name][\"select\"] = jnp.array(df[SELECT_COLUMNS], dtype=jnp.float32)\n",
    "        data_dict[name][\"fold\"] = jnp.array(df[FOLD_COLUMNS], dtype=jnp.float32)\n",
    "        data_dict[name][\"bind\"] = jnp.array(df[BIND_COLUMNS], dtype=jnp.float32)\n",
    "        data_dict[name][\"target\"] = jnp.array(df[TARGET_COLUMN], dtype=jnp.float32)\n",
    "        data_dict[name][\"target_sd\"] = jnp.array(df[TARGET_SD_COLUMN], dtype=jnp.float32)\n",
    "\n",
    "        # Save remaining columns\n",
    "        if SEQUENCE_COLUMN in df.columns:\n",
    "            data_dict[name][\"sequence\"] = np.array(df[SEQUENCE_COLUMN].values)\n",
    "        if TRAINING_SET_COLUMN in df.columns:\n",
    "            data_dict[name][\"training_set\"] = jnp.expand_dims(jnp.array(df[TRAINING_SET_COLUMN].values), axis=-1)\n",
    "\n",
    "        data_dict[name][\"fold_colnames\"] = np.array([col.replace(\"fold_\", \"\") for col in FOLD_COLUMNS])\n",
    "        data_dict[name][\"bind_colnames\"] = np.array([col.replace(\"bind_\", \"\") for col in BIND_COLUMNS])\n",
    "\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "25d0467b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_file = '/Users/pierredemetz/UCL_work/Crick/doubledeepms/Results//Data/mochi/GRB2-SH3/mochi__fit_tmodel_3state_sparse_dimsum128_subsample100p//dataset_train.txt'\n",
    "\n",
    "data_valid_file = '/Users/pierredemetz/UCL_work/Crick/doubledeepms/Results//Data/mochi/GRB2-SH3/mochi__fit_tmodel_3state_sparse_dimsum128_subsample100p//dataset_valid.txt' \n",
    "\n",
    "data_obs_file = '/Users/pierredemetz/UCL_work/Crick/doubledeepms/Results//Data/mochi/GRB2-SH3/mochi__fit_tmodel_3state_sparse_dimsum128_subsample100p//dataset_all.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "e3cb5b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the rng\n",
    "random_seed = 42\n",
    "rng = jax.random.PRNGKey(random_seed)\n",
    "\n",
    "#Load model data\n",
    "model_data_jax = load_model_data_jax({\n",
    "    \"train\": data_train_file,\n",
    "    \"valid\": data_valid_file,\n",
    "    \"obs\": data_obs_file\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "6ca9709d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'select': DeviceArray([[0., 1.],\n",
       "              [0., 1.],\n",
       "              [1., 0.],\n",
       "              ...,\n",
       "              [1., 0.],\n",
       "              [1., 0.],\n",
       "              [0., 1.]], dtype=float32),\n",
       " 'fold': DeviceArray([[1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              ...,\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " 'bind': DeviceArray([[1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              ...,\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " 'target': DeviceArray([-0.33598602, -0.8518485 , -1.0957463 , ..., -0.26487023,\n",
       "              -1.166961  , -0.66433465], dtype=float32),\n",
       " 'target_sd': DeviceArray([0.11158013, 0.17281719, 0.09720125, ..., 0.22753495,\n",
       "              0.36643863, 0.15336636], dtype=float32),\n",
       " 'sequence': array(['0000000000000000000000000000000000000000000000000L000000',\n",
       "        '00000000I0000000000000000000000000000000Q000000000000000',\n",
       "        '000000000000000000000000000000000000000V000000W000000000', ...,\n",
       "        '000000000M0000000000000000000000000000000000000000000S00',\n",
       "        '000000000000000000K0000000000000000T00000000000000000000',\n",
       "        '000000000N0000000000000000000000000000000000S00000000000'],\n",
       "       dtype=object),\n",
       " 'training_set': DeviceArray([[1],\n",
       "              [1],\n",
       "              [1],\n",
       "              ...,\n",
       "              [1],\n",
       "              [1],\n",
       "              [1]], dtype=int32),\n",
       " 'fold_colnames': array(['WT', 'T1A', 'T1C', ..., 'N56V', 'N56W', 'N56Y'], dtype='<U4'),\n",
       " 'bind_colnames': array(['WT', 'T1A', 'T1E', 'T1G', 'T1I', 'T1K', 'T1L', 'T1M', 'T1N',\n",
       "        'T1P', 'T1R', 'T1S', 'T1V', 'Y2A', 'Y2C', 'Y2D', 'Y2F', 'Y2H',\n",
       "        'Y2I', 'Y2K', 'Y2L', 'Y2N', 'Y2Q', 'Y2R', 'Y2S', 'Y2T', 'Y2W',\n",
       "        'V3A', 'V3C', 'V3D', 'V3E', 'V3F', 'V3G', 'V3H', 'V3I', 'V3L',\n",
       "        'V3N', 'V3P', 'V3S', 'V3T', 'V3Y', 'Q4E', 'Q4G', 'Q4H', 'Q4K',\n",
       "        'Q4L', 'Q4M', 'Q4N', 'Q4P', 'Q4R', 'Q4S', 'Q4T', 'Q4V', 'Q4W',\n",
       "        'Q4Y', 'A5D', 'A5E', 'A5G', 'A5I', 'A5N', 'A5P', 'A5S', 'A5T',\n",
       "        'A5V', 'A5Y', 'L6C', 'L6F', 'L6H', 'L6I', 'L6N', 'L6P', 'L6Q',\n",
       "        'L6R', 'L6S', 'L6V', 'L6Y', 'F7A', 'F7C', 'F7H', 'F7I', 'F7L',\n",
       "        'F7M', 'F7N', 'F7P', 'F7S', 'F7T', 'F7V', 'F7Y', 'D8A', 'D8C',\n",
       "        'D8E', 'D8F', 'D8G', 'D8H', 'D8I', 'D8K', 'D8N', 'D8Q', 'D8R',\n",
       "        'D8S', 'D8T', 'D8V', 'D8Y', 'F9A', 'F9C', 'F9H', 'F9I', 'F9L',\n",
       "        'F9M', 'F9N', 'F9P', 'F9S', 'F9T', 'F9V', 'F9Y', 'D10A', 'D10C',\n",
       "        'D10E', 'D10F', 'D10G', 'D10H', 'D10I', 'D10K', 'D10L', 'D10N',\n",
       "        'D10S', 'D10T', 'D10V', 'D10Y', 'P11A', 'P11D', 'P11F', 'P11H',\n",
       "        'P11I', 'P11L', 'P11N', 'P11Q', 'P11R', 'P11S', 'P11T', 'P11Y',\n",
       "        'Q12A', 'Q12D', 'Q12E', 'Q12G', 'Q12H', 'Q12K', 'Q12L', 'Q12M',\n",
       "        'Q12N', 'Q12P', 'Q12R', 'Q12T', 'Q12V', 'Q12W', 'Q12Y', 'E13A',\n",
       "        'E13D', 'E13G', 'E13K', 'E13L', 'E13M', 'E13N', 'E13Q', 'E13R',\n",
       "        'E13V', 'E13Y', 'D14A', 'D14C', 'D14E', 'D14F', 'D14G', 'D14H',\n",
       "        'D14I', 'D14K', 'D14L', 'D14N', 'D14Q', 'D14R', 'D14S', 'D14V',\n",
       "        'D14Y', 'G15A', 'G15C', 'G15D', 'G15E', 'G15I', 'G15K', 'G15L',\n",
       "        'G15Q', 'G15R', 'G15S', 'G15V', 'G15W', 'E16A', 'E16D', 'E16G',\n",
       "        'E16K', 'E16L', 'E16M', 'E16N', 'E16Q', 'E16R', 'E16V', 'E16W',\n",
       "        'E16Y', 'L17A', 'L17H', 'L17I', 'L17K', 'L17M', 'L17P', 'L17Q',\n",
       "        'L17R', 'L17S', 'L17T', 'L17V', 'L17W', 'G18A', 'G18C', 'G18D',\n",
       "        'G18E', 'G18F', 'G18H', 'G18I', 'G18N', 'G18R', 'G18S', 'G18T',\n",
       "        'G18V', 'G18W', 'G18Y', 'F19C', 'F19H', 'F19I', 'F19L', 'F19M',\n",
       "        'F19N', 'F19P', 'F19R', 'F19S', 'F19T', 'F19V', 'F19Y', 'R20A',\n",
       "        'R20C', 'R20D', 'R20F', 'R20G', 'R20H', 'R20I', 'R20L', 'R20N',\n",
       "        'R20P', 'R20Q', 'R20S', 'R20T', 'R20W', 'R20Y', 'R21A', 'R21C',\n",
       "        'R21E', 'R21G', 'R21H', 'R21I', 'R21K', 'R21L', 'R21M', 'R21P',\n",
       "        'R21Q', 'R21S', 'R21T', 'R21V', 'R21W', 'G22A', 'G22C', 'G22D',\n",
       "        'G22E', 'G22I', 'G22K', 'G22L', 'G22Q', 'G22R', 'G22S', 'G22V',\n",
       "        'G22W', 'D23A', 'D23C', 'D23E', 'D23F', 'D23G', 'D23H', 'D23I',\n",
       "        'D23K', 'D23L', 'D23N', 'D23S', 'D23V', 'D23Y', 'F24A', 'F24C',\n",
       "        'F24D', 'F24G', 'F24H', 'F24I', 'F24L', 'F24M', 'F24N', 'F24P',\n",
       "        'F24R', 'F24S', 'F24T', 'F24V', 'F24W', 'F24Y', 'I25A', 'I25D',\n",
       "        'I25F', 'I25H', 'I25K', 'I25L', 'I25M', 'I25N', 'I25P', 'I25R',\n",
       "        'I25S', 'I25T', 'I25V', 'I25Y', 'H26A', 'H26C', 'H26D', 'H26E',\n",
       "        'H26F', 'H26G', 'H26I', 'H26K', 'H26L', 'H26N', 'H26P', 'H26Q',\n",
       "        'H26R', 'H26S', 'H26T', 'H26V', 'H26Y', 'V27A', 'V27C', 'V27D',\n",
       "        'V27E', 'V27F', 'V27G', 'V27H', 'V27I', 'V27L', 'V27M', 'V27N',\n",
       "        'V27S', 'V27T', 'V27Y', 'M28A', 'M28E', 'M28F', 'M28G', 'M28I',\n",
       "        'M28K', 'M28L', 'M28N', 'M28P', 'M28Q', 'M28R', 'M28S', 'M28T',\n",
       "        'M28V', 'M28W', 'M28Y', 'D29A', 'D29C', 'D29E', 'D29F', 'D29G',\n",
       "        'D29H', 'D29I', 'D29K', 'D29L', 'D29N', 'D29P', 'D29S', 'D29V',\n",
       "        'D29Y', 'N30A', 'N30C', 'N30D', 'N30E', 'N30F', 'N30G', 'N30H',\n",
       "        'N30I', 'N30K', 'N30M', 'N30R', 'N30S', 'N30T', 'N30V', 'N30Y',\n",
       "        'S31A', 'S31E', 'S31F', 'S31I', 'S31K', 'S31L', 'S31P', 'S31Q',\n",
       "        'S31R', 'S31T', 'S31V', 'S31W', 'S31Y', 'D32A', 'D32C', 'D32E',\n",
       "        'D32F', 'D32G', 'D32H', 'D32I', 'D32K', 'D32N', 'D32S', 'D32T',\n",
       "        'D32V', 'D32Y', 'P33A', 'P33C', 'P33D', 'P33F', 'P33G', 'P33H',\n",
       "        'P33I', 'P33K', 'P33L', 'P33N', 'P33Q', 'P33R', 'P33S', 'P33T',\n",
       "        'P33V', 'P33Y', 'N34A', 'N34C', 'N34D', 'N34E', 'N34F', 'N34G',\n",
       "        'N34H', 'N34I', 'N34K', 'N34L', 'N34Q', 'N34R', 'N34S', 'N34T',\n",
       "        'N34V', 'N34Y', 'W35A', 'W35C', 'W35E', 'W35F', 'W35G', 'W35K',\n",
       "        'W35L', 'W35M', 'W35Q', 'W35R', 'W35S', 'W35T', 'W35V', 'W35Y',\n",
       "        'W36C', 'W36F', 'W36G', 'W36K', 'W36L', 'W36M', 'W36Q', 'W36R',\n",
       "        'W36S', 'W36T', 'W36V', 'W36Y', 'K37D', 'K37E', 'K37G', 'K37I',\n",
       "        'K37L', 'K37M', 'K37N', 'K37Q', 'K37R', 'K37S', 'K37T', 'K37V',\n",
       "        'K37Y', 'G38A', 'G38C', 'G38D', 'G38E', 'G38I', 'G38K', 'G38L',\n",
       "        'G38Q', 'G38R', 'G38S', 'G38T', 'G38V', 'G38W', 'A39C', 'A39D',\n",
       "        'A39E', 'A39F', 'A39G', 'A39I', 'A39N', 'A39P', 'A39S', 'A39T',\n",
       "        'A39V', 'A39Y', 'C40F', 'C40G', 'C40H', 'C40I', 'C40L', 'C40N',\n",
       "        'C40R', 'C40S', 'C40W', 'C40Y', 'H41C', 'H41D', 'H41E', 'H41F',\n",
       "        'H41G', 'H41I', 'H41K', 'H41L', 'H41N', 'H41P', 'H41Q', 'H41R',\n",
       "        'H41S', 'H41T', 'H41V', 'H41Y', 'G42A', 'G42C', 'G42D', 'G42E',\n",
       "        'G42F', 'G42K', 'G42L', 'G42M', 'G42Q', 'G42R', 'G42S', 'G42T',\n",
       "        'G42V', 'G42W', 'Q43D', 'Q43E', 'Q43H', 'Q43K', 'Q43L', 'Q43M',\n",
       "        'Q43N', 'Q43P', 'Q43R', 'Q43V', 'Q43W', 'Q43Y', 'T44A', 'T44C',\n",
       "        'T44D', 'T44F', 'T44G', 'T44I', 'T44K', 'T44M', 'T44N', 'T44P',\n",
       "        'T44R', 'T44S', 'T44V', 'T44Y', 'G45A', 'G45C', 'G45D', 'G45E',\n",
       "        'G45F', 'G45H', 'G45I', 'G45L', 'G45N', 'G45P', 'G45R', 'G45S',\n",
       "        'G45T', 'G45V', 'G45W', 'G45Y', 'M46A', 'M46E', 'M46F', 'M46I',\n",
       "        'M46K', 'M46L', 'M46N', 'M46R', 'M46S', 'M46T', 'M46V', 'M46W',\n",
       "        'F47C', 'F47D', 'F47H', 'F47I', 'F47L', 'F47N', 'F47P', 'F47S',\n",
       "        'F47T', 'F47V', 'F47Y', 'P48A', 'P48F', 'P48H', 'P48I', 'P48L',\n",
       "        'P48N', 'P48Q', 'P48R', 'P48S', 'P48T', 'P48Y', 'R49A', 'R49C',\n",
       "        'R49D', 'R49F', 'R49G', 'R49H', 'R49I', 'R49L', 'R49N', 'R49P',\n",
       "        'R49Q', 'R49S', 'R49T', 'R49W', 'R49Y', 'N50C', 'N50D', 'N50E',\n",
       "        'N50F', 'N50G', 'N50H', 'N50I', 'N50K', 'N50L', 'N50M', 'N50Q',\n",
       "        'N50R', 'N50S', 'N50T', 'N50V', 'N50Y', 'Y51C', 'Y51D', 'Y51F',\n",
       "        'Y51H', 'Y51I', 'Y51K', 'Y51L', 'Y51N', 'Y51Q', 'Y51R', 'Y51S',\n",
       "        'Y51T', 'Y51V', 'Y51W', 'V52A', 'V52C', 'V52D', 'V52E', 'V52F',\n",
       "        'V52G', 'V52I', 'V52L', 'V52M', 'V52N', 'V52P', 'V52S', 'V52T',\n",
       "        'V52Y', 'T53A', 'T53D', 'T53F', 'T53G', 'T53I', 'T53K', 'T53M',\n",
       "        'T53N', 'T53P', 'T53R', 'T53S', 'T53V', 'T53Y', 'P54A', 'P54D',\n",
       "        'P54F', 'P54H', 'P54I', 'P54L', 'P54N', 'P54Q', 'P54R', 'P54S',\n",
       "        'P54T', 'P54V', 'P54Y', 'V55A', 'V55D', 'V55E', 'V55F', 'V55G',\n",
       "        'V55I', 'V55K', 'V55L', 'V55M', 'V55P', 'V55Q', 'V55R', 'V55S',\n",
       "        'V55T', 'N56C', 'N56D', 'N56E', 'N56F', 'N56G', 'N56H', 'N56I',\n",
       "        'N56K', 'N56M', 'N56Q', 'N56R', 'N56S', 'N56T', 'N56V', 'N56Y'],\n",
       "       dtype='<U4')}"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data_jax['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "f489c718",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import constrained_gradients, StateProbBound, StateProbFolded, Between, between, get_seq_id, get_layer_index\n",
    "from training import model_training, shuffle_weights, fit_model_grid_jax\n",
    "from dataloading import load_model_data_jax, resample_training_data_jax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd95b47",
   "metadata": {},
   "source": [
    "# Resample training data jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "a4fb114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_training_data_jax(tensor_dict, n_resamplings, rng):\n",
    "    # Resample observed fitness from error distribution\n",
    "\n",
    "    observed_fitness = tensor_dict[\"target\"]\n",
    "    observed_fitness_sd = tensor_dict[\"target_sd\"]\n",
    "\n",
    "    observed_fitness_resample = jnp.array(\n",
    "    [jnp.array(\n",
    "      [observed_fitness[i]+(observed_fitness_sd[i] * jax.random.normal(rng, shape=(1,))) for i in range(len(observed_fitness))])\n",
    "    for j in range(n_resamplings)]\n",
    "    )\n",
    "    print('here')\n",
    "    #Save new data\n",
    "\n",
    "    tensor_dict[\"target\"] = jax.device_put(jnp.expand_dims(observed_fitness_resample.ravel(), -1))\n",
    "\n",
    "    select_tensors = [tensor_dict[\"select\"] for i in range(n_resamplings)]  # Assuming n_resamplings is defined\n",
    "    tensor_dict[\"select\"] = jnp.concatenate(select_tensors, axis=0)\n",
    "\n",
    "    fold_matrices = [tensor_dict[\"fold\"] for i in range(n_resamplings)]\n",
    "    tensor_dict[\"fold\"] = jnp.concatenate(fold_matrices, axis=0)\n",
    "\n",
    "    bind_matrices = [tensor_dict[\"bind\"] for i in range(n_resamplings)]\n",
    "    tensor_dict[\"bind\"] = jnp.concatenate(bind_matrices, axis=0)\n",
    "\n",
    "    return tensor_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "2d43df12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    }
   ],
   "source": [
    "#Resample training data\n",
    "num_resamplings = 1\n",
    "\n",
    "#create the rng\n",
    "random_seed = 42\n",
    "rng = jax.random.PRNGKey(random_seed)\n",
    "\n",
    "if num_resamplings!=0:\n",
    "    model_data_jax[\"train\"] = resample_training_data_jax(\n",
    "        tensor_dict = model_data_jax[\"train\"],\n",
    "        n_resamplings = num_resamplings,\n",
    "        rng = rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "320d08ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'select': DeviceArray([[0., 1.],\n",
       "              [0., 1.],\n",
       "              [1., 0.],\n",
       "              ...,\n",
       "              [1., 0.],\n",
       "              [1., 0.],\n",
       "              [0., 1.]], dtype=float32),\n",
       " 'fold': DeviceArray([[1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              ...,\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " 'bind': DeviceArray([[1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              ...,\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " 'target': DeviceArray([-0.33598602, -0.8518485 , -1.0957463 , ..., -0.26487023,\n",
       "              -1.166961  , -0.66433465], dtype=float32),\n",
       " 'target_sd': DeviceArray([0.11158013, 0.17281719, 0.09720125, ..., 0.22753495,\n",
       "              0.36643863, 0.15336636], dtype=float32),\n",
       " 'sequence': array(['0000000000000000000000000000000000000000000000000L000000',\n",
       "        '00000000I0000000000000000000000000000000Q000000000000000',\n",
       "        '000000000000000000000000000000000000000V000000W000000000', ...,\n",
       "        '000000000M0000000000000000000000000000000000000000000S00',\n",
       "        '000000000000000000K0000000000000000T00000000000000000000',\n",
       "        '000000000N0000000000000000000000000000000000S00000000000'],\n",
       "       dtype=object),\n",
       " 'training_set': DeviceArray([[1],\n",
       "              [1],\n",
       "              [1],\n",
       "              ...,\n",
       "              [1],\n",
       "              [1],\n",
       "              [1]], dtype=int32),\n",
       " 'fold_colnames': array(['WT', 'T1A', 'T1C', ..., 'N56V', 'N56W', 'N56Y'], dtype='<U4'),\n",
       " 'bind_colnames': array(['WT', 'T1A', 'T1E', 'T1G', 'T1I', 'T1K', 'T1L', 'T1M', 'T1N',\n",
       "        'T1P', 'T1R', 'T1S', 'T1V', 'Y2A', 'Y2C', 'Y2D', 'Y2F', 'Y2H',\n",
       "        'Y2I', 'Y2K', 'Y2L', 'Y2N', 'Y2Q', 'Y2R', 'Y2S', 'Y2T', 'Y2W',\n",
       "        'V3A', 'V3C', 'V3D', 'V3E', 'V3F', 'V3G', 'V3H', 'V3I', 'V3L',\n",
       "        'V3N', 'V3P', 'V3S', 'V3T', 'V3Y', 'Q4E', 'Q4G', 'Q4H', 'Q4K',\n",
       "        'Q4L', 'Q4M', 'Q4N', 'Q4P', 'Q4R', 'Q4S', 'Q4T', 'Q4V', 'Q4W',\n",
       "        'Q4Y', 'A5D', 'A5E', 'A5G', 'A5I', 'A5N', 'A5P', 'A5S', 'A5T',\n",
       "        'A5V', 'A5Y', 'L6C', 'L6F', 'L6H', 'L6I', 'L6N', 'L6P', 'L6Q',\n",
       "        'L6R', 'L6S', 'L6V', 'L6Y', 'F7A', 'F7C', 'F7H', 'F7I', 'F7L',\n",
       "        'F7M', 'F7N', 'F7P', 'F7S', 'F7T', 'F7V', 'F7Y', 'D8A', 'D8C',\n",
       "        'D8E', 'D8F', 'D8G', 'D8H', 'D8I', 'D8K', 'D8N', 'D8Q', 'D8R',\n",
       "        'D8S', 'D8T', 'D8V', 'D8Y', 'F9A', 'F9C', 'F9H', 'F9I', 'F9L',\n",
       "        'F9M', 'F9N', 'F9P', 'F9S', 'F9T', 'F9V', 'F9Y', 'D10A', 'D10C',\n",
       "        'D10E', 'D10F', 'D10G', 'D10H', 'D10I', 'D10K', 'D10L', 'D10N',\n",
       "        'D10S', 'D10T', 'D10V', 'D10Y', 'P11A', 'P11D', 'P11F', 'P11H',\n",
       "        'P11I', 'P11L', 'P11N', 'P11Q', 'P11R', 'P11S', 'P11T', 'P11Y',\n",
       "        'Q12A', 'Q12D', 'Q12E', 'Q12G', 'Q12H', 'Q12K', 'Q12L', 'Q12M',\n",
       "        'Q12N', 'Q12P', 'Q12R', 'Q12T', 'Q12V', 'Q12W', 'Q12Y', 'E13A',\n",
       "        'E13D', 'E13G', 'E13K', 'E13L', 'E13M', 'E13N', 'E13Q', 'E13R',\n",
       "        'E13V', 'E13Y', 'D14A', 'D14C', 'D14E', 'D14F', 'D14G', 'D14H',\n",
       "        'D14I', 'D14K', 'D14L', 'D14N', 'D14Q', 'D14R', 'D14S', 'D14V',\n",
       "        'D14Y', 'G15A', 'G15C', 'G15D', 'G15E', 'G15I', 'G15K', 'G15L',\n",
       "        'G15Q', 'G15R', 'G15S', 'G15V', 'G15W', 'E16A', 'E16D', 'E16G',\n",
       "        'E16K', 'E16L', 'E16M', 'E16N', 'E16Q', 'E16R', 'E16V', 'E16W',\n",
       "        'E16Y', 'L17A', 'L17H', 'L17I', 'L17K', 'L17M', 'L17P', 'L17Q',\n",
       "        'L17R', 'L17S', 'L17T', 'L17V', 'L17W', 'G18A', 'G18C', 'G18D',\n",
       "        'G18E', 'G18F', 'G18H', 'G18I', 'G18N', 'G18R', 'G18S', 'G18T',\n",
       "        'G18V', 'G18W', 'G18Y', 'F19C', 'F19H', 'F19I', 'F19L', 'F19M',\n",
       "        'F19N', 'F19P', 'F19R', 'F19S', 'F19T', 'F19V', 'F19Y', 'R20A',\n",
       "        'R20C', 'R20D', 'R20F', 'R20G', 'R20H', 'R20I', 'R20L', 'R20N',\n",
       "        'R20P', 'R20Q', 'R20S', 'R20T', 'R20W', 'R20Y', 'R21A', 'R21C',\n",
       "        'R21E', 'R21G', 'R21H', 'R21I', 'R21K', 'R21L', 'R21M', 'R21P',\n",
       "        'R21Q', 'R21S', 'R21T', 'R21V', 'R21W', 'G22A', 'G22C', 'G22D',\n",
       "        'G22E', 'G22I', 'G22K', 'G22L', 'G22Q', 'G22R', 'G22S', 'G22V',\n",
       "        'G22W', 'D23A', 'D23C', 'D23E', 'D23F', 'D23G', 'D23H', 'D23I',\n",
       "        'D23K', 'D23L', 'D23N', 'D23S', 'D23V', 'D23Y', 'F24A', 'F24C',\n",
       "        'F24D', 'F24G', 'F24H', 'F24I', 'F24L', 'F24M', 'F24N', 'F24P',\n",
       "        'F24R', 'F24S', 'F24T', 'F24V', 'F24W', 'F24Y', 'I25A', 'I25D',\n",
       "        'I25F', 'I25H', 'I25K', 'I25L', 'I25M', 'I25N', 'I25P', 'I25R',\n",
       "        'I25S', 'I25T', 'I25V', 'I25Y', 'H26A', 'H26C', 'H26D', 'H26E',\n",
       "        'H26F', 'H26G', 'H26I', 'H26K', 'H26L', 'H26N', 'H26P', 'H26Q',\n",
       "        'H26R', 'H26S', 'H26T', 'H26V', 'H26Y', 'V27A', 'V27C', 'V27D',\n",
       "        'V27E', 'V27F', 'V27G', 'V27H', 'V27I', 'V27L', 'V27M', 'V27N',\n",
       "        'V27S', 'V27T', 'V27Y', 'M28A', 'M28E', 'M28F', 'M28G', 'M28I',\n",
       "        'M28K', 'M28L', 'M28N', 'M28P', 'M28Q', 'M28R', 'M28S', 'M28T',\n",
       "        'M28V', 'M28W', 'M28Y', 'D29A', 'D29C', 'D29E', 'D29F', 'D29G',\n",
       "        'D29H', 'D29I', 'D29K', 'D29L', 'D29N', 'D29P', 'D29S', 'D29V',\n",
       "        'D29Y', 'N30A', 'N30C', 'N30D', 'N30E', 'N30F', 'N30G', 'N30H',\n",
       "        'N30I', 'N30K', 'N30M', 'N30R', 'N30S', 'N30T', 'N30V', 'N30Y',\n",
       "        'S31A', 'S31E', 'S31F', 'S31I', 'S31K', 'S31L', 'S31P', 'S31Q',\n",
       "        'S31R', 'S31T', 'S31V', 'S31W', 'S31Y', 'D32A', 'D32C', 'D32E',\n",
       "        'D32F', 'D32G', 'D32H', 'D32I', 'D32K', 'D32N', 'D32S', 'D32T',\n",
       "        'D32V', 'D32Y', 'P33A', 'P33C', 'P33D', 'P33F', 'P33G', 'P33H',\n",
       "        'P33I', 'P33K', 'P33L', 'P33N', 'P33Q', 'P33R', 'P33S', 'P33T',\n",
       "        'P33V', 'P33Y', 'N34A', 'N34C', 'N34D', 'N34E', 'N34F', 'N34G',\n",
       "        'N34H', 'N34I', 'N34K', 'N34L', 'N34Q', 'N34R', 'N34S', 'N34T',\n",
       "        'N34V', 'N34Y', 'W35A', 'W35C', 'W35E', 'W35F', 'W35G', 'W35K',\n",
       "        'W35L', 'W35M', 'W35Q', 'W35R', 'W35S', 'W35T', 'W35V', 'W35Y',\n",
       "        'W36C', 'W36F', 'W36G', 'W36K', 'W36L', 'W36M', 'W36Q', 'W36R',\n",
       "        'W36S', 'W36T', 'W36V', 'W36Y', 'K37D', 'K37E', 'K37G', 'K37I',\n",
       "        'K37L', 'K37M', 'K37N', 'K37Q', 'K37R', 'K37S', 'K37T', 'K37V',\n",
       "        'K37Y', 'G38A', 'G38C', 'G38D', 'G38E', 'G38I', 'G38K', 'G38L',\n",
       "        'G38Q', 'G38R', 'G38S', 'G38T', 'G38V', 'G38W', 'A39C', 'A39D',\n",
       "        'A39E', 'A39F', 'A39G', 'A39I', 'A39N', 'A39P', 'A39S', 'A39T',\n",
       "        'A39V', 'A39Y', 'C40F', 'C40G', 'C40H', 'C40I', 'C40L', 'C40N',\n",
       "        'C40R', 'C40S', 'C40W', 'C40Y', 'H41C', 'H41D', 'H41E', 'H41F',\n",
       "        'H41G', 'H41I', 'H41K', 'H41L', 'H41N', 'H41P', 'H41Q', 'H41R',\n",
       "        'H41S', 'H41T', 'H41V', 'H41Y', 'G42A', 'G42C', 'G42D', 'G42E',\n",
       "        'G42F', 'G42K', 'G42L', 'G42M', 'G42Q', 'G42R', 'G42S', 'G42T',\n",
       "        'G42V', 'G42W', 'Q43D', 'Q43E', 'Q43H', 'Q43K', 'Q43L', 'Q43M',\n",
       "        'Q43N', 'Q43P', 'Q43R', 'Q43V', 'Q43W', 'Q43Y', 'T44A', 'T44C',\n",
       "        'T44D', 'T44F', 'T44G', 'T44I', 'T44K', 'T44M', 'T44N', 'T44P',\n",
       "        'T44R', 'T44S', 'T44V', 'T44Y', 'G45A', 'G45C', 'G45D', 'G45E',\n",
       "        'G45F', 'G45H', 'G45I', 'G45L', 'G45N', 'G45P', 'G45R', 'G45S',\n",
       "        'G45T', 'G45V', 'G45W', 'G45Y', 'M46A', 'M46E', 'M46F', 'M46I',\n",
       "        'M46K', 'M46L', 'M46N', 'M46R', 'M46S', 'M46T', 'M46V', 'M46W',\n",
       "        'F47C', 'F47D', 'F47H', 'F47I', 'F47L', 'F47N', 'F47P', 'F47S',\n",
       "        'F47T', 'F47V', 'F47Y', 'P48A', 'P48F', 'P48H', 'P48I', 'P48L',\n",
       "        'P48N', 'P48Q', 'P48R', 'P48S', 'P48T', 'P48Y', 'R49A', 'R49C',\n",
       "        'R49D', 'R49F', 'R49G', 'R49H', 'R49I', 'R49L', 'R49N', 'R49P',\n",
       "        'R49Q', 'R49S', 'R49T', 'R49W', 'R49Y', 'N50C', 'N50D', 'N50E',\n",
       "        'N50F', 'N50G', 'N50H', 'N50I', 'N50K', 'N50L', 'N50M', 'N50Q',\n",
       "        'N50R', 'N50S', 'N50T', 'N50V', 'N50Y', 'Y51C', 'Y51D', 'Y51F',\n",
       "        'Y51H', 'Y51I', 'Y51K', 'Y51L', 'Y51N', 'Y51Q', 'Y51R', 'Y51S',\n",
       "        'Y51T', 'Y51V', 'Y51W', 'V52A', 'V52C', 'V52D', 'V52E', 'V52F',\n",
       "        'V52G', 'V52I', 'V52L', 'V52M', 'V52N', 'V52P', 'V52S', 'V52T',\n",
       "        'V52Y', 'T53A', 'T53D', 'T53F', 'T53G', 'T53I', 'T53K', 'T53M',\n",
       "        'T53N', 'T53P', 'T53R', 'T53S', 'T53V', 'T53Y', 'P54A', 'P54D',\n",
       "        'P54F', 'P54H', 'P54I', 'P54L', 'P54N', 'P54Q', 'P54R', 'P54S',\n",
       "        'P54T', 'P54V', 'P54Y', 'V55A', 'V55D', 'V55E', 'V55F', 'V55G',\n",
       "        'V55I', 'V55K', 'V55L', 'V55M', 'V55P', 'V55Q', 'V55R', 'V55S',\n",
       "        'V55T', 'N56C', 'N56D', 'N56E', 'N56F', 'N56G', 'N56H', 'N56I',\n",
       "        'N56K', 'N56M', 'N56Q', 'N56R', 'N56S', 'N56T', 'N56V', 'N56Y'],\n",
       "       dtype='<U4')}"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data_jax[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a707a31",
   "metadata": {},
   "source": [
    "# Shuffle Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "42a7ec01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_weights(rng, params):\n",
    "    def _shuffle_array(rng, arr):\n",
    "        flat_arr = arr.ravel()\n",
    "        shuffled_flat_arr = jax.random.permutation(rng, flat_arr)\n",
    "        return jnp.reshape(shuffled_flat_arr, arr.shape)\n",
    "    \n",
    "    leaves, _ = jax.tree_util.tree_flatten(params)\n",
    "    rngs = jax.random.split(rng, len(leaves))\n",
    "    new_params = jax.tree_util.tree_map(_shuffle_array, rngs, params)\n",
    "    return new_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209e6f09",
   "metadata": {},
   "source": [
    "# Create model Jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "8f552bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_fn(number_additive_traits, l1, l2, rng):\n",
    "\n",
    "    def model_fn(inputs_select, inputs_folding, inputs_binding):\n",
    "\n",
    "        input_layer_select_folding = jnp.expand_dims(inputs_select[:, 0], -1)\n",
    "        input_layer_select_binding = jnp.expand_dims(inputs_select[:, 1], -1)\n",
    "\n",
    "        folding_additive_trait_layer = hk.Linear(number_additive_traits,\n",
    "                                                 w_init=hk.initializers.VarianceScaling(1.0, \"fan_avg\",\n",
    "                                                                                        \"truncated_normal\"),\n",
    "                                                 with_bias=False\n",
    "                                                 )(inputs_folding)\n",
    "\n",
    "        folding_nonlinear_layer = StateProbFolded()(folding_additive_trait_layer)\n",
    "\n",
    "        folding_additive_layer = hk.Linear(number_additive_traits,\n",
    "                                           w_init=hk.initializers.VarianceScaling(1.0, \"fan_avg\", \"truncated_normal\"),\n",
    "                                           with_bias=False  # ,\n",
    "                                           # kernel_regularizer=hk.regularizers.L1L2(l1=l1, l2=l2)\n",
    "                                           )(folding_nonlinear_layer)\n",
    "\n",
    "        # binding\n",
    "        binding_additive_trait_layer = hk.Linear(number_additive_traits,\n",
    "                                                 w_init=hk.initializers.VarianceScaling(1.0, \"fan_avg\",\n",
    "                                                                                        \"truncated_normal\"),\n",
    "                                                 with_bias=False\n",
    "                                                 )(inputs_binding)\n",
    "\n",
    "        binding_nonlinear_layer = StateProbBound()(binding_additive_trait_layer, folding_additive_trait_layer)\n",
    "\n",
    "        binding_additive_layer = hk.Linear(number_additive_traits,\n",
    "                                           w_init=hk.initializers.VarianceScaling(1.0, \"fan_avg\", \"truncated_normal\"),\n",
    "                                           with_bias=False\n",
    "                                           )(binding_nonlinear_layer)\n",
    "\n",
    "        # output\n",
    "        multiplicative_layer_folding = folding_additive_layer * input_layer_select_folding\n",
    "        multiplicative_layer_binding = binding_additive_layer * input_layer_select_binding\n",
    "        output_layer = multiplicative_layer_folding + multiplicative_layer_binding\n",
    "\n",
    "        return output_layer\n",
    "\n",
    "    return model_fn\n",
    "\n",
    "\n",
    "def create_model_jax(rng, learn_rate, l1, l2, input_dim_select, input_dim_folding, input_dim_binding,\n",
    "                     number_additive_traits):\n",
    "    # Create model\n",
    "    model_fn = create_model_fn(number_additive_traits, l1, l2, rng)\n",
    "    model = hk.without_apply_rng(hk.transform(model_fn))\n",
    "\n",
    "    # Create optimizer\n",
    "    opt = optax.chain(\n",
    "        optax.adam(learn_rate),\n",
    "        constrained_gradients(['folding_additive', 'binding_additive'], 0, 1e3),\n",
    "    )\n",
    "\n",
    "    # Create regularizer\n",
    "    # regularizer = hk.regularizers.L1L2(l1=l1, l2=l2)\n",
    "\n",
    "    return model, opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb34634",
   "metadata": {},
   "source": [
    "# Grid Search Jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "2f942d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(input_data, batch_size, rng):\n",
    "    \"\"\"Generate batches for training.\n",
    "\n",
    "    Args:\n",
    "        input_data: A dictionary of NumPy arrays containing the input data.\n",
    "        batch_size: The batch size.\n",
    "        rng: A JAX PRNGKey.\n",
    "\n",
    "    Yields:\n",
    "        A tuple of (select, fold, bind, target) batches.\n",
    "    \"\"\"\n",
    "    num_samples = input_data['select'].shape[0]\n",
    "    indices = jnp.arange(num_samples)\n",
    "\n",
    "    # Shuffle the training data.\n",
    "    rng, _ = jax.random.split(rng)\n",
    "    indices = jax.random.permutation(rng, indices)\n",
    "\n",
    "    # Generate batches.\n",
    "    for start_idx in range(0, num_samples, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, num_samples)\n",
    "        batch_indices = indices[start_idx:end_idx]\n",
    "\n",
    "        batch_select = input_data['select'][batch_indices]\n",
    "        batch_fold = input_data['fold'][batch_indices]\n",
    "        batch_bind = input_data['bind'][batch_indices]\n",
    "        batch_target = input_data['target'][batch_indices]\n",
    "\n",
    "        yield batch_select, batch_fold, batch_bind, batch_target\n",
    "        \n",
    "def fit_model_grid_jax(param_dict, input_data, n_epochs, rng):\n",
    "    # Summarize results\n",
    "    print(\"Grid search using %s\" % (param_dict))\n",
    "\n",
    "    rng_init, rng_batches = jax.random.split(rng)\n",
    "\n",
    "    # Create model\n",
    "    model, optimizer = create_model_jax(\n",
    "        rng=rng_init,\n",
    "        learn_rate=param_dict['learning_rate'],\n",
    "        l1=param_dict['l1_regularization_factor'],\n",
    "        l2=param_dict['l2_regularization_factor'],\n",
    "        input_dim_select=input_data['train']['select'].shape[1],\n",
    "        input_dim_folding=input_data['train']['fold'].shape[1],\n",
    "        input_dim_binding=input_data['train']['bind'].shape[1],\n",
    "        number_additive_traits=param_dict['number_additive_traits'])\n",
    "\n",
    "    @jax.jit\n",
    "    def loss_fn(params, inputs_select, inputs_folding, inputs_binding, target):\n",
    "        output = model.apply(params, inputs_select, inputs_folding, inputs_binding)\n",
    "        loss = jnp.mean(jnp.abs(output - target))\n",
    "\n",
    "        # Apply L1 and L2 regularization\n",
    "        l1_loss = 0\n",
    "        l2_loss = 0\n",
    "        for p in jax.tree_util.tree_leaves(params):\n",
    "            if p.ndim > 1:  # exclude bias parameters\n",
    "                l1_loss += jnp.sum(jnp.abs(p))\n",
    "                l2_loss += jnp.sum(jnp.square(p))\n",
    "        loss = loss + param_dict['l1_regularization_factor'] * l1_loss + param_dict[\n",
    "            'l2_regularization_factor'] * l2_loss\n",
    "\n",
    "        return loss\n",
    "\n",
    "    @jax.jit\n",
    "    def update(params, opt_state, inputs_select, inputs_folding, inputs_binding, target):\n",
    "        grads = jax.grad(loss_fn)(params, inputs_select, inputs_folding, inputs_binding, target)\n",
    "        updates, new_opt_state = optimizer.update(grads, opt_state)\n",
    "        # print('update done')\n",
    "        new_params = optax.apply_updates(params, updates)\n",
    "        return new_params, new_opt_state\n",
    "\n",
    "    params = model.init(rng, input_data['train']['select'], input_data['train']['fold'], input_data['train']['bind'])\n",
    "    opt_state = optimizer.init(params)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_data in generate_batches(input_data['train'], param_dict['num_samples'], rng_batches):\n",
    "            inputs_select, inputs_folding, inputs_binding, target = batch_data\n",
    "            params, opt_state = update(params, opt_state, inputs_select, inputs_folding, inputs_binding, target)\n",
    "        val_loss = loss_fn(params, input_data['valid']['select'], input_data['valid']['fold'],\n",
    "                           input_data['valid']['bind'], input_data['valid']['target'])\n",
    "        print('epoch done')\n",
    "\n",
    "    return val_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "9b0bdd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import fit_model_grid_jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "1fb8cb39",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search using {'num_samples': 128, 'learning_rate': 0.0001, 'l1_regularization_factor': 0.0001, 'l2_regularization_factor': 0.0001, 'number_additive_traits': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierredemetz/miniconda3/envs/pierre/lib/python3.8/site-packages/haiku/_src/data_structures.py:143: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.\n",
      "  leaves, treedef = jax.tree_flatten(tree)\n",
      "/Users/pierredemetz/miniconda3/envs/pierre/lib/python3.8/site-packages/haiku/_src/data_structures.py:144: FutureWarning: jax.tree_unflatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_unflatten instead.\n",
      "  return jax.tree_unflatten(treedef, leaves)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "Grid search using {'num_samples': 128, 'learning_rate': 0.0001, 'l1_regularization_factor': 0.0001, 'l2_regularization_factor': 0.001, 'number_additive_traits': 1}\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "Grid search using {'num_samples': 128, 'learning_rate': 0.0001, 'l1_regularization_factor': 0.0001, 'l2_regularization_factor': 0.01, 'number_additive_traits': 1}\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "Best: 0.427219 using {'num_samples': 128, 'learning_rate': 0.0001, 'l1_regularization_factor': 0.0001, 'l2_regularization_factor': 0.01, 'number_additive_traits': 1}\n"
     ]
    }
   ],
   "source": [
    "#Fit model\n",
    "if len(l1) == 1 and len(l2) == 1 and len(batch_size) == 1 and len(learn_rate) == 1:\n",
    "    best_params = {\n",
    "        \"num_samples\": batch_size[0],\n",
    "        \"learning_rate\": learn_rate[0],\n",
    "        \"l1_regularization_factor\": l1[0],\n",
    "        \"l2_regularization_factor\": l2[0],\n",
    "        \"number_additive_traits\": 1\n",
    "    }\n",
    "else:\n",
    "    parameter_grid = [{\n",
    "        \"num_samples\": i,\n",
    "        \"learning_rate\": j,\n",
    "        \"l1_regularization_factor\": k,\n",
    "        \"l2_regularization_factor\": l,\n",
    "        \"number_additive_traits\": 1\n",
    "    } for i in batch_size for j in learn_rate for k in l1 for l in l2]\n",
    "\n",
    "    rng = jax.random.PRNGKey(random_seed)\n",
    "    rngs = jax.random.split(rng, len(parameter_grid[:3]))\n",
    "    #print(len(parameter_grid))\n",
    "    grid_results = [fit_model_grid_jax(params, model_data_jax, num_epochs_grid, rng_key) for params, rng_key in zip(parameter_grid, rngs)]\n",
    "\n",
    "    best_params = parameter_grid[np.argmin(grid_results)]\n",
    "\n",
    "    print(\"Best: %f using %s\" % (min(grid_results), best_params))\n",
    "\n",
    "num_samples = best_params['num_samples']\n",
    "learning_rate = best_params['learning_rate']\n",
    "l1_regularization_factor = best_params['l1_regularization_factor']\n",
    "l2_regularization_factor = best_params['l2_regularization_factor']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0583e3ad",
   "metadata": {},
   "source": [
    "# Fitting final model and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "717174a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Output model directory already exists.\n",
      "Warning: Output plot directory already exists.\n"
     ]
    }
   ],
   "source": [
    "#Output model directory\n",
    "model_directory = os.path.join(output_directory, \"whole_model\")\n",
    "#Create output model directory\n",
    "try:\n",
    "  os.mkdir(model_directory)\n",
    "except FileExistsError:\n",
    "  print(\"Warning: Output model directory already exists.\")\n",
    "\n",
    "#Output plot directory\n",
    "plot_directory = os.path.join(output_directory, \"plots\")\n",
    "#Create output plot directory\n",
    "try:\n",
    "  os.mkdir(plot_directory)\n",
    "except FileExistsError:\n",
    "  print(\"Warning: Output plot directory already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "624b32b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import model_training, shuffle_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "7ad9b7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search using {'num_samples': 128, 'learning_rate': 0.0001, 'l1_regularization_factor': 0.0001, 'l2_regularization_factor': 0.01, 'number_additive_traits': 1}\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "epoch done\n",
      "[0.6976140141487122, 0.6637396812438965, 0.6319745779037476, 0.602327823638916, 0.5750360488891602, 0.5503971576690674, 0.5282517671585083, 0.5083247423171997, 0.48985135555267334, 0.47273972630500793]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAHgCAYAAADT1NXlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAABLG0lEQVR4nO3dd5hU5fnG8e+zfem9d8FCF5ZqiTUxiQo2FBGWJmJLjDFR00yiSTTGEmNFOmI3Kmk2YomowCJFLBRRFKRKZ4Fdluf3xxx+WcmWgd2Zsztzf67rXDvlzMzNXolz7znveV9zd0RERCS5pIQdQEREROJPBUBERCQJqQCIiIgkIRUAERGRJKQCICIikoRUAERERJJQWtgB4qlRo0berl27sGOIiIjExYIFCza7e+OSnkuqAtCuXTvy8vLCjiEiIhIXZra6tOd0CkBERCQJqQCIiIgkIRUAERGRJKQCICIikoRCKQBm1sDMXjWzFcHP+iXs09bM3jezRWb2oZmNL/bcG2a2LHhukZk1ie+/QEREpHoL6wjATcBsd+8EzA7uH2odMMDdewL9gJvMrEWx54e5e89g2xjzxCIiIgkkrAIwCJgW3J4GDD50B3cvcPd9wd1MdLpCRESk0oT1pdrU3dcFt9cDTUvaycxam9kS4EvgDnf/qtjTU4LD/780Myvtg8xsnJnlmVnepk2bKu0fICIiUp3FrACY2WtmtrSEbVDx/dzdAS/pPdz9S3fvDnQEcs3sYFEY5u7dgJOCbXhpOdx9grvnuHtO48YlToYkIiKSdGI2E6C7n1Hac2a2wcyau/s6M2sOlHkO392/MrOlRL7sn3X3tcHjO83scaAvML0S44uIiCS0sE4BzAJyg9u5wIuH7mBmrcwsO7hdHzgRWGZmaWbWKHg8HTgbWBqX1CIiIgkirAJwO3Cmma0AzgjuY2Y5ZjYx2Oc4YK6ZLQbeBP7k7h8QGRD4cjA2YBGwFng0zvlFRESqNYucgk8OOTk5rsWAREQkWZjZAnfPKek5XVonIiKShFQAREREkpAKgIiISBJSAThC+/YX8dW2PWHHEBEROSIqAEfo+qcWc8mE99i0c1/5O4uIiFQxKgBH6PKTO7Bp5z5GT53P7n37w44jIiJyWFQAjlDP1vV4cFgvPlq3gytnvk9h0YGwI4mIiERNBaACTj22CX84rxtvLd/ETc99QDLNqSAiItVbzNYCSBZD+rRm/Y693P3qcprVzeQn3zk27EgiIiLlUgGoBNee1pF12/fywOuf0qxOFsMHtAs7koiISJlUACqBmXHroC5s2rmXX836kMa1szira7OwY4mIiJRKYwAqSVpqCn8Z2ouerevxwycXkvf5lrAjiYiIlEoFoBJlZ6QyKbcPLetlM2ZaHis37gw7koiISIlUACpZg5oZTBvdl/TUFHInz2fDjr1hRxIREfkfKgAx0LpBDaaO6sO2/AJyJ89jx97CsCOJiIh8gwpAjHRtWZeHh/dm5cZdjJ+xgIL9mihIRESqDhWAGDqpU2P+eGF33vn0a254ZjEHDmiiIBERqRp0GWCMnd+rFRt27OOOlz6hWd0sfva948KOJCIiogIQD+O/1YH12/cw4a1VNK2TxZgT24cdSUREkpwKQByYGb86pwsbd+7jtn98RNM6mZzdvUXYsUREJIlpDECcpKYY91zckz5tG3D9U4t599Ovw44kIiJJTAUgjrLSU3l0RA5tG9Zg3Iw8Plm/I+xIIiKSpFQA4qxujXSmju5LjYxURk6ez1fb9oQdSUREkpAKQAha1stm6qi+7N63n9zJ89ier4mCREQkvlQAQnJc8zo8MqI3q7/O5/LpeewtLAo7koiIJBEVgBANPKoRdw3pwbzPt3D904so0kRBIiISJ7oMMGTn9GjBhh17ue0fH9Ok9kfcck5nzCzsWCIikuBUAKqAsSd1YP32vUx8+zOa1c1i/LeOCjuSiIgkOBWAKuJn3zuODTv3cfu/PqFpnUzOO75V2JFERCSBqQBUESkpxp8u6s7mnfv4yTNLaFQrk5M6NQ47loiIJCgNAqxCMtNSeWREbzo2qcX4GQtYunZ72JFERCRBqQBUMXWy0pk6qi91s9MZNXU+X27JDzuSiIgkIBWAKqhZ3Symje5Lwf4D5E6ex5bdBWFHEhGRBKMCUEV1alqbibk5rNm2h7HT5rOnQBMFiYhI5VEBqML6tGvAfZf0ZOGX27j2iYXsLzoQdiQREUkQKgBV3Fldm/Prc7rw2scb+NWsD3HXbIEiIlJxugywGsgd2I71O/by0Buf0rxOFtee3insSCIiUs2pAFQTP/3OMWzYvpe7Xl1O07pZDMlpHXYkERGpxlQAqgkz444Lu7Np1z5u/usHNK6VyanHNgk7loiIVFMaA1CNpKem8NBlvTm2WW2umvk+i7/cFnYkERGpplQAqplamWlMGdWHhrUyGD11Pp9v3h12JBERqYZUAKqhJrWzmD66LwfcyZ0yj8279oUdSUREqpnQCoCZNTCzV81sRfCzfhn71jGzNWZ2f7HHepvZB2a20szuMzOLT/KqoUPjWkwa2YcNO/Yyeup8du/bH3YkERGpRsI8AnATMNvdOwGzg/uluRV465DHHgIuBzoF21mxCFmV9WpTn/uH9mLp2u1c/fj7FGqiIBERiVKYBWAQMC24PQ0YXNJOZtYbaAq8Uuyx5kAdd3/PIzPjTC/t9YnujM5NuW1wN95Ytomf/fUDTRQkIiJRCfMywKbuvi64vZ7Il/w3mFkKcBdwGXBGsadaAmuK3V8TPPY/zGwcMA6gTZs2FU9dBV3arw3rd+zlvtkraF43i+u/fUzYkUREpIqLaQEws9eAZiU89fPid9zdzaykP12vAv7p7muO9BS/u08AJgDk5OQk7J/HPzqjExu27+W+f6+kad0shvVrG3YkERGpwmJaANz9jNKeM7MNZtbc3dcFh/Q3lrDbAOAkM7sKqAVkmNku4M9Aq2L7tQLWVmL0asfM+N15Xdm4cy+/fGEpjWtl8u0uJXUvERGRcMcAzAJyg9u5wIuH7uDuw9y9jbu3A24Aprv7TcGpgx1m1j8Y/T+ipNcnm7TUFB4Y1otuLety7RMLWbB6a9iRRESkigqzANwOnGlmK4ic378dwMxyzGxiFK+/CpgIrAQ+Bf4Vq6DVSY2MNCaN7EPzulmMmTafTzftCjuSiIhUQZZMo8ZzcnI8Ly8v7Bhxsfrr3Vzw0DtkpqXy/FUDaVInK+xIIiISZ2a2wN1zSnpOMwEmqLYNazJ5ZB+25hcwcsp8du4tDDuSiIhUISoACax7q3o8OKwXyzbs5MrH3qdgvyYKEhGRCBWABHfKMU24/fxuvL1yMz99djEHDiTPKR8RESldmBMBSZxclNOaDTv28qdXltO0ThY3f++4sCOJiEjIVACSxNWndmT9jr088tYqmtTJYsyJ7cOOJCIiIVIBSBJmxm/O7crmnQXc+vePaFQrg0E9S5w9WUREkoDGACSR1BTj3kt60rd9A254ZjFvLd8UdiQREQmJCkCSyUpP5dERORzVuBbjH1vAkjXbwo4kIiIhUAFIQnWz05k2ui/1a2Qwasp8Ptu8O+xIIiISZyoASappnSxmjOmLAyMmz2Xjjr1hRxIRkThSAUhiHRrXYvLIPny9q4DcKfPZodkCRUSShgpAkuvZuh4PXdabFRt2Mm56HnsLi8KOJCIicaACIHzr6Mb86aIevLdqC9c/vYgizRYoIpLwNA+AADD4+JZs3rWP2/7xMQ1rfshvB3XBzMKOJSIiMaICIP9v7Ekd2LRzX2S2wNqZXHt6p7AjiYhIjKgAyDfceNaxbNq5j7teXU6j2pkM7dsm7EgiIhIDKgDyDSkpxh0XdmdLfgE/f/4DGtTM4DtdmoUdS0REKpkGAcr/SE9N4cFhvejWqh4/eGIh8z7bEnYkERGpZCoAUqIaGWlMGdmHlvWzGTttPp+s3xF2JBERqUQqAFKqBjUzmD66L9kZqeROnsearflhRxIRkUqiAiBlalW/BtNG9yW/oIgRk+exZXdB2JFERKQSqABIuY5tVodJuX1Ys3UPo6fOJ79gf9iRRESkglQAJCp92zfgL0OPZ8mabVw1830Kiw6EHUlERCpABUCi9p0uzbhtcDfeWLaJG59bgrumDBYRqa40D4Aclkv7tWHzrn3c/epyGtfO5ObvHhd2JBEROQIqAHLYrj2tY2TK4DdX0bhWJmNP6hB2JBEROUwqAHLYzIxfn9vl/xcPalQrk8HHtww7loiIHAaNAZAjkppi3HNxT/p3aMANzyzmreWbwo4kIiKHQQVAjlhWeioTRuTQqWltxj+2gMVfbgs7koiIREkFQCqkTlY600b1oUHNDEZNnc+qTbvCjiQiIlFQAZAKa1Inixlj+mHAiMnz2Lhjb9iRRESkHCoAUinaN6rJlFF92LK7gNwp89mxtzDsSCIiUgYVAKk03VvV4+HLerNiw07GTc9jb2FR2JFERKQUKgBSqU4+ujF3DenBe6u28KOnFlF0QLMFiohURSoAUukG9WzJL8/uzL+WrueWWUs1ZbCISBWkiYAkJsac2J6NO/fyyJuraFI7ix+c3insSCIiUowKgMTMTWcdy+adBdz96nIa1crk0n5two4kIiIBFQCJGTPj9gu6sWX3Pn7xwgc0rJXBd7o0CzuWiIigMQASY+mpKTwwrBfdW9Xj2icWMnfV12FHEhERVAAkDmpkpDFlZB9a189m7PQ8Plm/I+xIIiJJTwVA4qJ+zQymj+lHzYw0cifPY83W/LAjiYgktVAKgJk1MLNXzWxF8LN+GfvWMbM1ZnZ/scfeMLNlZrYo2JrEJ7lURMt62Uwb3Zc9BUWMmDyPLbsLwo4kIpK0wjoCcBMw2907AbOD+6W5FXirhMeHuXvPYNsYi5BS+Y5pVpuJuX1Yu3UPo6bOJ79gf9iRRESSUlgFYBAwLbg9DRhc0k5m1htoCrwSn1gSD33bN+AvQ4/ngzXbuPKx9yksOhB2JBGRpBNWAWjq7uuC2+uJfMl/g5mlAHcBN5TyHlOCw/+/NDOLUU6JkW93acbvz+vGm8s3ceOzSzigKYNFROIqZvMAmNlrQEkXff+8+B13dzMr6b/+VwH/dPc1JXy/D3P3tWZWG3gOGA5MLyXHOGAcQJs2moimKrmkbxs27dzHXa8up3HtTG7+3nFhRxIRSRpRF4BgoF3Wwfvu/kVZ+7v7GWW81wYza+7u68ysOVDSOfwBwElmdhVQC8gws13ufpO7rw0+Y6eZPQ70pZQC4O4TgAkAOTk5+jOzirnmtI5s2rWPR95aRaNamVx+coewI4mIJIVyTwGY2blmtgL4DHgT+Bz4VwU/dxaQG9zOBV48dAd3H+bubdy9HZHTANPd/SYzSzOzRkG2dOBsYGkF80hIzIxbzunC97s153f//JjnF64JO5KISFKIZgzArUB/YLm7twdOB96r4OfeDpwZFIszgvuYWY6ZTSzntZnAy2a2BFgErAUerWAeCVFqinH3xT0Y0KEhP3lmCW8u3xR2JBGRhGflLdVqZnnunmNmi4Hj3f2AmS129x7xiVh5cnJyPC8vL+wYUoodewu55JH3+Pzr3Tx+eX96tq4XdiQRkWrNzBa4e05Jz0VzBGCbmdUici3+TDP7M7C7MgOKANTJSmfq6D40rJXB6KnzWbVpV9iRREQSVjQFYBCQD/wIeAn4lMh5d5FK16R2FjNG98OA4ZPmsWHH3rAjiYgkpGgKwK/c/YC773f3ae5+H3BjrINJ8mrXqCZTR/VlW34BuZPnsX1PYdiRREQSTjQF4MwSHvtuZQcRKa5bq7o8PLw3n27axeXT89hbWBR2JBGRhFJqATCzK83sA+AYM1tSbPsMWBK/iJKsTurUmLuG9GT+51u45vGF7NeUwSIilaasiYAeJ3K9/x/45mI9O919S0xTiQTO7dGCbfkF/OrFD7nxuQ+488LupKRo5mcRkYoqtQC4+3ZgOzAUvjETYC0zq1XeTIAilWXEgHZs3V3IPa8tp36NdH7+/ePQ8g8iIhVT7lTAZnYOcDfQgsiUvW2Bj4EusY0m8l8/OL0jW/MLmPj2Z9SvmcHVp3YMO5KISLUWzVoAtxGZCfA1dz/ezE4FLottLJFvMjN+dXZntuUXcOfLy6hXI51h/dqGHUtEpNqKpgAUuvvXZpZiZinu/rqZ3RvrYCKHSkkx7ryoBzv27ucXLyylXnYG3+/ePOxYIiLVkmYClGolPTWFBy7tRU7b+lz31EL+s0LrBoiIHIloZwLcwzdnAjwnlqFEypKdkcrE3D50bFKbK2YsYOEXW8OOJCJS7ZRbANx9t7sXFZ8J0N2/jkc4kdLUzU5n2ug+NK6dyaip81m+YWfYkUREqpWyJgLaaWY7StviGVKkJE1qZ/HYmH5kpKYwfNJcvtySH3YkEZFqo9QC4O613b0O8GciEwG1BFoRWQfg3rikEylH6wY1mDGmH3sKihg+aS6bdu4LO5KISLUQzRiAc939QXff6e473P0hIuMCRKqEY5rVZsqovmzYsY/cyfPYsVeLB4mIlCeaArDbzIaZWWpwKeAwdBWAVDG929bn4eG9WbFxJ2OnafEgEZHyRFMALgWGABuC7aLgMZEq5VtHF1886H0KtXiQiEipyp0IyN0/R4f8pZo4t0cLtu8p5JcvLOXGZ5fwp4t6aPEgEZESRDMToEi1Mrx/W7btLuCuV5dTr0YGvzxbiweJiBxKBUAS0jWndWRLfgGT53xGg5rpXHNap7AjiYhUKSoAkpDMjF9+vzPb8wv50yuRIwGX9dfiQSIiB0WzHPD1JTy8HVjg7osqPZFIJUlJMe64sDs79hbyyxeXUjc7nXN6tAg7lohIlRDNVQA5wHgiEwG1BK4AzgIeNbOfxjCbSIWlp6Zw/6W96NO2Adc/vYg3l2vxIBERiK4AtAJ6ufuP3f3HQG+gCXAyMDKG2UQqRVZ6KhNH5tCpSW3Gz1jAgtVaPEhEJJoC0AQoPr9qIdDU3fcc8rhIlVUnK51po/vStE4mo6fOZ9l6LR4kIsktmgIwE5hrZreY2S3AHOBxM6sJfBTTdCKVqHHtTGaM6UdWuhYPEhGJZjngW4mc998WbOPd/bfBMsHDYhtPpHIdXDxo3/4DXKbFg0QkiUVzBADgfeAZ4Hlgo5m1iV0kkdg6umltpozqw6ad+xgxeR7b92jxIBFJPuUWADO7lsgaAK8Cfwf+EfwUqbZ6tanPw5f1ZuXGnYydNp89BVo8SESSSzRHAH4IHOPuXdy9u7t3c/fusQ4mEmsnH92Yey7uSd7qrVytxYNEJMlEUwC+JDLxj0jCObt7C24b3JV/f7KRnz67hAMHPOxIIiJxEc1UwKuAN8zsHxS77M/d745ZKpE4GtavLdvyC7nz5WXUzU7nlnM6a/EgEUl40RSAL4ItI9hEEs5VpxzFlt0FTHr7MxrUzOAHp2vxIBFJbOUWAHf/TTyCiITJzPj5945jW34hd7+6nPo10hk+oF3YsUREYqbUAmBm97r7dWb2N+B/Toy6+7kxTSYSZykpxh0XdGP7nkJ+NetD6mSnM6hny7BjiYjERFlHAGYEP/8UjyAiVUFaagr3X3o8uZPn8eOnF1M3O51TjmkSdiwRkUpX6lUA7r4guNnT3d8svgE945JOJARZ6ak8mpvDMc1qM/6xBSxYvSXsSCIilS6aywBzS3hsZCXnEKlSDi4e1LxuNqOmzOeT9TvCjiQiUqlKLQBmNjQ4/9/ezGYV294A9CeRJLxGtTKZMaYvNTLSGD5pHl98rcWDRCRxlHUE4B3gLuCT4OfB7XrgO7GPJhK+VvVrMGNMXwqLIosHbdy5N+xIIiKVoqwxAKvd/Q3gDOA/wbn/dUArQLOkSNLo1LQ2U0f1ZfOufYyYpMWDRCQxRDMG4C0gy8xaAq8Aw4GpFflQM2tgZq+a2YrgZ/1S9isys0XBNqvY4+3NbK6ZrTSzp8xMExRJTPVsXY8Jw3P4dNMuxkzV4kEiUv1FUwDM3fOB84EH3f0ioEsFP/cmYLa7dwJmB/dLssfdewZb8XkH7gDucfeOwFZgTAXziJTrxE6N+PMlx7Pgi61cNXOBFg8SkWotqgJgZgOAYUSWAgZIreDnDgKmBbenAYOjfaFFJmk/DXj2SF4vUhHf69ac35/XjdeXbeKGZxZr8SARqbaiWQvgOuBm4Hl3/9DMOgCvV/Bzm7r7uuD2eqBpKftlmVkesB+43d1fABoC29x9f7DPGkDTtUncDO3bhq35BfzxpWXUy07n1+d20eJBIlLtRLMWwJvAm2ZWI7i/CvhBea8zs9eAZiU89fND3t/NrLQ/o9q6+9qgdPzbzD7gMJcmNrNxwDiANm3aHM5LRUp15beOYuvuAh79z2fUr5nBdWccHXYkEZHDUm4BCA7/TwJqAW3MrAdwhbtfVdbr3P2MMt5zg5k1d/d1ZtYc2FjKe6wNfq4K5h84HngOqGdmacFRgFbA2jJyTAAmAOTk5Oh4rVQKM+NnweJB9762gvo1Msgd2C7sWCIiUYtmDMC9RK77/xrA3RcDJ1fwc2fx3xkGc4EXD93BzOqbWWZwuxFwAvCRuzuRUxAXlvV6kVgzM/5wfje+3bkpt8z6kBcXldpDRUSqnGgKAO7+5SEPVfQaqNuBM81sBZF5Bm4HMLMcM5sY7HMckGdmi4l84d/u7h8Fz90IXG9mK4mMCZhUwTwiRyQtNYX7hh5P/w4N+PHTi3n9kxIPZomIVDkW+YO6jB3MngXuBu4H+gE/BHLc/ZLYx6tcOTk5npeXF3YMSUA79xZy6aNzWbFxJzPG9KNPuwZhRxIRwcwWuHtOSc9FcwRgPHA1kZH2a4msBFjm+X+RZFM7K52po/rQom42o6fO5+N1WjxIRKq2aArAMe4+zN2bunsTd7+MyOF5ESmmYa1MZoztR63MyOJBn23eHXYkEZFSRVMA/hLlYyJJr2W9bGaM6csBd4Y9+h5rtmoFQRGpmspaDniAmf0YaGxm1xfbfk3FZwIUSVgdm9Rmxpi+7Nq3n2ET57Jhh1YQFJGqp6wjABlErv1PA2oX23bw30vwRKQEXVrUZdrovmzeuY9hE+fy9a59YUcSEfmGaK4CaOvuq+OUJ6Z0FYDE23urvmbklHl0aFSLJy7vT90a6WFHEpEkUqGrABLly18kDP07NOSR4Tms3LiL3Cnz2LVvf/kvEhGJg6gmAhKRI/etoxtz/6XH88Ha7YyZOp89BRWdR0tEpOJUAETi4NtdmnH3kB7M+3wLVzy2gH37VQJEJFzRLAbUGLgcaFd8f3cfHbtYIolnUM+W7Cs8wE+fW8K1jy/kgWG9SE9VBxeRcJRbAIgstPMf4DUqvgaASFIb0qc1ewqLuGXWh/z46cXcc3FPUlMs7FgikoSiKQA13P3GmCcRSRK5A9uRX1DEHS99QnZ6Kn84vxspKgEiEmfRFIC/m9n33P2fMU8jkiSuPOUo9hTs575/ryQ7I5VbzumMmUqAiMRPNAXgh8DPzKwAKAwec3evE7tYIonvR2ceTX5BERPf/ozsjFR++p1jVAJEJG7KLQDuXjseQUSSjZnx8+8fx57CIh5641NqpKdy7emdwo4lIkkimiMAmNm5wMnB3Tfc/e+xiySSPMyMWwd1ZU9hEXe9upzsjFTGntQh7FgikgSiuQzwdqAPMDN46IdmdoK73xzTZCJJIiXF+OMF3dlXeIDb/vEx2RmpDOvXNuxYIpLgojkC8D2gp7sfADCzacBCQAVApJKkpaZwz8U92VNYxC9eWEp2eirn92oVdiwRSWDRzkJSr9jtujHIIZL0MtJSeHBYLwYe1ZAbnlnMP5asCzuSiCSwaArAH4CFZjY1+Ot/AfC72MYSSU5Z6ak8OiKHXm3q88MnFzL74w1hRxKRBBXNaoBPAP2BvwLPAQPc/alYBxNJVjUy0pg8qg+dW9Thypnv8/aKzWFHEpEEFNUpAHdf5+6zgm19rEOJJLs6WelMG9WX9g1rcvn0POZ/viXsSCKSYLQSiUgVVb9mBo+N7UfzulmMmjKfJWu2hR1JRBKICoBIFda4diYzL+9HvRrpjJg8j0/W7wg7kogkiKgKgJnVN7MuZtbBzFQaROKoed1sHh/bn6y0VC6bOJdPN+0KO5KIJIBSv8zNrK6Z/czMPgDeAx4BngZWm9kzZnZqvEKKJLs2DWvw2Nh+uMOwR+fy5Zb8sCOJSDVX1l/zzwJfAie5+zHufqK757h7a+B2YJCZjYlLShGhY5NaPDa2H3sKi7h04nus274n7EgiUo2Zu4edIW5ycnI8Ly8v7BgiFbL4y20MmziXJnUyeWrcABrXzgw7kohUUWa2wN1zSnqurFMAlxW7fcIhz11TefFE5HD0aF2PySP78NW2PQyfNJdt+QVhRxKRaqisUwDXF7v9l0OeGx2DLCISpb7tG/DoiBxWbdpN7uR57NxbGHYkEalmyioAVsrtku6LSJyd1KkxDw7rxYdf7WD01PnkF+wPO5KIVCNlFQAv5XZJ90UkBGd0bsq9l/RkweqtjJu+gL2FRWFHEpFqoqzlgI81syVE/to/KrhNcL9DzJOJSFTO7t6CvYUHuOGZxVzz+Ps8dFlv0lM1XYeIlK2sAnBc3FKISIVc2LsVewr288sXP+S6pxZx3yXHk5qiM3UiUrpSC4C7ry7pcTM7ERgKXB2rUCJy+IYPaMeewiJ+/89PyEpL5c4Lu5OiEiAipSjrCMD/M7PjgUuBi4DPiCwNLCJVzLiTjyK/oIh7X1tBdkYKtw7qiplKgIj8r1ILgJkdTeQv/aHAZuApIhMHaQpgkSrsh6d3Yk9BEY+8tYoaGWnc/N1jVQJE5H+UdQTgE+A/wNnuvhLAzH4Ul1QicsTMjJu+eyx7CouY8NYqstNT+dGZR4cdS0SqmLIKwPnAJcDrZvYS8CS6/l+kWjAzfn1OF/ILivjz7BXUyEjlim8dFXYsEalCyhoE+ALwgpnVBAYB1wFNzOwh4Hl3fyUuCUXkiKSkGHdc0J29hUX84V+fkJ2RyogB7cKOJSJVRLkXC7v7bnd/3N3PAVoBC4EbY55MRCosNcW45+KenHFcU3714oc8nfdl2JFEpIooazGgBoduRE4BPEvkagARqQbSU1O4/9LjOalTI256bgmzFn8VdiQRqQLKGgOwGVgDHJxgvPj5f6cCswEGZeIpoB3wOTDE3beWsF8R8EFw9wt3Pzd4fCrwLWB78NxId190pHlEEl1WeioThueQO3keP3pqEVlpKXy7S7OwY4lIiMo6BXAfsBV4CcgFOrh7+2Cr6FTANwGz3b0TMDu4X5I97t4z2M495LmfFHtuUQXziCS87IxUJo3MoWvLulzz+ELeXL4p7EgiEqJSC4C7Xwf0BJ4BhgMLzeyPZta+Ej53EDAtuD0NGFwJ7yki5aidlc60UX3o0LgmV8zIY+6qr8OOJCIhKXMQoEe8DvwUeBgYBZxRCZ/b1N3XBbfXA01L2S/LzPLM7D0zG3zIc78zsyVmdo+ZZVZCJpGkUK9GBo+N7UfLetmMnjqfhV/8z9k3EUkCZQ0CrGlml5rZi8A/gVpAb3d/NJo3NrPXzGxpCdug4vu5u1P68sJt3T2HyDTE95rZwQuZbwaOBfoADSjjqgQzGxeUiLxNm3TIUwSgUa1MZo7tT8NameROnseHX20v/0UiklAs8v1bwhNmu4EVRCYAWsEhX9LufsTrAZjZMuAUd19nZs2BN9z9mHJeMxX4u7s/e8jjpwA3uPvZ5X1uTk6O5+XlHWlskYTz5ZZ8hjzyLvv2H+DpK/rTsUntsCOJSCUyswXBH9L/o6xTAM8Queb/GOBs4JxiW7lftuWYRWRgIcHPFw/dwczqHzy0b2aNgBOAj4L7zYOfRmT8wNIK5hFJSq0b1GDm2H6kmHHpo3P5bPPusCOJSJyUegQgph9q1hB4GmgDrCZyGeAWM8sBxrv7WDMbCDwCHCBSVO5190nB6/8NNCZyaeKi4DW7yvtcHQEQKdmy9TsZ+uh7pKcaj1/en6Ma1wo7kohUgrKOAJR1CuAy4HF3P1DK80cBzd397UpLGmMqACKlW7Z+J5c++h4pKcYTl/fT6QCRBHCkpwAaErn0b7KZXW1mQ8xshJn91szeBP4IbIhFYBGJv2Oa1ebJcf1xh0smzGX5hp1hRxKRGCprHoA/A72AJ4gcbj89uL8WGO7uF7j7irikFJG46NQ0UgLMYOiE9/hk/Y6wI4lIjIQyBiAsOgUgEp1PN+3i0kffo7DIeWxMPzq3qBN2JBE5Akd6CkBEktRRjWvx5LgBZKSmcOnE91i6VvMEiCQaFQARKVH7RjV56or+1EhPZdjEuXywRiVAJJGUWQDMLMXMhsQrjIhULW0b1uSpKwZQKzONYRPfY/GX28KOJCKVpLy1AA4QWQdARJJU6wY1eHJcf+rWSOeyiXO1doBIgojmFMBrZnaDmbU2swYHt5gnE5EqI1ICBlC/ZgbDJ81jweotYUcSkQqKpgBcDFwNvAUsCDYNpRdJMi3rZfPUFf1pVCuDEZPmMf9zlQCR6qzcAuDu7UvYOsQjnIhULc3rZvPkuAE0rZNF7uR5zF31ddiRROQIlVsAzCzdzH5gZs8G2zVmlh6PcCJS9TSrm8WT4/rTvG4WI6fM591PVQJEqqNoTgE8BPQGHgy23sFjIpKkmtTJ4olx/WlVP5tRU+cxZ+XmsCOJyGGKpgD0cfdcd/93sI0C+sQ6mIhUbU1qR0pA2wY1GT11Pm8t3xR2JBE5DNEUgKJg5T8AzKwDUBS7SCJSXTSqlcnjl/ejfaOajJ2exxvLNoYdSUSiFE0BuAF43czeCFYB/Dfw49jGEpHqomGtTJ64vD8dG9di3PQFvP6JSoBIdVDeTICpQA+gE/AD4FrgGHd/PQ7ZRKSaqF8zg8cv78fRzWoxbkYer32klcJFqrryZgIsAoa6+z53XxJs++KUTUSqkXo1Mpg5pj+dm9fhypkLePnD9WFHEpEyRHMKYI6Z3W9mJ5lZr4NbzJOJSLVTt0Y608f0o0uLulw9833+9cG6sCOJSCnSotinZ/Dzt8Uec+C0Sk8jItVe3ex0po/py8jJ87jmiYXc5/D97s3DjiUihyizAARjAGa5+z1xyiMiCaBOVuRIwMjJ8/jBkwspcufcHi3CjiUixUQ1BiBOWUQkgdTKTGPa6L70bluf655cyAsL14YdSUSK0RgAEYmZmplpTB3Vh77tG3D904t4bsGasCOJSEBjAEQkpmpkpDFlZF/GTp/PDc8upsidITmtw44lkvTKLQDufmo8gohI4srOSGVSbh8un57Hjc8t4cAB55K+bcKOJZLUSj0FYGb3Frv9w0Oemxq7SCKSiLLSU3l0RA4ndWrMTX/9gJlzV4cdSSSplTUG4ORit3MPea57DLKISILLSk9lwvDenHpMY37+/FJmvPt52JFEklZZBcBKuS0icsSy0lN5eHhvzjiuCb988UOmzvks7EgiSamsApBiZvXNrGGx2w3MrAGQGqd8IpKAMtNSeXBYb87s3JRf/+0jJr2tEiASb2UNAqwLLOC/f/2/X+w5j1kiEUkKGWkpPDisF9c+vpBb//4RBw44l5/cIexYIkmj1ALg7u3imENEklB6agp/ufR4rntyEb/758fsP+BcecpRYccSSQrRzAMgIhIz6akp/PmSnqSkGHe89AkH3Ln61I5hxxJJeCoAIhK6tNQU7hnSg1SDO19exv4i54dndAo7lkhCUwEQkSohLTWFu4ZEjgTc89pyitz50RmdMNNFSCKxEFUBMLMTgU7uPsXMGgO13F3DdkWkUqWmGHde2IMUM+6bvYIDB5wff/tolQCRGCi3AJjZLUAOcAwwBUgHHgNOiG00EUlGqSnGHy/oTlqKcf/rKyly56ffOUYlQKSSRXME4DzgeILLAN39KzOrHdNUIpLUUlKM35/XjZQU46E3PqXogHPzd49VCRCpRNEUgAJ3dzNzADOrGeNMIiKkpBi3DepKqhkT3lpF0QHnF98/TiVApJJEUwCeNrNHgHpmdjkwGpgY21giIpES8NtBXUhNMSa9/RlFB5xbzumsEiBSCaJZDvhPZnYmsIPIOIBfufurMU8mIgKYGbec05kUMybP+YwD7vzm3C4qASIVFM0gwDvc/Ubg1RIeExGJOTPjl2cfR1rqf08H3DqoKykpKgEiR6qsxYAOOrOEx75b2UFERMpiZtz83WMZ/62jmDn3C372/AccOKBlSUSOVKlHAMzsSuAqoIOZLSn2VG1gTqyDiYgcysy48axjSE2BB16PXB1w+wXdSdWRAJHDVtYpgMeBfwF/AG4q9vhOd99SkQ8NlhR+CmgHfA4McfetJezXhsiAw9ZEViD8nrt/bmbtgSeBhkRWLBzu7gUVySQi1YOZccO3jyE1JYX7Zq9g7/4D3HVRDzLSojmgKSIHlfr/GHff7u6fAzcS+fI9uNUKvpgr4iZgtrt3AmbzzYJR3HTgTnc/DugLbAwevwO4x907AluBMRXMIyLViJlx/ZlHc+NZx/K3xV9x+fQ88gv2hx1LpFqJpjL/A/h78HM2sIrIkYGKGARMC25PAwYfuoOZdQbSDl5x4O673D3fIkN/TwOeLev1IpL4rjzlKP5wfjf+s2ITwyfNY3t+YdiRRKqNcguAu3dz9+7Bz05E/hJ/t4Kf29Td1wW31wNNS9jnaGCbmf3VzBaa2Z1mlkrksP82dz9Y99cALUv7IDMbZ2Z5Zpa3adOmCsYWkapmaN823H9pL5as2cbFE95l4469YUcSqRYO+6SZu78P9CtvPzN7zcyWlrANOuT9Dp5aOFQacBJwA9AH6ACMPIK8E9w9x91zGjdufLgvF5Fq4HvdmjN5ZB++2JLPhQ+/yxdf54cdSaTKi2YegOuL3U0BegFflfc6dz+jjPfcYGbN3X2dmTXnv+f2i1sDLHL3VcFrXgD6A5OJzEqYFhwFaAWsLS+PiCS2kzo1ZubYfoyaOp8LHn6HGWP6cmyzOmHHEqmyojkCULvYlklkLMCgMl9RvllAbnA7F3ixhH3mE/miP/hn+2nAR8ERg9eBC8t5vYgkmePb1OfpKwaQYjDk4XdZsLpCFyyJJDSLfJ/G+UPNGgJPA22A1UQuA9xiZjnAeHcfG+x3JnAXYEQu9xvn7gVm1oHIZYANgIXAZe6+r7zPzcnJ8by8vJj8m0Sk6vhySz7DJ81l/Y69PHxZb045pknYkURCYWYL3D2nxOdKKwBm9jdKPjcPgLufWznx4kcFQCR5bNq5j9zJ81ixcSd3D+nJOT1ahB1JJO7KKgBljQH4U4zyiIjEXOPamTx5RX/GTs3jB08uZNueQob3bxt2LJEqo9QC4O5vHrxtZhlELssDWObuuthWRKq8OlnpTBvdl6sff59fvrCU7fkFXH1qR60kKEIUgwDN7BRgBfAA8CCw3MxOjm0sEZHKkZ2RyiPDe3Pe8S350yvLue0fH2sRIRGiuAyQyCC8b7v7MgAzOxp4Augdy2AiIpUlPTWFuy7qQd3sdCa9/Rnb8gu544JupKVq/QBJXtEUgPSDX/4A7r7czNJjmElEpNKlpBi3nNOZ+jUyuOe15WzfU8j9lx5PVnpq2NFEQhFN/c0zs4lmdkqwTQQ0lF5Eqh0z44dndOI353bhtY83kDt5Hjv3akiTJKdoCsCVwEfAD4Ltw+AxEZFqKXdgO/58SU8WrN7K0EffY/OucqcREUk40SwGtM/d73b384GxRJbx1f9bRKRaG9SzJRNG9GbFhl0Mefhd1m7bE3YkkbiK5iqAN8ysjpk1IDIb36Nmdk/so4mIxNZpxzblsbH92LRrHxc+9A4rN+4MO5JI3ERzCqCuu+8Azgemu3s/4PTYxhIRiY8+7Rrw1LgBFBY5Fz38Lou/3BZ2JJG4iKYApAUr9g0B/h7jPCIicde5RR2eHT+AmplpXProe7yzcnPYkURiLpoC8FvgZeBTd58fLMSzIraxRETiq12jmjx35UBa1s9m5JT5vLR0fdiRRGIqmkGAz7h7d3e/Mri/yt0viH00EZH4aloni6evGECXlnW4auYCnp7/ZdiRRGImmkGAHczsb2a2ycw2mtmLwVEAEZGEU69GBo+N6ccJHRvx0+eW8Ohbq8KOJBIT0ZwCeBx4GmgOtACeITIVsIhIQqqZmcbE3By+3605v/vnx9zx0ieUtnS6SHUVzVTANdx9RrH7j5nZT2IVSESkKshMS+W+ocdTJzudh974lG35hdw2uCupKVpJUBJDqQUguO4f4F9mdhPwJODAxcA/45BNRCRUqSnG78/rSv0a6Tz4xqfs2FPI3Rf3IDNN6wdI9VfWEYAFRL7wD9bdK4o958DNsQolIlJVmBk/PetY6tfI4Hf//Jgdewt5+LLe1MyM5gCqSNVV6v+C3b19ac9pNUARSTaXn9yBujXSuem5JQybOJepo/pQr0ZG2LFEjljUi2FbxOlmNglYE8NMIiJV0pCc1jw4rDcffbWDIY+8y/rte8OOJHLEorkMsL+Z3QesBl4E3gKOjXUwEZGq6KyuzZg6qg9rt+7hwoff4bPNu8OOJHJESi0AZvZ7M1sB/A5YAhwPbHL3ae6+NV4BRUSqmoEdG/H45f3ZvW8/Fz38Dh9+tT3sSCKHrawjAGOBDcBDwAx3/5rI4D8RkaTXo3U9nhk/kPTUFC6Z8B7zPtsSdiSRw1JWAWgO3AacA3xqZjOAbDPT0FcREaBjk1o8e+VAGtfKZPikufz7kw1hRxKJWqkFwN2L3P0ld88FjgJeAOYAa83s8TjlExGp0lrWy+aZ8QPo1LQW46Yv4IWFa8OOJBKVqK4CcPd97v6cu18IdAJeim0sEZHqo2GtTJ64vD857epz3VOLmPbO52FHEilX1JcBHuTuO9x9eizCiIhUV7Wz0pk6qi9nHNeUW2Z9yL2vLdf6AVKlHXYBEBGRkmWlp/LwZb24oFcr7n1tBb/520ccOKASIFWTBvSJiFSitNQU7rywO/VqpDPp7c/Yll/AnRf1ID1Vf29J1RJVATCzgUC74vvrNICISMlSUoxffP84GtTM4M6Xl7Fj734eHNaLrHQtIiRVR7kFILj87yhgEVAUPOyACoCISCnMjKtP7Ujd7HR++eJSRkyax6O5OdTN1lIqUjVEcwQgB+jsGs0iInLYLuvflrrZ6Vz/9CIumfAe00f3pXHtzLBjiUQ1CHAp0CzWQUREEtU5PVowMbcPn2/ezUUPv8OXW/LDjiQSVQFoBHxkZi+b2ayDW6yDiYgkkm8d3ZjHxvZla34h5z04h0Vfbgs7kiQ5K+/Ivpl9q6TH3f3NmCSKoZycHM/Lyws7hogksZUbdzFq6jw27dzHvRcfz1lddYBVYsfMFrh7TknPlXsEwN3fLGmr/JgiIomvY5NaPH/VCRzbrA5XzlzAxP+s0oRBEopyC4CZ9Tez+Wa2y8wKzKzIzHbEI5yISCJqFEwd/O3OTbntHx/zm799RJEmDJI4i2YMwP3AUGAFkE1kmeAHYhlKRCTRZWek8uCw3ow9sT1T3/mcK2bkkV+wP+xYkkSiXQxoJZAarBA4BTgrtrFERBJfaorxi7M789tBXfj3Jxu5+JH32Lhjb9ixJElEUwDyzSwDWGRmfzSzH0X5OhERicKIAe14dEQOKzfu4rwH32H5hp1hR5IkEM0X+fBgv2uA3UBr4IJYhhIRSTanH9eUp68YQEHRAS548B3mrNwcdiRJcNFcBbAaMKC5u//G3a8PTgmIiEgl6taqLi9cfQLN62WRO3kez+R9GXYkSWDRXAVwDpF1AF4K7ves6ERAZtbAzF41sxXBz/ql7NfGzF4xs4/N7CMzaxc8PtXMPjOzRcHWsyJ5RESqipb1snn2yoH079CQnzy7hLtfWabLBCUmojkF8GugL7ANwN0XAe0r+Lk3AbPdvRMwO7hfkunAne5+XJBhY7HnfuLuPYNtUQXziIhUGXWy0pkyqg9Dclpx379Xcv3Ti9m3v6j8F4ochmgKQKG7bz/ksYrW0UHAtOD2NGDwoTuYWWcgzd1fBXD3Xe6uCbRFJCmkp6ZwxwXdueHbR/P8wrWMmDSP7fmFYceSBBJNAfjQzC4FUs2sk5n9BXingp/b1N3XBbfXA01L2OdoYJuZ/dXMFprZnWZWfDHt35nZEjO7x8xKXVrLzMaZWZ6Z5W3atKmCsUVE4sfMuOa0Tvz5kp4s/GIb5z80RwsJSaWJpgBcC3QB9gFPADuA68p7kZm9ZmZLS9gGFd8vWGa4pCMKacBJwA1AH6ADMDJ47mbg2ODxBsCNpeVw9wnunuPuOY0bNy4vtohIlTOoZ0tmjOnL5l0FnPfgHBZ+sTXsSJIAorkKIN/df+7ufYIv0p+7e7kzVbj7Ge7etYTtRWCDmTUHCH5uLOEt1gCL3H2Vu+8HXgB6Be+9ziP2AVOIjA8QEUlY/To05K9XDaRGRhqXTHiPl5auDzuSVHOlFoDiS/+WtFXwc2cBucHtXODFEvaZD9Qzs4N/tp8GfBRkO1gejMj4gaUVzCMiUuUd1bgWf71qIMc110JCUnFpZTw3APiSyGH/uUTmAqgstwNPm9kYYDUwBMDMcoDx7j7W3YvM7AZgdvBFvwB4NHj9zKAYGJFLFMdXYjYRkSqrUa1MnhzXnx89tYjb/vExX27J51fndCE1pTL/Ey3JwEprj8GAuzOJLATUHfgH8IS7fxi/eJUrJyfH8/Lywo4hIlJhBw44t7/0CRPeWsXpxzbhvqHHUzOzrL/pJBmZ2QJ3zynpuVJPAQQL/7zk7rlAf2Al8IaZXROjnCIiEqWUFONn3zuOWwd14fVlG7l4wrtaSEgOS5mDAM0s08zOBx4DrgbuA56PRzARESnf8AHtmJibw6pNuznvwXdYtl4LCUl0yhoEOB14l8jI+98EVwHc6u5r45ZORETKddqxkYWECosOcOFD7/D2Ci0kJOUr6wjAZUAn4IfAO2a2I9h2mtmO+MQTEZFodG0ZWUioRb1sRk6Zx9NaSEjKUdYYgBR3rx1sdYpttd29TjxDiohI+VrUy+aZKwcw4KiG/PTZJdylhYSkDNHMBCgiItVEnax0Jo/sw8U5rfnLv1fyo6cWaSEhKZGuGRERSTDpqSncfkE32jSswZ0vL+Or7XuZMLw39WpkhB1NqhAdARARSUBmxtWnduTPl/Rk0RfbOP+hd/jiay0kJP+lAiAiksAG9WzJY2P78bUWEpJDqACIiCS4vu0b8NerBlIz8+BCQuvKf5EkPBUAEZEkcFTjWjx/1UA6t6jDlTPf10JCogIgIpIsGtbK5InL+3NWl2bc9o+PuWXWh+wvOhB2LAmJCoCISBLJSk/lgUt7ccXJHZj+7mqumLGA3fv2hx1LQqACICKSZFJSjJu/dxy3Du7K68s2MuSRd9mghYSSjgqAiEiSGt6/LZNy+/DZ5t2c98AcPlmvWd6TiQqAiEgSO/XYJjx9xQD2H3AueuhdLSSURFQARESS3MGFhFrWDxYSmq+FhJKBCoCIiEQWEhofLCT0nBYSSgYqACIiAkDtYCGhS/pEFhK6TgsJJTQtBiQiIv8vPTWFP5zfjdYNIgsJrdNCQglLRwBEROQbDi4kdN/Q4/9/IaHVX+8OO5ZUMhUAEREp0bk9WvDY2H5s2V3A4Afm8N6qr8OOJJVIBUBERErVt30DXrjqBBrUzOCyiXN5av4XYUeSSqICICIiZWrXqCZ/veoEBnZsxI3PfcCtf/+IogO6QqC6UwEQEZFy1c1OZ3JuDiMHtmPS258xdtp8du4tDDuWVIAKgIiIRCUtNYVfn9uF353Xlf+s2Mz5D77DF1/nhx1LjpAKgIiIHJZh/doyfUxfNu7cx6AH3mauBgdWSyoAIiJy2AYe1YgXrj6B+jUzuGySBgdWRyoAIiJyRNo3qsnzV51A/w4NufG5D7hNgwOrFRUAERE5YnWz05kysg8jB7ZjogYHVisqACIiUiEHBwfeNrgrb63YzAUPvcOXWzQ4sKpTARARkUpxWf+2TB/dlw079jHogTnM+2xL2JGkDCoAIiJSaU7oGBkcWC87nWET3+PpvC/DjiSlUAEQEZFKdXBwYL/2Dfnps0v4/T8/1uDAKkgFQEREKl3dGulMHdWH3AFtmfDWKsZNz9PgwCpGBUBERGIiLTWF3wzqyq2Du/LG8k1c+NC7GhxYhagAiIhITA3v35Zpo/qybvseBj0wh/mfa3BgVaACICIiMXdip/8ODrz00fd4RoMDQ6cCICIicdGhca3/Hxz4k2eX8AcNDgyVCoCIiMRN3RrpTBnVhxED2vJIMDhw1779YcdKSioAIiISV+mpKfx2UFd+O6gLbyzfxAUPaubAMIRSAMysgZm9amYrgp/1S9jnVDNbVGzba2aDg+fam9lcM1tpZk+ZWUbc/xEiIlIhIwa0Y+qoPqzbvofBD8whT4MD4yqsIwA3AbPdvRMwO7j/De7+urv3dPeewGlAPvBK8PQdwD3u3hHYCoyJS2oREalUJ3VqzPNXn0Cd7HQufXQuzy5YE3akpBFWARgETAtuTwMGl7P/hcC/3D3fzIxIIXj2MF4vIiJV1FGNa/H8VQPp074+NzyzmD/8S4MD4yGsAtDU3dcFt9cDTcvZ/xLgieB2Q2Cbux8cNbIGaFn5EUVEJF7q1chg6qi+XNa/DY+8uYorZizQ4MAYi1kBMLPXzGxpCdug4vu5uwOlVj0zaw50A14+whzjzCzPzPI2bdp0JG8hIiJxkJ6awm2Du/HbQV14fdlGLnzoHdZs1eDAWIlZAXD3M9y9awnbi8CG4Iv94Bf8xjLeagjwvLsfnET6a6CemaUF91sBa8vIMcHdc9w9p3HjxhX/h4mISEwdHBy4dltkcOCC1RocGAthnQKYBeQGt3OBF8vYdyj/Pfx/8IjB60TGBUTzehERqWZO6tSY5686gVqZaQydMJfnNDiw0oVVAG4HzjSzFcAZwX3MLMfMJh7cyczaAa2BNw95/Y3A9Wa2ksiYgEnxCC0iIvHTsUktXrj6BHLa1efHzyzm9n99wgENDqw0FvmDOjnk5OR4Xl5e2DFEROQwFBYd4NezPmTm3C84s3NT7r24JzUz08p/oWBmC9w9p6TnNBOgiIhUaZHBgV35zbldmP3xBi546B3WbtsTdqxqTwVARESqPDMjd2A7pozqy9ptexh0/9ssWL017FjVmgqAiIhUG986OjI4sGZmGkMnvMfzCzU48EipAIiISLXSsUktXrjqBHq1rcePnlrMH1/S4MAjoQIgIiLVTv2aGcwY04+hfdvw4BufMv6xBezWzIGHRQVARESqpfTUFH5/XlduOaczr328gQsffleDAw+DCoCIiFRbZsaoE9ozeWQf1mzJZ9D9czQ4MEoqACIiUu2dckwTnr96IDUzUxn66Hu8sLDUGeIloAIgIiIJoWOT2pHBgW3qcd1Ti7jjpU+0rHAZVABERCRh1K+ZwfTR/bi0XxseeuNTRk+dz/b8wvJfmIRUAEREJKFkpKXw+/O68fvzuvHOp5s594G3WbZ+Z9ixqhwVABERSUiX9mvDk+P6k19QxHkPzuFfH6wLO1KVogIgIiIJq3fbBvz92hM5plltrpz5Pne+rHEBB6kAiIhIQmtaJ4snx/VnaN/WPPD6p4yZNp/tezQuQAVAREQSXmZaKn84vzu/O68rc1ZuZtD9b7N8Q3KPC1ABEBGRpDGsX1ueuLw/uwuKOO+BOby0NHnHBagAiIhIUslp14C/XXMinZrWZvxj7/Onl5cl5bgAFQAREUk6zepm8dQV/bk4pzX3v76SsUk4LkAFQEREklJmWiq3X9CNWwd35T8rNjP4gTmsSKJxASoAIiKStMyM4f3b8sS4/uzcu5/BD8zhpaXrw44VFyoAIiKS9Pq0i8wX0LFpbcY/toC7X1nGgQQfF6ACICIiQjAuYFx/huS04r5/r+Ty6Xns2Ju44wJUAERERAJZ6anccUF3bh3UhTeXb2Lw/XNYuTExxwWoAIiIiBRjZgwf0I7HL+/Pjr2FDH7gHV75MPHGBagAiIiIlKBv+wb87doTOapxTcbNWMDdry5PqHEBKgAiIiKlaF43m6euGMCFvVtx3+wVjJuROOMCVABERETKkJWeyp0Xdue3g7rwxrJNDH5gDis37go7VoWpAIiIiJTDzBgxoB0zx/Zje34hgx+Yw6sfbQg7VoWoAIiIiESpX4eG/O3aE+nQuCaXT8/j3teq77gAFQAREZHD0KJeNk9fMYALerXi3tdWMG7GAnZWw3EBKgAiIiKHKSs9lT9d1J1fn9OZ15dtZPADc/h0U/UaF6ACICIicgTMjJEntGfm2H5syy9k8P1zeK0ajQtQARAREamA/h0aMuvaE2nXqCZjp+fx59dWVItxASoAIiIiFdSyXjbPjB/A+b1acs9ryxn/WNUfF6ACICIiUgmy0lO566Ie3HJOZ2Z/EhkXsKoKjwtQARAREakkZsaoE9rz2Jh+bM0vZND9c5j9cdUcF6ACICIiUskGHNWQWdecQNtGNRg7PY+/zK564wJUAERERGKgVf0aPDt+IIN7tuSuV5dz5cwF7Nq3P+xY/08FQEREJEay0lO5e0gPfnV2Z177eCPnPTCHzzbvDjsWoAIgIiISU2bG6BPbM2NMX77eXcC597/N659sDDuWCoCIiEg8DDyqEbOuOYE2DWowetp87v/3CtzDGxegAiAiIhInB8cFDOrRgj+9spwrH3s/tHEBoRQAM2tgZq+a2YrgZ/0S9jnVzBYV2/aa2eDgualm9lmx53rG+98gIiJyJLIzUrnn4p784vvH8erHG0IbFxDWEYCbgNnu3gmYHdz/Bnd/3d17untP4DQgH3il2C4/Ofi8uy+KQ2YREZFKYWaMPakDM0b3ZfOufZFxAcviOy4grAIwCJgW3J4GDC5n/wuBf7l7fixDiYiIxNPAjo2Ydc2JtK5fg9FT5/PA6yvj9tlhFYCm7r4uuL0eaFrO/pcATxzy2O/MbImZ3WNmmZWeUEREJA5aN6jBc1cO5JzuLcgviN94AIvVCEQzew1oVsJTPwemuXu9Yvtudff/GQcQPNccWAK0cPfCYo+tBzKACcCn7v7bUl4/DhgH0KZNm96rV68+4n+TiIhIrLg77pCSYpX2nma2wN1zSnourdI+5RDufkYZgTaYWXN3Xxd8mZd14mMI8PzBL//gvQ8ePdhnZlOAG8rIMYFISSAnJ6dqzcMoIiISMDOs8r77yxXWKYBZQG5wOxd4sYx9h3LI4f+gNGBmRmT8wNLKjygiIpK4wioAtwNnmtkK4IzgPmaWY2YTD+5kZu2A1sCbh7x+ppl9AHwANAJui0doERGRRBGzUwBlcfevgdNLeDwPGFvs/udAyxL2Oy2W+URERBKdZgIUERFJQioAIiIiSUgFQEREJAmpAIiIiCQhFQAREZEkpAIgIiKShFQAREREkpAKgIiISBJSARAREUlCKgAiIiJJSAVAREQkCakAiIiIJCEVABERkSSkAiAiIpKEzN3DzhA3ZrYJWF2Jb9kI2FyJ7ycl0+85PvR7jh/9ruNDv2do6+6NS3oiqQpAZTOzPHfPCTtHotPvOT70e44f/a7jQ7/nsukUgIiISBJSARAREUlCKgAVMyHsAElCv+f40O85fvS7jg/9nsugMQAiIiJJSEcAREREkpAKwBEys7PMbJmZrTSzm8LOk4jMrLWZvW5mH5nZh2b2w7AzJTIzSzWzhWb297CzJCozq2dmz5rZJ2b2sZkNCDtTIjKzHwX/zVhqZk+YWVbYmaoiFYAjYGapwAPAd4HOwFAz6xxuqoS0H/ixu3cG+gNX6/ccUz8EPg47RIL7M/CSux8L9EC/70pnZi2BHwA57t4VSAUuCTdV1aQCcGT6AivdfZW7FwBPAoNCzpRw3H2du78f3N5J5D+WLcNNlZjMrBXwfWBi2FkSlZnVBU4GJgG4e4G7bws1VOJKA7LNLA2oAXwVcp4qSQXgyLQEvix2fw36YoopM2sHHA/MDTlKoroX+ClwIOQciaw9sAmYEpxqmWhmNcMOlWjcfS3wJ+ALYB2w3d1fCTdV1aQCIFWemdUCngOuc/cdYedJNGZ2NrDR3ReEnSXBpQG9gIfc/XhgN6DxQ5XMzOoTOSLbHmgB1DSzy8JNVTWpAByZtUDrYvdbBY9JJTOzdCJf/jPd/a9h50lQJwDnmtnnRE5nnWZmj4UbKSGtAda4+8GjWM8SKQRSuc4APnP3Te5eCPwVGBhypipJBeDIzAc6mVl7M8sgMsBkVsiZEo6ZGZHzpR+7+91h50lU7n6zu7dy93ZE/rf8b3fXX0yVzN3XA1+a2THBQ6cDH4UYKVF9AfQ3sxrBf0NOR4MtS5QWdoDqyN33m9k1wMtERphOdvcPQ46ViE4AhgMfmNmi4LGfufs/w4skUiHXAjODPxxWAaNCzpNw3H2umT0LvE/kSqKFaEbAEmkmQBERkSSkUwAiIiJJSAVAREQkCakAiIiIJCEVABERkSSkAiAiIpKEVABEqhkzczO7q9j9G8zs15X03lPN7MLKeK9yPueiYDW812P9WYd87kgzuz+enylSVakAiFQ/+4DzzaxR2EGKCxZeidYY4HJ3PzVWeUSkbCoAItXPfiITm/zo0CcO/QvezHYFP08xszfN7EUzW2Vmt5vZMDObZ2YfmNlRxd7mDDPLM7PlwToBmFmqmd1pZvPNbImZXVHsff9jZrMoYVY7MxsavP9SM7sjeOxXwInAJDO7s4TX/KTY5/wmeKydmX1iZjODIwfPmlmN4LnTg8V1PjCzyWaWGTzex8zeMbPFwb+zdvARLczsJTNbYWZ/LPbvmxrk/MDM/ud3K5JoNBOgSPX0ALDk4BdYlHoAxwFbiMxCN9Hd+5rZD4nMUHddsF87IkteHwW8bmYdgRFEVlXrE3zBzjGzgyus9QK6uvtnxT/MzFoAdwC9ga3AK2Y22N1/a2anATe4e94hr/k20Cn4fANmmdnJRKZ3PQYY4+5zzGwycFVwOH8qcLq7Lzez6cCVZvYg8BRwsbvPN7M6wJ7gY3oSWVlyH7DMzP4CNAFaBuvHY2b1DuP3KlIt6QiASDUUrIo4HfjBYbxsvruvc/d9wKfAwS/wD4h86R/0tLsfcPcVRIrCscC3gRHBlMxzgYZEvqgB5h365R/oA7wRLMqyH5gJnFxOxm8H20IiU7keW+xzvnT3OcHtx4gcRTiGyMIvy4PHpwWfcQywzt3nQ+T3FWQAmO3u2919L5GjFm2Df2cHM/uLmZ0FaNVJSXg6AiBSfd1L5EtySrHH9hMUezNLATKKPbev2O0Dxe4f4Jv/LTh0fnAn8tf4te7+cvEnzOwUIsvaVhYD/uDujxzyOe1KyXUkiv8eioA0d99qZj2A7wDjgSHA6CN8f5FqQUcARKopd98CPE1kQN1BnxM55A5wLpB+BG99kZmlBOMCOgDLiCx8dWWwPDNmdrSZ1SznfeYB3zKzRmaWCgwF3iznNS8Do82sVvA5Lc2sSfBcGzMbENy+FHg7yNYuOE0BkcWj3gweb25mfYL3qV3WIMVgQGWKuz8H/AIt0ytJQEcARKq3u4Brit1/FHjRzBYDL3Fkf51/QeTLuw4w3t33mtlEIqcJ3g+WWN0EDC7rTdx9nZndBLxO5C/7f7j7i+W85hUzOw54N/Ix7AIuI/KX+jLg6uD8/0fAQ0G2UcAzwRf8fOBhdy8ws4uBv5hZNpHz/2eU8dEtgSnBUROAm8vKKZIItBqgiFR5wSmAvx8cpCciFadTACIiIklIRwBERESSkI4AiIiIJCEVABERkSSkAiAiIpKEVABERESSkAqAiIhIElIBEBERSUL/B3qJrje0PZGgAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search using {'num_samples': 128, 'learning_rate': 0.0001, 'l1_regularization_factor': 0.0001, 'l2_regularization_factor': 0.01, 'number_additive_traits': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierredemetz/miniconda3/envs/pierre/lib/python3.8/site-packages/haiku/_src/data_structures.py:143: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.\n",
      "  leaves, treedef = jax.tree_flatten(tree)\n",
      "/Users/pierredemetz/miniconda3/envs/pierre/lib/python3.8/site-packages/haiku/_src/data_structures.py:144: FutureWarning: jax.tree_unflatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_unflatten instead.\n",
      "  return jax.tree_unflatten(treedef, leaves)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[466], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m shuffled_weights \u001b[38;5;241m=\u001b[39m shuffle_weights(rng, weights)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#Fit the model on best params\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m history, model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffled_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_data_jax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m#save model\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m#model.save(os.path.join(model_directory, 'my_model_'+str(model_count)))\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m handle:\n",
      "File \u001b[0;32m~/UCL_work/Crick/doubledeepms/inst/python/training.py:73\u001b[0m, in \u001b[0;36mmodel_training\u001b[0;34m(model, optimizer, weights, opt_state, param_dict, input_data, n_epochs, rng)\u001b[0m\n\u001b[1;32m     70\u001b[0m history \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_data \u001b[38;5;129;01min\u001b[39;00m generate_batches(input_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m], param_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_samples\u001b[39m\u001b[38;5;124m'\u001b[39m], rng_batches):\n\u001b[1;32m     74\u001b[0m         inputs_select, inputs_folding, inputs_binding, target \u001b[38;5;241m=\u001b[39m batch_data\n\u001b[1;32m     75\u001b[0m         weights, opt_state \u001b[38;5;241m=\u001b[39m update(weights, opt_state, inputs_select, inputs_folding, inputs_binding, target)\n",
      "File \u001b[0;32m~/UCL_work/Crick/doubledeepms/inst/python/training.py:110\u001b[0m, in \u001b[0;36mgenerate_batches\u001b[0;34m(input_data, batch_size, rng)\u001b[0m\n\u001b[1;32m    108\u001b[0m batch_fold \u001b[38;5;241m=\u001b[39m input_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold\u001b[39m\u001b[38;5;124m'\u001b[39m][batch_indices]\n\u001b[1;32m    109\u001b[0m batch_bind \u001b[38;5;241m=\u001b[39m input_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbind\u001b[39m\u001b[38;5;124m'\u001b[39m][batch_indices]\n\u001b[0;32m--> 110\u001b[0m batch_target \u001b[38;5;241m=\u001b[39m \u001b[43minput_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_indices\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m batch_select, batch_fold, batch_bind, batch_target\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py:3815\u001b[0m, in \u001b[0;36m_rewriting_take\u001b[0;34m(arr, idx, indices_are_sorted, unique_indices, mode, fill_value)\u001b[0m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(aval, core\u001b[38;5;241m.\u001b[39mDShapedArray) \u001b[38;5;129;01mand\u001b[39;00m aval\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m () \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m         dtypes\u001b[38;5;241m.\u001b[39missubdtype(aval\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39minteger) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m dtypes\u001b[38;5;241m.\u001b[39missubdtype(aval\u001b[38;5;241m.\u001b[39mdtype, dtypes\u001b[38;5;241m.\u001b[39mbool_) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   3812\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(arr\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mint\u001b[39m)):\n\u001b[1;32m   3813\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m lax\u001b[38;5;241m.\u001b[39mdynamic_index_in_dim(arr, idx, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 3815\u001b[0m treedef, static_idx, dynamic_idx \u001b[38;5;241m=\u001b[39m \u001b[43m_split_index_for_jit\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3816\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _gather(arr, treedef, static_idx, dynamic_idx, indices_are_sorted,\n\u001b[1;32m   3817\u001b[0m                unique_indices, mode, fill_value)\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py:3894\u001b[0m, in \u001b[0;36m_split_index_for_jit\u001b[0;34m(idx, shape)\u001b[0m\n\u001b[1;32m   3890\u001b[0m idx \u001b[38;5;241m=\u001b[39m _eliminate_deprecated_list_indexing(idx)\n\u001b[1;32m   3892\u001b[0m \u001b[38;5;66;03m# Expand any (concrete) boolean indices. We can then use advanced integer\u001b[39;00m\n\u001b[1;32m   3893\u001b[0m \u001b[38;5;66;03m# indexing logic to handle them.\u001b[39;00m\n\u001b[0;32m-> 3894\u001b[0m idx \u001b[38;5;241m=\u001b[39m \u001b[43m_expand_bool_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3896\u001b[0m leaves, treedef \u001b[38;5;241m=\u001b[39m tree_flatten(idx)\n\u001b[1;32m   3897\u001b[0m dynamic \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(leaves)\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py:4197\u001b[0m, in \u001b[0;36m_expand_bool_indices\u001b[0;34m(idx, shape)\u001b[0m\n\u001b[1;32m   4195\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dim_number, i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(idx):\n\u001b[1;32m   4196\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 4197\u001b[0m     abstract_i \u001b[38;5;241m=\u001b[39m \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_aval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4198\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   4199\u001b[0m     abstract_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/core.py:1256\u001b[0m, in \u001b[0;36mget_aval\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1254\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39maval\n\u001b[1;32m   1255\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1256\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_aval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/core.py:1245\u001b[0m, in \u001b[0;36mconcrete_aval\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1243\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m typ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__mro__\u001b[39m:\n\u001b[1;32m   1244\u001b[0m   handler \u001b[38;5;241m=\u001b[39m pytype_aval_mappings\u001b[38;5;241m.\u001b[39mget(typ)\n\u001b[0;32m-> 1245\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m handler: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__jax_array__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1247\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete_aval(x\u001b[38;5;241m.\u001b[39m__jax_array__())\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/_src/abstract_arrays.py:53\u001b[0m, in \u001b[0;36mcanonical_concrete_aval\u001b[0;34m(val, weak_type)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcanonical_concrete_aval\u001b[39m(val, weak_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 53\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m ConcreteArray(\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanonicalize_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, val,\n\u001b[1;32m     54\u001b[0m                        weak_type\u001b[38;5;241m=\u001b[39mweak_type)\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/_src/dtypes.py:118\u001b[0m, in \u001b[0;36mcanonicalize_dtype\u001b[0;34m(dtype, allow_opaque_dtype)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcanonicalize_dtype\u001b[39m(dtype: Any, allow_opaque_dtype: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[DType, OpaqueDType]:\n\u001b[0;32m--> 118\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _canonicalize_dtype(\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx64_enabled\u001b[49m, allow_opaque_dtype, dtype)\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/_src/config.py:246\u001b[0m, in \u001b[0;36mConfig.define_bool_state.<locals>.get_state\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    245\u001b[0m   val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_thread_local_state, name, unset)\n\u001b[0;32m--> 246\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m val \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unset \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/_src/config.py:104\u001b[0m, in \u001b[0;36mConfig._read\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mabsl_flags\u001b[38;5;241m.\u001b[39mFLAGS, name)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 104\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_exists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues[name]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_samples = best_params['num_samples']\n",
    "learning_rate = best_params['learning_rate']\n",
    "l1_regularization_factor = best_params['l1_regularization_factor']\n",
    "l2_regularization_factor = best_params['l2_regularization_factor']\n",
    "number_additive_traits = best_params['number_additive_traits']\n",
    "\n",
    "#######################################################################\n",
    "## BUILD FINAL NEURAL NETWORK ##\n",
    "#######################################################################\n",
    "\n",
    "#create the rng\n",
    "random_seed = 42\n",
    "rng = jax.random.PRNGKey(random_seed)\n",
    "num_models = 2 \n",
    "\n",
    "model, optimizer = create_model_jax(\n",
    "    rng=rng,\n",
    "    learn_rate=learning_rate,\n",
    "    l1=l1_regularization_factor,\n",
    "    l2=l2_regularization_factor,\n",
    "    input_dim_select=model_data_jax['train']['select'].shape[1],\n",
    "    input_dim_folding=model_data_jax['train']['fold'].shape[1],\n",
    "    input_dim_binding=model_data_jax['train']['bind'].shape[1],\n",
    "    number_additive_traits=number_additive_traits\n",
    ")\n",
    "\n",
    "weights = model.init(rng, model_data_jax['train']['select'], model_data_jax['train']['fold'], model_data_jax['train']['bind'])\n",
    "opt_state = optimizer.init(weights)\n",
    "\n",
    "for model_count in range(num_models):\n",
    "\n",
    "    #Shuffle model weights\n",
    "    shuffled_weights = shuffle_weights(rng, weights)\n",
    "\n",
    "    #Fit the model on best params\n",
    "    history, model = model_training(model, optimizer, shuffled_weights, opt_state, best_params, model_data_jax, num_epochs_grid, rng)\n",
    "    \n",
    "    #save model\n",
    "    #model.save(os.path.join(model_directory, 'my_model_'+str(model_count)))\n",
    "    with open(f'weights_{model_count}.pickle', 'wb') as handle:\n",
    "        pickle.dump(shuffled_weights, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    #load model\n",
    "    #model = load_model(os.path.join(model_directory, 'my_model_'+str(model_count)))\n",
    "    with open(f'weights_{model_count}.pickle', 'rb') as handle:\n",
    "        shuffled_weights_reloaded = pickle.load(handle)\n",
    "        \n",
    "    print(history)\n",
    "    #Plot model performance per epoch\n",
    "    my_figure = plt.figure(figsize = (8,8))\n",
    "    plt.plot(np.log(history))\n",
    "    plt.xlabel('Number of epochs')\n",
    "    plt.ylabel('Mean Absolute Error (MAE) on testing data')\n",
    "    plt.show()\n",
    "    my_figure.savefig(os.path.join(plot_directory, \"model_performance_perepoch_\"+str(model_count)+\".pdf\"), bbox_inches='tight')\n",
    "    \n",
    "    #######################################################################\n",
    "    ## SAVE OBSERVATIONS, PREDICTIONS & ADDITIVE TRAIT VALUES ##\n",
    "    #######################################################################\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fce8c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
