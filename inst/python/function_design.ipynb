{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "2903c6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "#tf.config.optimizer.set_jit(False)\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "import random\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "#import matplotlib\n",
    "import os\n",
    "\n",
    "from keras.constraints import Constraint\n",
    "from keras.layers import Layer\n",
    "from keras import backend as K\n",
    "\n",
    "import jax\n",
    "import jax.nn as nn\n",
    "from jax.random import normal\n",
    "from jax.experimental import sparse\n",
    "#from sparse import bcoo_concatenate\n",
    "from jax.tree_util import tree_map\n",
    "import jaxlib\n",
    "import jax.numpy as jnp\n",
    "import haiku as hk\n",
    "import optax\n",
    "from jax import jit\n",
    "from functools import partial\n",
    "import functools\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from optax import GradientTransformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "380169d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b96bb26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State_prob_folded(Layer):\n",
    "    def __init__(self, trainable=False, **kwargs):\n",
    "        super(State_prob_folded, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.trainable = trainable\n",
    "    def build(self, input_shape):\n",
    "        super(State_prob_folded, self).build(input_shape)\n",
    "    def call(self, inputs, mask=None):\n",
    "        return K.pow(K.constant(1.) + K.exp(inputs),-1)\n",
    "    def get_config(self):\n",
    "        config = {'trainable': self.trainable}\n",
    "        base_config = super(State_prob_folded, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "class State_prob_bound(Layer):\n",
    "    def __init__(self, trainable=False, **kwargs):\n",
    "        super(State_prob_bound, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.trainable = trainable\n",
    "    def build(self, input_shape):\n",
    "        super(State_prob_bound, self).build(input_shape)\n",
    "    def call(self, inputs, mask=None):\n",
    "        return K.pow(K.constant(1.) + K.exp(inputs[0]) * (K.constant(1.)+K.exp(inputs[1])),-1)\n",
    "    def get_config(self):\n",
    "        config = {'trainable': self.trainable}\n",
    "        base_config = super(State_prob_bound, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "class Between(Constraint):\n",
    "    def __init__(self, min_value, max_value):\n",
    "        self.min_value = min_value\n",
    "        self.max_value = max_value\n",
    "    def __call__(self, w):\n",
    "        return K.clip(w, self.min_value, self.max_value)\n",
    "    def get_config(self):\n",
    "        return {'min_value': self.min_value,\n",
    "                'max_value': self.max_value}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2201d2b0",
   "metadata": {},
   "source": [
    "# Define arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58df56d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cae27996",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = '/Users/pierredemetz/UCL_work/Crick/doubledeepms/Results//Data/mochi/GRB2-SH3/mochi__fit_tmodel_3state_sparse_dimsum128_subsample100p//dataset_train.txt'\n",
    "data_valid = '/Users/pierredemetz/UCL_work/Crick/doubledeepms/Results//Data/mochi/GRB2-SH3/mochi__fit_tmodel_3state_sparse_dimsum128_subsample100p//dataset_valid.txt' \n",
    "data_obs = '/Users/pierredemetz/UCL_work/Crick/doubledeepms/Results//Data/mochi/GRB2-SH3/mochi__fit_tmodel_3state_sparse_dimsum128_subsample100p//dataset_all.txt' \n",
    "o = '/Users/pierredemetz/UCL_work/Crick/doubledeepms/Results//Data/mochi/GRB2-SH3/mochi__fit_tmodel_3state_sparse_dimsum128_subsample100p/ '\n",
    "e = 100 \n",
    "l1_regularization_factor = 0 \n",
    "l2_regularization_factor = 0 \n",
    "p = 1000 \n",
    "num_samples= 128,256,512,1024 \n",
    "learning_rate= 0.001 \n",
    "num_resamplings= 10 \n",
    "num_models= 1 \n",
    "random_seed= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1bc187d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"data_train\": \"'/Users/pierredemetz/UCL_work/Crick/doubledeepms/Results//Data/mochi/GRB2-SH3/mochi__fit_tmodel_3state_sparse_dimsum128_subsample100p//dataset_train.txt'\",\n",
    "    \"data_valid\": \"/Users/pierredemetz/UCL_work/Crick/doubledeepms/Results//Data/mochi/GRB2-SH3/mochi__fit_tmodel_3state_sparse_dimsum128_subsample100p//dataset_valid.txt\",\n",
    "    \"data_obs\": \"/Users/pierredemetz/UCL_work/Crick/doubledeepms/Results//Data/mochi/GRB2-SH3/mochi__fit_tmodel_3state_sparse_dimsum128_subsample100p//dataset_all.txt\",\n",
    "    \"output_directory\": \"/Users/pierredemetz/UCL_work/Crick/doubledeepms/Results//Data/mochi/GRB2-SH3/mochi__fit_tmodel_3state_sparse_dimsum128_subsample100p/\",\n",
    "    \"number_additive_traits\": 1,\n",
    "    \"l1_regularization_factor\": \"0.0001,0.001,0.01,0.1\",\n",
    "    \"l2_regularization_factor\": \"0.0001,0.001,0.01,0.1\",\n",
    "    \"num_epochs_grid\": 10,\n",
    "    \"num_epochs\": 10000,\n",
    "    \"num_samples\": \"128,256,512,1024\",\n",
    "    \"learning_rate\": \"0.0001,0.001,0.01,0.1\",\n",
    "    \"num_resamplings\": 10,\n",
    "    \"early_stopping\": False,\n",
    "    \"num_models\": 10,\n",
    "    \"random_seed\": 1\n",
    "}\n",
    "\n",
    "data_train_file = args[\"data_train\"]\n",
    "data_valid_file = args[\"data_valid\"]\n",
    "data_obs_file = args[\"data_obs\"]\n",
    "output_directory = args[\"output_directory\"]\n",
    "number_additive_traits = args[\"number_additive_traits\"]\n",
    "num_epochs_grid = args[\"num_epochs_grid\"]\n",
    "num_epochs = args[\"num_epochs\"]\n",
    "num_resamplings = args[\"num_resamplings\"]\n",
    "early_stopping = args[\"early_stopping\"]\n",
    "num_models = args[\"num_models\"]\n",
    "random_seed = args[\"random_seed\"]\n",
    "\n",
    "#Grid search arguments\n",
    "l1 = [float(i) for i in args[\"l1_regularization_factor\"].split(\",\")]\n",
    "l2 = [float(i) for i in args[\"l2_regularization_factor\"].split(\",\")]\n",
    "batch_size = [int(i) for i in args[\"num_samples\"].split(\",\")]\n",
    "learn_rate = [float(i) for i in args[\"learning_rate\"].split(\",\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7844f1",
   "metadata": {},
   "source": [
    "# Load model data legacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e52a99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model data into sparse tensors\n",
    "def load_model_data(file_dict):\n",
    "  data_dict = {}\n",
    "  for name in file_dict.keys():\n",
    "    #Initialise\n",
    "    data_dict[name] = {}\n",
    "    #Column names\n",
    "    ALL_COLUMNS = list(pd.read_csv(file_dict[name], nrows = 1).columns)\n",
    "    SELECT_COLUMNS = [i for i in range(len(ALL_COLUMNS)) if str.startswith(ALL_COLUMNS[i], \"dataset_\")]\n",
    "    FOLD_COLUMNS = [i for i in range(len(ALL_COLUMNS)) if str.startswith(ALL_COLUMNS[i], \"fold_\") or ALL_COLUMNS[i]==\"WT\"]\n",
    "    BIND_COLUMNS = [i for i in range(len(ALL_COLUMNS)) if str.startswith(ALL_COLUMNS[i], \"bind_\") or ALL_COLUMNS[i]==\"WT\"]\n",
    "    TARGET_COLUMN = [i for i in range(len(ALL_COLUMNS)) if ALL_COLUMNS[i]==\"fitness\"]\n",
    "    TARGET_SD_COLUMN = [i for i in range(len(ALL_COLUMNS)) if ALL_COLUMNS[i]==\"fitness_sd\"]\n",
    "    SEQUENCE_COLUMN = [i for i in range(len(ALL_COLUMNS)) if ALL_COLUMNS[i]==\"variant_sequence\"]\n",
    "    TRAINING_SET_COLUMN = [i for i in range(len(ALL_COLUMNS)) if ALL_COLUMNS[i]==\"training_set\"]\n",
    "    \n",
    "    #Save (sparse) tensors\n",
    "    data_dict[name][\"select\"] = tf.convert_to_tensor(np.asarray(pd.read_csv(file_dict[name], usecols = SELECT_COLUMNS)), np.float32)\n",
    "    data_dict[name][\"fold\"] = tf.sparse.from_dense(tf.convert_to_tensor(np.asarray(pd.read_csv(file_dict[name], usecols = FOLD_COLUMNS)), np.float32))\n",
    "    data_dict[name][\"bind\"] = tf.sparse.from_dense(tf.convert_to_tensor(np.asarray(pd.read_csv(file_dict[name], usecols = BIND_COLUMNS)), np.float32))\n",
    "    data_dict[name][\"target\"] = tf.convert_to_tensor(np.asarray(pd.read_csv(file_dict[name], usecols = TARGET_COLUMN)), np.float32)\n",
    "    data_dict[name][\"target_sd\"] = tf.convert_to_tensor(np.asarray(pd.read_csv(file_dict[name], usecols = TARGET_SD_COLUMN)), np.float32)\n",
    "    \n",
    "    #Save remaining columns\n",
    "    if len(SEQUENCE_COLUMN)!=0 and len(TRAINING_SET_COLUMN)!=0:\n",
    "      data_dict[name][\"sequence\"] = np.asarray(pd.read_csv(file_dict[name], usecols = SEQUENCE_COLUMN))\n",
    "    if len(TRAINING_SET_COLUMN)!=0:\n",
    "      data_dict[name][\"training_set\"] = np.asarray(pd.read_csv(file_dict[name], usecols = TRAINING_SET_COLUMN))\n",
    "    data_dict[name][\"fold_colnames\"] = np.asarray([ALL_COLUMNS[i].replace(\"fold_\", \"\") for i in FOLD_COLUMNS])\n",
    "    data_dict[name][\"bind_colnames\"] = np.asarray([ALL_COLUMNS[i].replace(\"bind_\", \"\") for i in BIND_COLUMNS])\n",
    "  return data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3beead6a",
   "metadata": {},
   "source": [
    "# Load model data jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "6c9e744c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_data_jax(file_dict):\n",
    "    data_dict = {}\n",
    "    for name in file_dict.keys():\n",
    "        # Initialize\n",
    "        data_dict[name] = {}\n",
    "\n",
    "        # Read the entire file once\n",
    "        df = pd.read_csv(file_dict[name])\n",
    "\n",
    "        # Column names\n",
    "        ALL_COLUMNS = list(df.columns)\n",
    "        SELECT_COLUMNS = [col for col in ALL_COLUMNS if col.startswith(\"dataset_\")]\n",
    "        FOLD_COLUMNS = [col for col in ALL_COLUMNS if col.startswith(\"fold_\") or col == \"WT\"]\n",
    "        BIND_COLUMNS = [col for col in ALL_COLUMNS if col.startswith(\"bind_\") or col == \"WT\"]\n",
    "        TARGET_COLUMN = \"fitness\"\n",
    "        TARGET_SD_COLUMN = \"fitness_sd\"\n",
    "        SEQUENCE_COLUMN = \"variant_sequence\"\n",
    "        TRAINING_SET_COLUMN = \"training_set\"\n",
    "\n",
    "        # Save (sparse) tensors\n",
    "        data_dict[name][\"select\"] = jnp.array(df[SELECT_COLUMNS], dtype=jnp.float32)\n",
    "        data_dict[name][\"fold\"] = jnp.array(df[FOLD_COLUMNS], dtype=jnp.float32)\n",
    "        data_dict[name][\"bind\"] = jnp.array(df[BIND_COLUMNS], dtype=jnp.float32)\n",
    "        data_dict[name][\"target\"] = jnp.array(df[TARGET_COLUMN], dtype=jnp.float32)\n",
    "        data_dict[name][\"target_sd\"] = jnp.array(df[TARGET_SD_COLUMN], dtype=jnp.float32)\n",
    "\n",
    "        # Save remaining columns\n",
    "        if SEQUENCE_COLUMN in df.columns:\n",
    "            data_dict[name][\"sequence\"] = np.array(df[SEQUENCE_COLUMN].values)\n",
    "        if TRAINING_SET_COLUMN in df.columns:\n",
    "            data_dict[name][\"training_set\"] = jnp.expand_dims(jnp.array(df[TRAINING_SET_COLUMN].values), axis=-1)\n",
    "\n",
    "        data_dict[name][\"fold_colnames\"] = np.array([col.replace(\"fold_\", \"\") for col in FOLD_COLUMNS])\n",
    "        data_dict[name][\"bind_colnames\"] = np.array([col.replace(\"bind_\", \"\") for col in BIND_COLUMNS])\n",
    "\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "4f147e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_file = '/Users/pierredemetz/UCL_work/Crick/doubledeepms/Results//Data/mochi/GRB2-SH3/mochi__fit_tmodel_3state_sparse_dimsum128_subsample100p//dataset_train.txt'\n",
    "\n",
    "data_valid_file = '/Users/pierredemetz/UCL_work/Crick/doubledeepms/Results//Data/mochi/GRB2-SH3/mochi__fit_tmodel_3state_sparse_dimsum128_subsample100p//dataset_valid.txt' \n",
    "\n",
    "data_obs_file = '/Users/pierredemetz/UCL_work/Crick/doubledeepms/Results//Data/mochi/GRB2-SH3/mochi__fit_tmodel_3state_sparse_dimsum128_subsample100p//dataset_all.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "093b77a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the rng\n",
    "random_seed = 42\n",
    "rng = jax.random.PRNGKey(random_seed)\n",
    "\n",
    "#Load model data\n",
    "model_data = load_model_data({\n",
    "    \"train\": data_train_file,\n",
    "    \"valid\": data_valid_file,\n",
    "    \"obs\": data_obs_file\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "b8828f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the rng\n",
    "random_seed = 42\n",
    "rng = jax.random.PRNGKey(random_seed)\n",
    "\n",
    "#Load model data\n",
    "model_data_jax = load_model_data_jax({\n",
    "    \"train\": data_train_file,\n",
    "    \"valid\": data_valid_file,\n",
    "    \"obs\": data_obs_file\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "0448c788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'select': DeviceArray([[0., 1.],\n",
       "              [0., 1.],\n",
       "              [1., 0.],\n",
       "              ...,\n",
       "              [1., 0.],\n",
       "              [1., 0.],\n",
       "              [0., 1.]], dtype=float32),\n",
       " 'fold': DeviceArray([[1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              ...,\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " 'bind': DeviceArray([[1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              ...,\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " 'target': DeviceArray([-0.33598602, -0.8518485 , -1.0957463 , ..., -0.26487023,\n",
       "              -1.166961  , -0.66433465], dtype=float32),\n",
       " 'target_sd': DeviceArray([0.11158013, 0.17281719, 0.09720125, ..., 0.22753495,\n",
       "              0.36643863, 0.15336636], dtype=float32),\n",
       " 'sequence': array(['0000000000000000000000000000000000000000000000000L000000',\n",
       "        '00000000I0000000000000000000000000000000Q000000000000000',\n",
       "        '000000000000000000000000000000000000000V000000W000000000', ...,\n",
       "        '000000000M0000000000000000000000000000000000000000000S00',\n",
       "        '000000000000000000K0000000000000000T00000000000000000000',\n",
       "        '000000000N0000000000000000000000000000000000S00000000000'],\n",
       "       dtype=object),\n",
       " 'training_set': DeviceArray([[1],\n",
       "              [1],\n",
       "              [1],\n",
       "              ...,\n",
       "              [1],\n",
       "              [1],\n",
       "              [1]], dtype=int32),\n",
       " 'fold_colnames': array(['WT', 'T1A', 'T1C', ..., 'N56V', 'N56W', 'N56Y'], dtype='<U4'),\n",
       " 'bind_colnames': array(['WT', 'T1A', 'T1E', 'T1G', 'T1I', 'T1K', 'T1L', 'T1M', 'T1N',\n",
       "        'T1P', 'T1R', 'T1S', 'T1V', 'Y2A', 'Y2C', 'Y2D', 'Y2F', 'Y2H',\n",
       "        'Y2I', 'Y2K', 'Y2L', 'Y2N', 'Y2Q', 'Y2R', 'Y2S', 'Y2T', 'Y2W',\n",
       "        'V3A', 'V3C', 'V3D', 'V3E', 'V3F', 'V3G', 'V3H', 'V3I', 'V3L',\n",
       "        'V3N', 'V3P', 'V3S', 'V3T', 'V3Y', 'Q4E', 'Q4G', 'Q4H', 'Q4K',\n",
       "        'Q4L', 'Q4M', 'Q4N', 'Q4P', 'Q4R', 'Q4S', 'Q4T', 'Q4V', 'Q4W',\n",
       "        'Q4Y', 'A5D', 'A5E', 'A5G', 'A5I', 'A5N', 'A5P', 'A5S', 'A5T',\n",
       "        'A5V', 'A5Y', 'L6C', 'L6F', 'L6H', 'L6I', 'L6N', 'L6P', 'L6Q',\n",
       "        'L6R', 'L6S', 'L6V', 'L6Y', 'F7A', 'F7C', 'F7H', 'F7I', 'F7L',\n",
       "        'F7M', 'F7N', 'F7P', 'F7S', 'F7T', 'F7V', 'F7Y', 'D8A', 'D8C',\n",
       "        'D8E', 'D8F', 'D8G', 'D8H', 'D8I', 'D8K', 'D8N', 'D8Q', 'D8R',\n",
       "        'D8S', 'D8T', 'D8V', 'D8Y', 'F9A', 'F9C', 'F9H', 'F9I', 'F9L',\n",
       "        'F9M', 'F9N', 'F9P', 'F9S', 'F9T', 'F9V', 'F9Y', 'D10A', 'D10C',\n",
       "        'D10E', 'D10F', 'D10G', 'D10H', 'D10I', 'D10K', 'D10L', 'D10N',\n",
       "        'D10S', 'D10T', 'D10V', 'D10Y', 'P11A', 'P11D', 'P11F', 'P11H',\n",
       "        'P11I', 'P11L', 'P11N', 'P11Q', 'P11R', 'P11S', 'P11T', 'P11Y',\n",
       "        'Q12A', 'Q12D', 'Q12E', 'Q12G', 'Q12H', 'Q12K', 'Q12L', 'Q12M',\n",
       "        'Q12N', 'Q12P', 'Q12R', 'Q12T', 'Q12V', 'Q12W', 'Q12Y', 'E13A',\n",
       "        'E13D', 'E13G', 'E13K', 'E13L', 'E13M', 'E13N', 'E13Q', 'E13R',\n",
       "        'E13V', 'E13Y', 'D14A', 'D14C', 'D14E', 'D14F', 'D14G', 'D14H',\n",
       "        'D14I', 'D14K', 'D14L', 'D14N', 'D14Q', 'D14R', 'D14S', 'D14V',\n",
       "        'D14Y', 'G15A', 'G15C', 'G15D', 'G15E', 'G15I', 'G15K', 'G15L',\n",
       "        'G15Q', 'G15R', 'G15S', 'G15V', 'G15W', 'E16A', 'E16D', 'E16G',\n",
       "        'E16K', 'E16L', 'E16M', 'E16N', 'E16Q', 'E16R', 'E16V', 'E16W',\n",
       "        'E16Y', 'L17A', 'L17H', 'L17I', 'L17K', 'L17M', 'L17P', 'L17Q',\n",
       "        'L17R', 'L17S', 'L17T', 'L17V', 'L17W', 'G18A', 'G18C', 'G18D',\n",
       "        'G18E', 'G18F', 'G18H', 'G18I', 'G18N', 'G18R', 'G18S', 'G18T',\n",
       "        'G18V', 'G18W', 'G18Y', 'F19C', 'F19H', 'F19I', 'F19L', 'F19M',\n",
       "        'F19N', 'F19P', 'F19R', 'F19S', 'F19T', 'F19V', 'F19Y', 'R20A',\n",
       "        'R20C', 'R20D', 'R20F', 'R20G', 'R20H', 'R20I', 'R20L', 'R20N',\n",
       "        'R20P', 'R20Q', 'R20S', 'R20T', 'R20W', 'R20Y', 'R21A', 'R21C',\n",
       "        'R21E', 'R21G', 'R21H', 'R21I', 'R21K', 'R21L', 'R21M', 'R21P',\n",
       "        'R21Q', 'R21S', 'R21T', 'R21V', 'R21W', 'G22A', 'G22C', 'G22D',\n",
       "        'G22E', 'G22I', 'G22K', 'G22L', 'G22Q', 'G22R', 'G22S', 'G22V',\n",
       "        'G22W', 'D23A', 'D23C', 'D23E', 'D23F', 'D23G', 'D23H', 'D23I',\n",
       "        'D23K', 'D23L', 'D23N', 'D23S', 'D23V', 'D23Y', 'F24A', 'F24C',\n",
       "        'F24D', 'F24G', 'F24H', 'F24I', 'F24L', 'F24M', 'F24N', 'F24P',\n",
       "        'F24R', 'F24S', 'F24T', 'F24V', 'F24W', 'F24Y', 'I25A', 'I25D',\n",
       "        'I25F', 'I25H', 'I25K', 'I25L', 'I25M', 'I25N', 'I25P', 'I25R',\n",
       "        'I25S', 'I25T', 'I25V', 'I25Y', 'H26A', 'H26C', 'H26D', 'H26E',\n",
       "        'H26F', 'H26G', 'H26I', 'H26K', 'H26L', 'H26N', 'H26P', 'H26Q',\n",
       "        'H26R', 'H26S', 'H26T', 'H26V', 'H26Y', 'V27A', 'V27C', 'V27D',\n",
       "        'V27E', 'V27F', 'V27G', 'V27H', 'V27I', 'V27L', 'V27M', 'V27N',\n",
       "        'V27S', 'V27T', 'V27Y', 'M28A', 'M28E', 'M28F', 'M28G', 'M28I',\n",
       "        'M28K', 'M28L', 'M28N', 'M28P', 'M28Q', 'M28R', 'M28S', 'M28T',\n",
       "        'M28V', 'M28W', 'M28Y', 'D29A', 'D29C', 'D29E', 'D29F', 'D29G',\n",
       "        'D29H', 'D29I', 'D29K', 'D29L', 'D29N', 'D29P', 'D29S', 'D29V',\n",
       "        'D29Y', 'N30A', 'N30C', 'N30D', 'N30E', 'N30F', 'N30G', 'N30H',\n",
       "        'N30I', 'N30K', 'N30M', 'N30R', 'N30S', 'N30T', 'N30V', 'N30Y',\n",
       "        'S31A', 'S31E', 'S31F', 'S31I', 'S31K', 'S31L', 'S31P', 'S31Q',\n",
       "        'S31R', 'S31T', 'S31V', 'S31W', 'S31Y', 'D32A', 'D32C', 'D32E',\n",
       "        'D32F', 'D32G', 'D32H', 'D32I', 'D32K', 'D32N', 'D32S', 'D32T',\n",
       "        'D32V', 'D32Y', 'P33A', 'P33C', 'P33D', 'P33F', 'P33G', 'P33H',\n",
       "        'P33I', 'P33K', 'P33L', 'P33N', 'P33Q', 'P33R', 'P33S', 'P33T',\n",
       "        'P33V', 'P33Y', 'N34A', 'N34C', 'N34D', 'N34E', 'N34F', 'N34G',\n",
       "        'N34H', 'N34I', 'N34K', 'N34L', 'N34Q', 'N34R', 'N34S', 'N34T',\n",
       "        'N34V', 'N34Y', 'W35A', 'W35C', 'W35E', 'W35F', 'W35G', 'W35K',\n",
       "        'W35L', 'W35M', 'W35Q', 'W35R', 'W35S', 'W35T', 'W35V', 'W35Y',\n",
       "        'W36C', 'W36F', 'W36G', 'W36K', 'W36L', 'W36M', 'W36Q', 'W36R',\n",
       "        'W36S', 'W36T', 'W36V', 'W36Y', 'K37D', 'K37E', 'K37G', 'K37I',\n",
       "        'K37L', 'K37M', 'K37N', 'K37Q', 'K37R', 'K37S', 'K37T', 'K37V',\n",
       "        'K37Y', 'G38A', 'G38C', 'G38D', 'G38E', 'G38I', 'G38K', 'G38L',\n",
       "        'G38Q', 'G38R', 'G38S', 'G38T', 'G38V', 'G38W', 'A39C', 'A39D',\n",
       "        'A39E', 'A39F', 'A39G', 'A39I', 'A39N', 'A39P', 'A39S', 'A39T',\n",
       "        'A39V', 'A39Y', 'C40F', 'C40G', 'C40H', 'C40I', 'C40L', 'C40N',\n",
       "        'C40R', 'C40S', 'C40W', 'C40Y', 'H41C', 'H41D', 'H41E', 'H41F',\n",
       "        'H41G', 'H41I', 'H41K', 'H41L', 'H41N', 'H41P', 'H41Q', 'H41R',\n",
       "        'H41S', 'H41T', 'H41V', 'H41Y', 'G42A', 'G42C', 'G42D', 'G42E',\n",
       "        'G42F', 'G42K', 'G42L', 'G42M', 'G42Q', 'G42R', 'G42S', 'G42T',\n",
       "        'G42V', 'G42W', 'Q43D', 'Q43E', 'Q43H', 'Q43K', 'Q43L', 'Q43M',\n",
       "        'Q43N', 'Q43P', 'Q43R', 'Q43V', 'Q43W', 'Q43Y', 'T44A', 'T44C',\n",
       "        'T44D', 'T44F', 'T44G', 'T44I', 'T44K', 'T44M', 'T44N', 'T44P',\n",
       "        'T44R', 'T44S', 'T44V', 'T44Y', 'G45A', 'G45C', 'G45D', 'G45E',\n",
       "        'G45F', 'G45H', 'G45I', 'G45L', 'G45N', 'G45P', 'G45R', 'G45S',\n",
       "        'G45T', 'G45V', 'G45W', 'G45Y', 'M46A', 'M46E', 'M46F', 'M46I',\n",
       "        'M46K', 'M46L', 'M46N', 'M46R', 'M46S', 'M46T', 'M46V', 'M46W',\n",
       "        'F47C', 'F47D', 'F47H', 'F47I', 'F47L', 'F47N', 'F47P', 'F47S',\n",
       "        'F47T', 'F47V', 'F47Y', 'P48A', 'P48F', 'P48H', 'P48I', 'P48L',\n",
       "        'P48N', 'P48Q', 'P48R', 'P48S', 'P48T', 'P48Y', 'R49A', 'R49C',\n",
       "        'R49D', 'R49F', 'R49G', 'R49H', 'R49I', 'R49L', 'R49N', 'R49P',\n",
       "        'R49Q', 'R49S', 'R49T', 'R49W', 'R49Y', 'N50C', 'N50D', 'N50E',\n",
       "        'N50F', 'N50G', 'N50H', 'N50I', 'N50K', 'N50L', 'N50M', 'N50Q',\n",
       "        'N50R', 'N50S', 'N50T', 'N50V', 'N50Y', 'Y51C', 'Y51D', 'Y51F',\n",
       "        'Y51H', 'Y51I', 'Y51K', 'Y51L', 'Y51N', 'Y51Q', 'Y51R', 'Y51S',\n",
       "        'Y51T', 'Y51V', 'Y51W', 'V52A', 'V52C', 'V52D', 'V52E', 'V52F',\n",
       "        'V52G', 'V52I', 'V52L', 'V52M', 'V52N', 'V52P', 'V52S', 'V52T',\n",
       "        'V52Y', 'T53A', 'T53D', 'T53F', 'T53G', 'T53I', 'T53K', 'T53M',\n",
       "        'T53N', 'T53P', 'T53R', 'T53S', 'T53V', 'T53Y', 'P54A', 'P54D',\n",
       "        'P54F', 'P54H', 'P54I', 'P54L', 'P54N', 'P54Q', 'P54R', 'P54S',\n",
       "        'P54T', 'P54V', 'P54Y', 'V55A', 'V55D', 'V55E', 'V55F', 'V55G',\n",
       "        'V55I', 'V55K', 'V55L', 'V55M', 'V55P', 'V55Q', 'V55R', 'V55S',\n",
       "        'V55T', 'N56C', 'N56D', 'N56E', 'N56F', 'N56G', 'N56H', 'N56I',\n",
       "        'N56K', 'N56M', 'N56Q', 'N56R', 'N56S', 'N56T', 'N56V', 'N56Y'],\n",
       "       dtype='<U4')}"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data_jax['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5be83bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'select': <tf.Tensor: shape=(88171, 2), dtype=float32, numpy=\n",
       " array([[0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        ...,\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.]], dtype=float32)>,\n",
       " 'fold': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x111ad0dc0>,\n",
       " 'bind': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x292465f10>,\n",
       " 'target': <tf.Tensor: shape=(88171, 1), dtype=float32, numpy=\n",
       " array([[-0.33598602],\n",
       "        [-0.8518485 ],\n",
       "        [-1.0957463 ],\n",
       "        ...,\n",
       "        [-0.26487023],\n",
       "        [-1.166961  ],\n",
       "        [-0.66433465]], dtype=float32)>,\n",
       " 'target_sd': <tf.Tensor: shape=(88171, 1), dtype=float32, numpy=\n",
       " array([[0.11158013],\n",
       "        [0.17281719],\n",
       "        [0.09720125],\n",
       "        ...,\n",
       "        [0.22753495],\n",
       "        [0.36643863],\n",
       "        [0.15336636]], dtype=float32)>,\n",
       " 'sequence': array([['0000000000000000000000000000000000000000000000000L000000'],\n",
       "        ['00000000I0000000000000000000000000000000Q000000000000000'],\n",
       "        ['000000000000000000000000000000000000000V000000W000000000'],\n",
       "        ...,\n",
       "        ['000000000M0000000000000000000000000000000000000000000S00'],\n",
       "        ['000000000000000000K0000000000000000T00000000000000000000'],\n",
       "        ['000000000N0000000000000000000000000000000000S00000000000']],\n",
       "       dtype=object),\n",
       " 'training_set': array([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        ...,\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]]),\n",
       " 'fold_colnames': array(['WT', 'T1A', 'T1C', ..., 'N56V', 'N56W', 'N56Y'], dtype='<U4'),\n",
       " 'bind_colnames': array(['WT', 'T1A', 'T1E', 'T1G', 'T1I', 'T1K', 'T1L', 'T1M', 'T1N',\n",
       "        'T1P', 'T1R', 'T1S', 'T1V', 'Y2A', 'Y2C', 'Y2D', 'Y2F', 'Y2H',\n",
       "        'Y2I', 'Y2K', 'Y2L', 'Y2N', 'Y2Q', 'Y2R', 'Y2S', 'Y2T', 'Y2W',\n",
       "        'V3A', 'V3C', 'V3D', 'V3E', 'V3F', 'V3G', 'V3H', 'V3I', 'V3L',\n",
       "        'V3N', 'V3P', 'V3S', 'V3T', 'V3Y', 'Q4E', 'Q4G', 'Q4H', 'Q4K',\n",
       "        'Q4L', 'Q4M', 'Q4N', 'Q4P', 'Q4R', 'Q4S', 'Q4T', 'Q4V', 'Q4W',\n",
       "        'Q4Y', 'A5D', 'A5E', 'A5G', 'A5I', 'A5N', 'A5P', 'A5S', 'A5T',\n",
       "        'A5V', 'A5Y', 'L6C', 'L6F', 'L6H', 'L6I', 'L6N', 'L6P', 'L6Q',\n",
       "        'L6R', 'L6S', 'L6V', 'L6Y', 'F7A', 'F7C', 'F7H', 'F7I', 'F7L',\n",
       "        'F7M', 'F7N', 'F7P', 'F7S', 'F7T', 'F7V', 'F7Y', 'D8A', 'D8C',\n",
       "        'D8E', 'D8F', 'D8G', 'D8H', 'D8I', 'D8K', 'D8N', 'D8Q', 'D8R',\n",
       "        'D8S', 'D8T', 'D8V', 'D8Y', 'F9A', 'F9C', 'F9H', 'F9I', 'F9L',\n",
       "        'F9M', 'F9N', 'F9P', 'F9S', 'F9T', 'F9V', 'F9Y', 'D10A', 'D10C',\n",
       "        'D10E', 'D10F', 'D10G', 'D10H', 'D10I', 'D10K', 'D10L', 'D10N',\n",
       "        'D10S', 'D10T', 'D10V', 'D10Y', 'P11A', 'P11D', 'P11F', 'P11H',\n",
       "        'P11I', 'P11L', 'P11N', 'P11Q', 'P11R', 'P11S', 'P11T', 'P11Y',\n",
       "        'Q12A', 'Q12D', 'Q12E', 'Q12G', 'Q12H', 'Q12K', 'Q12L', 'Q12M',\n",
       "        'Q12N', 'Q12P', 'Q12R', 'Q12T', 'Q12V', 'Q12W', 'Q12Y', 'E13A',\n",
       "        'E13D', 'E13G', 'E13K', 'E13L', 'E13M', 'E13N', 'E13Q', 'E13R',\n",
       "        'E13V', 'E13Y', 'D14A', 'D14C', 'D14E', 'D14F', 'D14G', 'D14H',\n",
       "        'D14I', 'D14K', 'D14L', 'D14N', 'D14Q', 'D14R', 'D14S', 'D14V',\n",
       "        'D14Y', 'G15A', 'G15C', 'G15D', 'G15E', 'G15I', 'G15K', 'G15L',\n",
       "        'G15Q', 'G15R', 'G15S', 'G15V', 'G15W', 'E16A', 'E16D', 'E16G',\n",
       "        'E16K', 'E16L', 'E16M', 'E16N', 'E16Q', 'E16R', 'E16V', 'E16W',\n",
       "        'E16Y', 'L17A', 'L17H', 'L17I', 'L17K', 'L17M', 'L17P', 'L17Q',\n",
       "        'L17R', 'L17S', 'L17T', 'L17V', 'L17W', 'G18A', 'G18C', 'G18D',\n",
       "        'G18E', 'G18F', 'G18H', 'G18I', 'G18N', 'G18R', 'G18S', 'G18T',\n",
       "        'G18V', 'G18W', 'G18Y', 'F19C', 'F19H', 'F19I', 'F19L', 'F19M',\n",
       "        'F19N', 'F19P', 'F19R', 'F19S', 'F19T', 'F19V', 'F19Y', 'R20A',\n",
       "        'R20C', 'R20D', 'R20F', 'R20G', 'R20H', 'R20I', 'R20L', 'R20N',\n",
       "        'R20P', 'R20Q', 'R20S', 'R20T', 'R20W', 'R20Y', 'R21A', 'R21C',\n",
       "        'R21E', 'R21G', 'R21H', 'R21I', 'R21K', 'R21L', 'R21M', 'R21P',\n",
       "        'R21Q', 'R21S', 'R21T', 'R21V', 'R21W', 'G22A', 'G22C', 'G22D',\n",
       "        'G22E', 'G22I', 'G22K', 'G22L', 'G22Q', 'G22R', 'G22S', 'G22V',\n",
       "        'G22W', 'D23A', 'D23C', 'D23E', 'D23F', 'D23G', 'D23H', 'D23I',\n",
       "        'D23K', 'D23L', 'D23N', 'D23S', 'D23V', 'D23Y', 'F24A', 'F24C',\n",
       "        'F24D', 'F24G', 'F24H', 'F24I', 'F24L', 'F24M', 'F24N', 'F24P',\n",
       "        'F24R', 'F24S', 'F24T', 'F24V', 'F24W', 'F24Y', 'I25A', 'I25D',\n",
       "        'I25F', 'I25H', 'I25K', 'I25L', 'I25M', 'I25N', 'I25P', 'I25R',\n",
       "        'I25S', 'I25T', 'I25V', 'I25Y', 'H26A', 'H26C', 'H26D', 'H26E',\n",
       "        'H26F', 'H26G', 'H26I', 'H26K', 'H26L', 'H26N', 'H26P', 'H26Q',\n",
       "        'H26R', 'H26S', 'H26T', 'H26V', 'H26Y', 'V27A', 'V27C', 'V27D',\n",
       "        'V27E', 'V27F', 'V27G', 'V27H', 'V27I', 'V27L', 'V27M', 'V27N',\n",
       "        'V27S', 'V27T', 'V27Y', 'M28A', 'M28E', 'M28F', 'M28G', 'M28I',\n",
       "        'M28K', 'M28L', 'M28N', 'M28P', 'M28Q', 'M28R', 'M28S', 'M28T',\n",
       "        'M28V', 'M28W', 'M28Y', 'D29A', 'D29C', 'D29E', 'D29F', 'D29G',\n",
       "        'D29H', 'D29I', 'D29K', 'D29L', 'D29N', 'D29P', 'D29S', 'D29V',\n",
       "        'D29Y', 'N30A', 'N30C', 'N30D', 'N30E', 'N30F', 'N30G', 'N30H',\n",
       "        'N30I', 'N30K', 'N30M', 'N30R', 'N30S', 'N30T', 'N30V', 'N30Y',\n",
       "        'S31A', 'S31E', 'S31F', 'S31I', 'S31K', 'S31L', 'S31P', 'S31Q',\n",
       "        'S31R', 'S31T', 'S31V', 'S31W', 'S31Y', 'D32A', 'D32C', 'D32E',\n",
       "        'D32F', 'D32G', 'D32H', 'D32I', 'D32K', 'D32N', 'D32S', 'D32T',\n",
       "        'D32V', 'D32Y', 'P33A', 'P33C', 'P33D', 'P33F', 'P33G', 'P33H',\n",
       "        'P33I', 'P33K', 'P33L', 'P33N', 'P33Q', 'P33R', 'P33S', 'P33T',\n",
       "        'P33V', 'P33Y', 'N34A', 'N34C', 'N34D', 'N34E', 'N34F', 'N34G',\n",
       "        'N34H', 'N34I', 'N34K', 'N34L', 'N34Q', 'N34R', 'N34S', 'N34T',\n",
       "        'N34V', 'N34Y', 'W35A', 'W35C', 'W35E', 'W35F', 'W35G', 'W35K',\n",
       "        'W35L', 'W35M', 'W35Q', 'W35R', 'W35S', 'W35T', 'W35V', 'W35Y',\n",
       "        'W36C', 'W36F', 'W36G', 'W36K', 'W36L', 'W36M', 'W36Q', 'W36R',\n",
       "        'W36S', 'W36T', 'W36V', 'W36Y', 'K37D', 'K37E', 'K37G', 'K37I',\n",
       "        'K37L', 'K37M', 'K37N', 'K37Q', 'K37R', 'K37S', 'K37T', 'K37V',\n",
       "        'K37Y', 'G38A', 'G38C', 'G38D', 'G38E', 'G38I', 'G38K', 'G38L',\n",
       "        'G38Q', 'G38R', 'G38S', 'G38T', 'G38V', 'G38W', 'A39C', 'A39D',\n",
       "        'A39E', 'A39F', 'A39G', 'A39I', 'A39N', 'A39P', 'A39S', 'A39T',\n",
       "        'A39V', 'A39Y', 'C40F', 'C40G', 'C40H', 'C40I', 'C40L', 'C40N',\n",
       "        'C40R', 'C40S', 'C40W', 'C40Y', 'H41C', 'H41D', 'H41E', 'H41F',\n",
       "        'H41G', 'H41I', 'H41K', 'H41L', 'H41N', 'H41P', 'H41Q', 'H41R',\n",
       "        'H41S', 'H41T', 'H41V', 'H41Y', 'G42A', 'G42C', 'G42D', 'G42E',\n",
       "        'G42F', 'G42K', 'G42L', 'G42M', 'G42Q', 'G42R', 'G42S', 'G42T',\n",
       "        'G42V', 'G42W', 'Q43D', 'Q43E', 'Q43H', 'Q43K', 'Q43L', 'Q43M',\n",
       "        'Q43N', 'Q43P', 'Q43R', 'Q43V', 'Q43W', 'Q43Y', 'T44A', 'T44C',\n",
       "        'T44D', 'T44F', 'T44G', 'T44I', 'T44K', 'T44M', 'T44N', 'T44P',\n",
       "        'T44R', 'T44S', 'T44V', 'T44Y', 'G45A', 'G45C', 'G45D', 'G45E',\n",
       "        'G45F', 'G45H', 'G45I', 'G45L', 'G45N', 'G45P', 'G45R', 'G45S',\n",
       "        'G45T', 'G45V', 'G45W', 'G45Y', 'M46A', 'M46E', 'M46F', 'M46I',\n",
       "        'M46K', 'M46L', 'M46N', 'M46R', 'M46S', 'M46T', 'M46V', 'M46W',\n",
       "        'F47C', 'F47D', 'F47H', 'F47I', 'F47L', 'F47N', 'F47P', 'F47S',\n",
       "        'F47T', 'F47V', 'F47Y', 'P48A', 'P48F', 'P48H', 'P48I', 'P48L',\n",
       "        'P48N', 'P48Q', 'P48R', 'P48S', 'P48T', 'P48Y', 'R49A', 'R49C',\n",
       "        'R49D', 'R49F', 'R49G', 'R49H', 'R49I', 'R49L', 'R49N', 'R49P',\n",
       "        'R49Q', 'R49S', 'R49T', 'R49W', 'R49Y', 'N50C', 'N50D', 'N50E',\n",
       "        'N50F', 'N50G', 'N50H', 'N50I', 'N50K', 'N50L', 'N50M', 'N50Q',\n",
       "        'N50R', 'N50S', 'N50T', 'N50V', 'N50Y', 'Y51C', 'Y51D', 'Y51F',\n",
       "        'Y51H', 'Y51I', 'Y51K', 'Y51L', 'Y51N', 'Y51Q', 'Y51R', 'Y51S',\n",
       "        'Y51T', 'Y51V', 'Y51W', 'V52A', 'V52C', 'V52D', 'V52E', 'V52F',\n",
       "        'V52G', 'V52I', 'V52L', 'V52M', 'V52N', 'V52P', 'V52S', 'V52T',\n",
       "        'V52Y', 'T53A', 'T53D', 'T53F', 'T53G', 'T53I', 'T53K', 'T53M',\n",
       "        'T53N', 'T53P', 'T53R', 'T53S', 'T53V', 'T53Y', 'P54A', 'P54D',\n",
       "        'P54F', 'P54H', 'P54I', 'P54L', 'P54N', 'P54Q', 'P54R', 'P54S',\n",
       "        'P54T', 'P54V', 'P54Y', 'V55A', 'V55D', 'V55E', 'V55F', 'V55G',\n",
       "        'V55I', 'V55K', 'V55L', 'V55M', 'V55P', 'V55Q', 'V55R', 'V55S',\n",
       "        'V55T', 'N56C', 'N56D', 'N56E', 'N56F', 'N56G', 'N56H', 'N56I',\n",
       "        'N56K', 'N56M', 'N56Q', 'N56R', 'N56S', 'N56T', 'N56V', 'N56Y'],\n",
       "       dtype='<U4')}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46a13bc",
   "metadata": {},
   "source": [
    "# Resample training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f606fc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resample training data\n",
    "def resample_training_data(tensor_dict, n_resamplings, rand_seed):\n",
    "    \n",
    "  #Resample observed fitness from error distribution\n",
    "  np.random.seed(rand_seed)\n",
    "  observed_fitness = np.array(tensor_dict[\"target\"])\n",
    "  observed_fitness_sd = np.array(tensor_dict[\"target_sd\"])\n",
    "    \n",
    "  observed_fitness_resample = np.array(\n",
    "    [np.array(\n",
    "      [observed_fitness[i]+np.random.normal(0, observed_fitness_sd[i]) for i in range(len(observed_fitness))])\n",
    "    for j in range(n_resamplings)])\n",
    "  #Save new data\n",
    "    \n",
    "  tensor_dict[\"target\"] = tf.expand_dims(tf.convert_to_tensor(np.ravel(observed_fitness_resample), np.float32), -1)\n",
    "  tensor_dict[\"select\"] = tf.concat([tensor_dict[\"select\"] for i in range(n_resamplings)], axis = 0)\n",
    "  tensor_dict[\"fold\"] = tf.sparse.concat(axis = 0, sp_inputs=[tensor_dict[\"fold\"] for i in range(n_resamplings)])\n",
    "  tensor_dict[\"bind\"] = tf.sparse.concat(axis = 0, sp_inputs=[tensor_dict[\"bind\"] for i in range(n_resamplings)])\n",
    "    \n",
    "  return(tensor_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fe2f27",
   "metadata": {},
   "source": [
    "# Resample training data jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "362e4b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_training_data_jax(tensor_dict, n_resamplings, rng):\n",
    "    # Resample observed fitness from error distribution\n",
    "    \n",
    "    observed_fitness = tensor_dict[\"target\"]\n",
    "    observed_fitness_sd = tensor_dict[\"target_sd\"]\n",
    "    \n",
    "    observed_fitness_resample = jnp.array(\n",
    "    [jnp.array(\n",
    "      [observed_fitness[i]+(observed_fitness_sd[i] * jax.random.normal(rng, shape=(1,))) for i in range(len(observed_fitness))])\n",
    "    for j in range(n_resamplings)]\n",
    "    )\n",
    "    print('here')\n",
    "    #Save new data\n",
    "\n",
    "    tensor_dict[\"target\"] = jax.device_put(jnp.expand_dims(observed_fitness_resample.ravel(), -1))\n",
    "\n",
    "    select_tensors = [tensor_dict[\"select\"] for i in range(n_resamplings)]  # Assuming n_resamplings is defined\n",
    "    tensor_dict[\"select\"] = jnp.concatenate(select_tensors, axis=0)\n",
    "\n",
    "    fold_matrices = [tensor_dict[\"fold\"] for i in range(n_resamplings)]  # Assuming fold tensors are JAX-compatible sparse matrices\n",
    "    tensor_dict[\"fold\"] = jnp.concatenate(fold_matrices, axis=0)\n",
    "\n",
    "    bind_matrices = [tensor_dict[\"bind\"] for i in range(n_resamplings)]  # Assuming bind tensors are JAX-compatible sparse matrices\n",
    "    tensor_dict[\"bind\"] = jnp.concatenate(bind_matrices, axis=0)\n",
    "    \n",
    "    return tensor_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "8bc89ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    }
   ],
   "source": [
    "#Resample training data\n",
    "num_resamplings = 1\n",
    "\n",
    "#create the rng\n",
    "random_seed = 42\n",
    "rng = jax.random.PRNGKey(random_seed)\n",
    "\n",
    "if num_resamplings!=0:\n",
    "    model_data_jax[\"train\"] = resample_training_data_jax(\n",
    "        tensor_dict = model_data_jax[\"train\"],\n",
    "        n_resamplings = num_resamplings,\n",
    "        rng = rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e536764",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resample training data\n",
    "num_resamplings = 1\n",
    "\n",
    "#keep a random seed\n",
    "random_seed = 42\n",
    "\n",
    "if num_resamplings!=0:\n",
    "    model_data[\"train\"] = resample_training_data(\n",
    "        tensor_dict = model_data[\"train\"],\n",
    "        n_resamplings = num_resamplings,\n",
    "        rand_seed = random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "ffd106ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'select': DeviceArray([[0., 1.],\n",
       "              [0., 1.],\n",
       "              [1., 0.],\n",
       "              ...,\n",
       "              [1., 0.],\n",
       "              [1., 0.],\n",
       "              [0., 1.]], dtype=float32),\n",
       " 'fold': DeviceArray([[1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              ...,\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " 'bind': DeviceArray([[1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              ...,\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.],\n",
       "              [1., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " 'target': DeviceArray([[-0.35659617],\n",
       "              [-0.88376987],\n",
       "              [-1.1137005 ],\n",
       "              ...,\n",
       "              [-0.3068986 ],\n",
       "              [-1.2346464 ],\n",
       "              [-0.69266325]], dtype=float32),\n",
       " 'target_sd': DeviceArray([0.11158013, 0.17281719, 0.09720125, ..., 0.22753495,\n",
       "              0.36643863, 0.15336636], dtype=float32),\n",
       " 'sequence': array(['0000000000000000000000000000000000000000000000000L000000',\n",
       "        '00000000I0000000000000000000000000000000Q000000000000000',\n",
       "        '000000000000000000000000000000000000000V000000W000000000', ...,\n",
       "        '000000000M0000000000000000000000000000000000000000000S00',\n",
       "        '000000000000000000K0000000000000000T00000000000000000000',\n",
       "        '000000000N0000000000000000000000000000000000S00000000000'],\n",
       "       dtype=object),\n",
       " 'training_set': DeviceArray([[1],\n",
       "              [1],\n",
       "              [1],\n",
       "              ...,\n",
       "              [1],\n",
       "              [1],\n",
       "              [1]], dtype=int32),\n",
       " 'fold_colnames': array(['WT', 'T1A', 'T1C', ..., 'N56V', 'N56W', 'N56Y'], dtype='<U4'),\n",
       " 'bind_colnames': array(['WT', 'T1A', 'T1E', 'T1G', 'T1I', 'T1K', 'T1L', 'T1M', 'T1N',\n",
       "        'T1P', 'T1R', 'T1S', 'T1V', 'Y2A', 'Y2C', 'Y2D', 'Y2F', 'Y2H',\n",
       "        'Y2I', 'Y2K', 'Y2L', 'Y2N', 'Y2Q', 'Y2R', 'Y2S', 'Y2T', 'Y2W',\n",
       "        'V3A', 'V3C', 'V3D', 'V3E', 'V3F', 'V3G', 'V3H', 'V3I', 'V3L',\n",
       "        'V3N', 'V3P', 'V3S', 'V3T', 'V3Y', 'Q4E', 'Q4G', 'Q4H', 'Q4K',\n",
       "        'Q4L', 'Q4M', 'Q4N', 'Q4P', 'Q4R', 'Q4S', 'Q4T', 'Q4V', 'Q4W',\n",
       "        'Q4Y', 'A5D', 'A5E', 'A5G', 'A5I', 'A5N', 'A5P', 'A5S', 'A5T',\n",
       "        'A5V', 'A5Y', 'L6C', 'L6F', 'L6H', 'L6I', 'L6N', 'L6P', 'L6Q',\n",
       "        'L6R', 'L6S', 'L6V', 'L6Y', 'F7A', 'F7C', 'F7H', 'F7I', 'F7L',\n",
       "        'F7M', 'F7N', 'F7P', 'F7S', 'F7T', 'F7V', 'F7Y', 'D8A', 'D8C',\n",
       "        'D8E', 'D8F', 'D8G', 'D8H', 'D8I', 'D8K', 'D8N', 'D8Q', 'D8R',\n",
       "        'D8S', 'D8T', 'D8V', 'D8Y', 'F9A', 'F9C', 'F9H', 'F9I', 'F9L',\n",
       "        'F9M', 'F9N', 'F9P', 'F9S', 'F9T', 'F9V', 'F9Y', 'D10A', 'D10C',\n",
       "        'D10E', 'D10F', 'D10G', 'D10H', 'D10I', 'D10K', 'D10L', 'D10N',\n",
       "        'D10S', 'D10T', 'D10V', 'D10Y', 'P11A', 'P11D', 'P11F', 'P11H',\n",
       "        'P11I', 'P11L', 'P11N', 'P11Q', 'P11R', 'P11S', 'P11T', 'P11Y',\n",
       "        'Q12A', 'Q12D', 'Q12E', 'Q12G', 'Q12H', 'Q12K', 'Q12L', 'Q12M',\n",
       "        'Q12N', 'Q12P', 'Q12R', 'Q12T', 'Q12V', 'Q12W', 'Q12Y', 'E13A',\n",
       "        'E13D', 'E13G', 'E13K', 'E13L', 'E13M', 'E13N', 'E13Q', 'E13R',\n",
       "        'E13V', 'E13Y', 'D14A', 'D14C', 'D14E', 'D14F', 'D14G', 'D14H',\n",
       "        'D14I', 'D14K', 'D14L', 'D14N', 'D14Q', 'D14R', 'D14S', 'D14V',\n",
       "        'D14Y', 'G15A', 'G15C', 'G15D', 'G15E', 'G15I', 'G15K', 'G15L',\n",
       "        'G15Q', 'G15R', 'G15S', 'G15V', 'G15W', 'E16A', 'E16D', 'E16G',\n",
       "        'E16K', 'E16L', 'E16M', 'E16N', 'E16Q', 'E16R', 'E16V', 'E16W',\n",
       "        'E16Y', 'L17A', 'L17H', 'L17I', 'L17K', 'L17M', 'L17P', 'L17Q',\n",
       "        'L17R', 'L17S', 'L17T', 'L17V', 'L17W', 'G18A', 'G18C', 'G18D',\n",
       "        'G18E', 'G18F', 'G18H', 'G18I', 'G18N', 'G18R', 'G18S', 'G18T',\n",
       "        'G18V', 'G18W', 'G18Y', 'F19C', 'F19H', 'F19I', 'F19L', 'F19M',\n",
       "        'F19N', 'F19P', 'F19R', 'F19S', 'F19T', 'F19V', 'F19Y', 'R20A',\n",
       "        'R20C', 'R20D', 'R20F', 'R20G', 'R20H', 'R20I', 'R20L', 'R20N',\n",
       "        'R20P', 'R20Q', 'R20S', 'R20T', 'R20W', 'R20Y', 'R21A', 'R21C',\n",
       "        'R21E', 'R21G', 'R21H', 'R21I', 'R21K', 'R21L', 'R21M', 'R21P',\n",
       "        'R21Q', 'R21S', 'R21T', 'R21V', 'R21W', 'G22A', 'G22C', 'G22D',\n",
       "        'G22E', 'G22I', 'G22K', 'G22L', 'G22Q', 'G22R', 'G22S', 'G22V',\n",
       "        'G22W', 'D23A', 'D23C', 'D23E', 'D23F', 'D23G', 'D23H', 'D23I',\n",
       "        'D23K', 'D23L', 'D23N', 'D23S', 'D23V', 'D23Y', 'F24A', 'F24C',\n",
       "        'F24D', 'F24G', 'F24H', 'F24I', 'F24L', 'F24M', 'F24N', 'F24P',\n",
       "        'F24R', 'F24S', 'F24T', 'F24V', 'F24W', 'F24Y', 'I25A', 'I25D',\n",
       "        'I25F', 'I25H', 'I25K', 'I25L', 'I25M', 'I25N', 'I25P', 'I25R',\n",
       "        'I25S', 'I25T', 'I25V', 'I25Y', 'H26A', 'H26C', 'H26D', 'H26E',\n",
       "        'H26F', 'H26G', 'H26I', 'H26K', 'H26L', 'H26N', 'H26P', 'H26Q',\n",
       "        'H26R', 'H26S', 'H26T', 'H26V', 'H26Y', 'V27A', 'V27C', 'V27D',\n",
       "        'V27E', 'V27F', 'V27G', 'V27H', 'V27I', 'V27L', 'V27M', 'V27N',\n",
       "        'V27S', 'V27T', 'V27Y', 'M28A', 'M28E', 'M28F', 'M28G', 'M28I',\n",
       "        'M28K', 'M28L', 'M28N', 'M28P', 'M28Q', 'M28R', 'M28S', 'M28T',\n",
       "        'M28V', 'M28W', 'M28Y', 'D29A', 'D29C', 'D29E', 'D29F', 'D29G',\n",
       "        'D29H', 'D29I', 'D29K', 'D29L', 'D29N', 'D29P', 'D29S', 'D29V',\n",
       "        'D29Y', 'N30A', 'N30C', 'N30D', 'N30E', 'N30F', 'N30G', 'N30H',\n",
       "        'N30I', 'N30K', 'N30M', 'N30R', 'N30S', 'N30T', 'N30V', 'N30Y',\n",
       "        'S31A', 'S31E', 'S31F', 'S31I', 'S31K', 'S31L', 'S31P', 'S31Q',\n",
       "        'S31R', 'S31T', 'S31V', 'S31W', 'S31Y', 'D32A', 'D32C', 'D32E',\n",
       "        'D32F', 'D32G', 'D32H', 'D32I', 'D32K', 'D32N', 'D32S', 'D32T',\n",
       "        'D32V', 'D32Y', 'P33A', 'P33C', 'P33D', 'P33F', 'P33G', 'P33H',\n",
       "        'P33I', 'P33K', 'P33L', 'P33N', 'P33Q', 'P33R', 'P33S', 'P33T',\n",
       "        'P33V', 'P33Y', 'N34A', 'N34C', 'N34D', 'N34E', 'N34F', 'N34G',\n",
       "        'N34H', 'N34I', 'N34K', 'N34L', 'N34Q', 'N34R', 'N34S', 'N34T',\n",
       "        'N34V', 'N34Y', 'W35A', 'W35C', 'W35E', 'W35F', 'W35G', 'W35K',\n",
       "        'W35L', 'W35M', 'W35Q', 'W35R', 'W35S', 'W35T', 'W35V', 'W35Y',\n",
       "        'W36C', 'W36F', 'W36G', 'W36K', 'W36L', 'W36M', 'W36Q', 'W36R',\n",
       "        'W36S', 'W36T', 'W36V', 'W36Y', 'K37D', 'K37E', 'K37G', 'K37I',\n",
       "        'K37L', 'K37M', 'K37N', 'K37Q', 'K37R', 'K37S', 'K37T', 'K37V',\n",
       "        'K37Y', 'G38A', 'G38C', 'G38D', 'G38E', 'G38I', 'G38K', 'G38L',\n",
       "        'G38Q', 'G38R', 'G38S', 'G38T', 'G38V', 'G38W', 'A39C', 'A39D',\n",
       "        'A39E', 'A39F', 'A39G', 'A39I', 'A39N', 'A39P', 'A39S', 'A39T',\n",
       "        'A39V', 'A39Y', 'C40F', 'C40G', 'C40H', 'C40I', 'C40L', 'C40N',\n",
       "        'C40R', 'C40S', 'C40W', 'C40Y', 'H41C', 'H41D', 'H41E', 'H41F',\n",
       "        'H41G', 'H41I', 'H41K', 'H41L', 'H41N', 'H41P', 'H41Q', 'H41R',\n",
       "        'H41S', 'H41T', 'H41V', 'H41Y', 'G42A', 'G42C', 'G42D', 'G42E',\n",
       "        'G42F', 'G42K', 'G42L', 'G42M', 'G42Q', 'G42R', 'G42S', 'G42T',\n",
       "        'G42V', 'G42W', 'Q43D', 'Q43E', 'Q43H', 'Q43K', 'Q43L', 'Q43M',\n",
       "        'Q43N', 'Q43P', 'Q43R', 'Q43V', 'Q43W', 'Q43Y', 'T44A', 'T44C',\n",
       "        'T44D', 'T44F', 'T44G', 'T44I', 'T44K', 'T44M', 'T44N', 'T44P',\n",
       "        'T44R', 'T44S', 'T44V', 'T44Y', 'G45A', 'G45C', 'G45D', 'G45E',\n",
       "        'G45F', 'G45H', 'G45I', 'G45L', 'G45N', 'G45P', 'G45R', 'G45S',\n",
       "        'G45T', 'G45V', 'G45W', 'G45Y', 'M46A', 'M46E', 'M46F', 'M46I',\n",
       "        'M46K', 'M46L', 'M46N', 'M46R', 'M46S', 'M46T', 'M46V', 'M46W',\n",
       "        'F47C', 'F47D', 'F47H', 'F47I', 'F47L', 'F47N', 'F47P', 'F47S',\n",
       "        'F47T', 'F47V', 'F47Y', 'P48A', 'P48F', 'P48H', 'P48I', 'P48L',\n",
       "        'P48N', 'P48Q', 'P48R', 'P48S', 'P48T', 'P48Y', 'R49A', 'R49C',\n",
       "        'R49D', 'R49F', 'R49G', 'R49H', 'R49I', 'R49L', 'R49N', 'R49P',\n",
       "        'R49Q', 'R49S', 'R49T', 'R49W', 'R49Y', 'N50C', 'N50D', 'N50E',\n",
       "        'N50F', 'N50G', 'N50H', 'N50I', 'N50K', 'N50L', 'N50M', 'N50Q',\n",
       "        'N50R', 'N50S', 'N50T', 'N50V', 'N50Y', 'Y51C', 'Y51D', 'Y51F',\n",
       "        'Y51H', 'Y51I', 'Y51K', 'Y51L', 'Y51N', 'Y51Q', 'Y51R', 'Y51S',\n",
       "        'Y51T', 'Y51V', 'Y51W', 'V52A', 'V52C', 'V52D', 'V52E', 'V52F',\n",
       "        'V52G', 'V52I', 'V52L', 'V52M', 'V52N', 'V52P', 'V52S', 'V52T',\n",
       "        'V52Y', 'T53A', 'T53D', 'T53F', 'T53G', 'T53I', 'T53K', 'T53M',\n",
       "        'T53N', 'T53P', 'T53R', 'T53S', 'T53V', 'T53Y', 'P54A', 'P54D',\n",
       "        'P54F', 'P54H', 'P54I', 'P54L', 'P54N', 'P54Q', 'P54R', 'P54S',\n",
       "        'P54T', 'P54V', 'P54Y', 'V55A', 'V55D', 'V55E', 'V55F', 'V55G',\n",
       "        'V55I', 'V55K', 'V55L', 'V55M', 'V55P', 'V55Q', 'V55R', 'V55S',\n",
       "        'V55T', 'N56C', 'N56D', 'N56E', 'N56F', 'N56G', 'N56H', 'N56I',\n",
       "        'N56K', 'N56M', 'N56Q', 'N56R', 'N56S', 'N56T', 'N56V', 'N56Y'],\n",
       "       dtype='<U4')}"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data_jax[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "e86f0ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.sparse_tensor.SparseTensor at 0x111ad0dc0>"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data[\"train\"]['fold']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1d79f2",
   "metadata": {},
   "source": [
    "# Sparse Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "d6a29064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1. 0. 0. ... 0. 0. 0.], shape=(1057,), dtype=float32)\n",
      "(array([0., 1.], dtype=float32), array([1055,    2]))\n"
     ]
    }
   ],
   "source": [
    "sparse_tensor = model_data[\"train\"]['fold']\n",
    "\n",
    "# Convert the SparseTensor to a dense tensor\n",
    "dense_tensor = tf.sparse.to_dense(sparse_tensor)\n",
    "\n",
    "# Print the contents of the dense tensor\n",
    "print(dense_tensor[0])\n",
    "\n",
    "test1 = dense_tensor[0].numpy()\n",
    "\n",
    "print(np.unique(test1, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "5c54f19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88171, 50)\n"
     ]
    }
   ],
   "source": [
    "def dim_sparse(data):\n",
    "    dense_tensor = tf.sparse.to_dense(data)\n",
    "\n",
    "    # Convert the dense tensor to a Numpy array\n",
    "    dense_matrix = dense_tensor.numpy()\n",
    "\n",
    "    # Convert the dense matrix to a Scipy sparse matrix (CSR format)\n",
    "    sparse_matrix = csr_matrix(dense_matrix)\n",
    "\n",
    "    # Create and fit a TruncatedSVD instance\n",
    "    n_components = 50  # Adjust this value based on your desired level of compression\n",
    "    svd = TruncatedSVD(n_components=n_components)\n",
    "    reduced_data = svd.fit_transform(sparse_matrix)\n",
    "\n",
    "    return reduced_data\n",
    "\n",
    "\n",
    "reduced_data = dim_sparse(model_data['train']['bind'])\n",
    "# Check the shape of the reduced data\n",
    "print(reduced_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "9ea6c773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_sparse(model_data_jax['train']['bind'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "9a27ef1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]], shape=(88171, 757), dtype=float32)\n",
      "(array([0., 1.], dtype=float32), array([755,   2]))\n"
     ]
    }
   ],
   "source": [
    "sparse_tensor = model_data[\"train\"]['bind']\n",
    "\n",
    "# Convert the SparseTensor to a dense tensor\n",
    "dense_tensor = tf.sparse.to_dense(sparse_tensor)\n",
    "\n",
    "# Print the contents of the dense tensor\n",
    "print(dense_tensor)\n",
    "\n",
    "test1 = dense_tensor[0].numpy()\n",
    "\n",
    "print(np.unique(test1, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b60a7d",
   "metadata": {},
   "source": [
    "# Shuffle Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "670375c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_weights(model, weights=None):\n",
    "  \"\"\"Randomly permute the weights in `model`, or the given `weights`.\n",
    "\n",
    "  This is a fast approximation of re-initializing the weights of a model.\n",
    "\n",
    "  Assumes weights are distributed independently of the dimensions of the weight tensors\n",
    "    (i.e., the weights have the same distribution along each dimension).\n",
    "\n",
    "  :param Model model: Modify the weights of the given model.\n",
    "  :param list(ndarray) weights: The model's weights will be replaced by a random permutation of these weights.\n",
    "    If `None`, permute the model's current weights.\n",
    "  \"\"\"\n",
    "  if weights is None:\n",
    "    weights = model.get_weights()\n",
    "  weights = [np.random.permutation(w.flat).reshape(w.shape) for w in weights]\n",
    "  # Faster, but less random: only permutes along the first dimension\n",
    "  # weights = [np.random.permutation(w) for w in weights]\n",
    "  model.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ea5678d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _shuffle_array(rng, arr):\n",
    "    flat_arr = arr.ravel()\n",
    "    shuffled_flat_arr = jax.random.permutation(rng, flat_arr)\n",
    "    return jnp.reshape(shuffled_flat_arr, arr.shape)\n",
    "\n",
    "def shuffle_weights(rng, model, weights=None):\n",
    "\n",
    "    \"\"\"\n",
    "    Randomly permute the weights in `model`, or the given `weights`.\n",
    "\n",
    "    This is a fast approximation of re-initializing the weights of a model.\n",
    "\n",
    "    Assumes weights are distributed independently of the dimensions of the weight tensors\n",
    "    (i.e., the weights have the same distribution along each dimension).\n",
    "\n",
    "    :param Model model: Modify the weights of the given model.\n",
    "    :param list(ndarray) weights: The model's weights will be replaced by a random permutation of these weights.\n",
    "    If `None`, permute the model's current weights.\n",
    "    \"\"\"\n",
    "\n",
    "    if weights is None:\n",
    "        weights = model.params\n",
    "\n",
    "    rngs = jax.random.split(rng, len(weights))\n",
    "    shuffled_weights = tree_map(lambda r, w: _shuffle_array(r, w), rngs, weights)\n",
    "\n",
    "    # Assuming `model` has a method `replace` that replaces its parameters.\n",
    "    # Adjust this line if the model structure is different.\n",
    "    new_model = model.replace(params=shuffled_weights)\n",
    "    return new_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe19afb7",
   "metadata": {},
   "source": [
    "# Create Model Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c2eed70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(learn_rate, l1, l2, input_dim_select, input_dim_folding, input_dim_binding, number_additive_traits):\n",
    "  ### INPUT LAYER\n",
    "  ########################################\n",
    "  #Input layer select\n",
    "  input_layer_select = keras.layers.Input(\n",
    "    shape = input_dim_select,\n",
    "    name = \"input_select\")\n",
    "  #Split\n",
    "  input_layer_select_folding = keras.layers.Lambda(lambda x: tf.expand_dims(x[:,0],-1))(input_layer_select)\n",
    "  input_layer_select_binding = keras.layers.Lambda(lambda x: tf.expand_dims(x[:,1],-1))(input_layer_select)\n",
    "  #Input layer folding\n",
    "  input_layer_folding = keras.layers.Input(\n",
    "    shape = input_dim_folding,\n",
    "    name = \"input_fold\", sparse=True)\n",
    "  #Input layer binding\n",
    "  input_layer_binding = keras.layers.Input(\n",
    "    shape = input_dim_binding,\n",
    "    name = \"input_bind\", sparse=True)\n",
    "  ### FOLDING LAYERS\n",
    "  ########################################\n",
    "  #Folding additive trait layer\n",
    "  folding_additive_trait_layer = keras.layers.Dense(\n",
    "    number_additive_traits,\n",
    "    # input_dim = input_dim,\n",
    "    kernel_initializer = 'glorot_normal',\n",
    "    activation = \"linear\",\n",
    "    use_bias = False,\n",
    "    name = \"folding_additivetrait\")(input_layer_folding)\n",
    "    # kernel_regularizer = keras.regularizers.l1_l2(l1 = l1, l2 = l2))(input_layerB)\n",
    "  #Folding nonlinear layer\n",
    "  folding_nonlinear_layer = State_prob_folded(trainable=False)(folding_additive_trait_layer)\n",
    "  #Folding additive layer\n",
    "  folding_additive_layer = keras.layers.Dense(\n",
    "    1,\n",
    "    activation = \"linear\",\n",
    "    name = \"folding_additive\",\n",
    "    kernel_constraint=Between(0, 1e3)#, bias_constraint=Between(-1, 1)\n",
    "    )(folding_nonlinear_layer)\n",
    "  ### BINDING LAYERS\n",
    "  ########################################\n",
    "  #Binding additive trait layer\n",
    "  binding_additive_trait_layer = keras.layers.Dense(\n",
    "    number_additive_traits,\n",
    "    # input_dim = input_dim,\n",
    "    kernel_initializer = 'glorot_normal',\n",
    "    activation = \"linear\",\n",
    "    use_bias = False,\n",
    "    name = \"binding_additivetrait\",\n",
    "    kernel_regularizer = keras.regularizers.l1_l2(l1 = l1, l2 = l2))(input_layer_binding)\n",
    "  #Binding nonlinear layer\n",
    "  binding_nonlinear_layer = State_prob_bound(trainable=False)([binding_additive_trait_layer, folding_additive_trait_layer])\n",
    "  #Binding additive layer\n",
    "  binding_additive_layer = keras.layers.Dense(\n",
    "    1,\n",
    "    activation = \"linear\",\n",
    "    name = \"binding_additive\",\n",
    "    kernel_constraint=Between(0, 1e3)#, bias_constraint=Between(-1, 1)\n",
    "    )(binding_nonlinear_layer)\n",
    "  ### OUTPUT LAYERS\n",
    "  ########################################\n",
    "  #Multiplicative layer folding\n",
    "  multiplicative_layer_folding = keras.layers.Multiply()([folding_additive_layer, input_layer_select_folding])\n",
    "  #Multiplicative layer binding\n",
    "  multiplicative_layer_binding = keras.layers.Multiply()([binding_additive_layer, input_layer_select_binding])\n",
    "  #Sum layer\n",
    "  output_layer = keras.layers.Add()([multiplicative_layer_folding, multiplicative_layer_binding])\n",
    "  #Create keras model defining input and output layers\n",
    "  model = keras.Model(\n",
    "    inputs = [input_layer_select, input_layer_folding, input_layer_binding],\n",
    "    outputs = [output_layer])\n",
    "  # Compile model\n",
    "  opt = keras.optimizers.Adam(learning_rate = learn_rate)\n",
    "  #Compile the model\n",
    "  model.compile(\n",
    "    optimizer = opt,\n",
    "    loss = 'mean_absolute_error')\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644efcc6",
   "metadata": {},
   "source": [
    "# Grid Search Legacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1cfca08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_grid(param_dict, input_data, n_epochs):\n",
    "  #Clear session\n",
    "  keras.backend.clear_session()\n",
    "  #Summarize results\n",
    "  print(\"Grid search using %s\" % (param_dict))\n",
    "  #Set random seeds\n",
    "  random.seed(random_seed)\n",
    "  tf.random.set_seed(random_seed)\n",
    "  #Create model\n",
    "  model = create_model(\n",
    "    learn_rate = param_dict['learning_rate'],\n",
    "    l1=param_dict['l1_regularization_factor'],\n",
    "    l2=param_dict['l2_regularization_factor'],\n",
    "    input_dim_select = input_data['train']['select'].shape[1],\n",
    "    input_dim_folding = input_data['train']['fold'].shape[1],\n",
    "    input_dim_binding = input_data['train']['bind'].shape[1],\n",
    "    number_additive_traits = param_dict['number_additive_traits'])\n",
    "  #Validation data\n",
    "  validation_data = (\n",
    "    [input_data['valid']['select'], input_data['valid']['fold'], input_data['valid']['bind']],\n",
    "    input_data['valid']['target'])\n",
    "  #Fit the model\n",
    "  history = model.fit(\n",
    "    [input_data['train']['select'], input_data['train']['fold'], input_data['train']['bind']],\n",
    "    input_data['train']['target'],\n",
    "    validation_data = validation_data,\n",
    "    epochs = n_epochs,\n",
    "    batch_size = param_dict['num_samples'],\n",
    "    shuffle = True,\n",
    "    verbose = 0,\n",
    "    use_multiprocessing = True)\n",
    "  return(history.history[\"val_loss\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9f6cb8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "Grid search using {'num_samples': 128, 'learning_rate': 0.0001, 'l1_regularization_factor': 0.0001, 'l2_regularization_factor': 0.0001, 'number_additive_traits': 1}\n",
      "Grid search using {'num_samples': 128, 'learning_rate': 0.0001, 'l1_regularization_factor': 0.0001, 'l2_regularization_factor': 0.001, 'number_additive_traits': 1}\n",
      "Grid search using {'num_samples': 128, 'learning_rate': 0.0001, 'l1_regularization_factor': 0.0001, 'l2_regularization_factor': 0.01, 'number_additive_traits': 1}\n",
      "Best: 0.401939 using {'num_samples': 128, 'learning_rate': 0.0001, 'l1_regularization_factor': 0.0001, 'l2_regularization_factor': 0.0001, 'number_additive_traits': 1}\n"
     ]
    }
   ],
   "source": [
    "#######################################################################\n",
    "## TUNE LEARNING RATE, NUMBER OF SAMPLES AND REGULARISATION PARAMS ##\n",
    "#######################################################################\n",
    "\n",
    "if len(l1)==1 and len(l2)==1 and len(batch_size)==1 and len(learn_rate)==1:\n",
    "  #Only parameters\n",
    "  num_samples = batch_size[0]\n",
    "  learning_rate = learn_rate[0]\n",
    "  l1_regularization_factor = l1[0]\n",
    "  l2_regularization_factor = l2[0]\n",
    "else:\n",
    "  #All combinations of tunable parameters\n",
    "  parameter_grid = [{\n",
    "  \"num_samples\":i,\n",
    "  \"learning_rate\":j,\n",
    "  \"l1_regularization_factor\":k,\n",
    "  \"l2_regularization_factor\":l,\n",
    "  \"number_additive_traits\":1} for i in batch_size for j in learn_rate for k in l1 for l in l2]\n",
    "  #Perform grid search\n",
    "  grid_results = [fit_model_grid(i, model_data, num_epochs_grid) for i in parameter_grid[:3]]\n",
    "    \n",
    "  best_params = parameter_grid[[i for i in range(len(grid_results)) if grid_results[i]==min(grid_results)][0]]\n",
    "  #Summarize results\n",
    "  print(\"Best: %f using %s\" % (min(grid_results), best_params))\n",
    "  #Best parameters\n",
    "  num_samples = best_params['num_samples']\n",
    "  learning_rate = best_params['learning_rate']\n",
    "  l1_regularization_factor = best_params['l1_regularization_factor']\n",
    "  l2_regularization_factor = best_params['l2_regularization_factor']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b3f4c2",
   "metadata": {},
   "source": [
    "# Jax Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "5f103ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import constrained_gradients, StateProbBound, StateProbFolded, Between, between\n",
    "from linear import custom_linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4448cd27",
   "metadata": {},
   "source": [
    "# Create model Jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "f265256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "custom_linear_jit = jit(partial(custom_linear, output_size=int(number_additive_traits)))\n",
    "\n",
    "def create_model_fn(number_additive_traits, l1, l2,rng):\n",
    "    \"\"\"\n",
    "    This function returns a function that creates the model. The model is a\n",
    "    neural network that predicts the log fold change of a protein. The model\n",
    "    uses a combination of linear and nonlinear layers. The nonlinear layers\n",
    "    use additive traits, which are the outputs of the linear layers.\n",
    "    The outputs of the nonlinear layers are then used to create a multiplicative\n",
    "    layer that is used in the prediction.\n",
    "    \"\"\"\n",
    "    #def custom_linear_wrapper(inputs, num_traits, rng_key):\n",
    "        #return custom_linear_jit(inputs, int(num_traits), w_init=None, with_bias=False, rng_key=rng)\n",
    "    \n",
    "    def model_fn(inputs_select, inputs_folding, inputs_binding):\n",
    "        \"\"\"\n",
    "        This function creates the model. The model is a neural network that\n",
    "        predicts the log fold change of a protein. The model uses a combination\n",
    "        of linear and nonlinear layers. The nonlinear layers use additive traits,\n",
    "        which are the outputs of the linear layers. The outputs of the nonlinear\n",
    "        layers are then used to create a multiplicative layer that is used in\n",
    "        the prediction.\n",
    "        \"\"\"\n",
    "        input_layer_select_folding = jnp.expand_dims(inputs_select[:, 0], -1)\n",
    "        input_layer_select_binding = jnp.expand_dims(inputs_select[:, 1], -1)\n",
    "\n",
    "        #inputs_folding = inputs_folding.todense()\n",
    "        #inputs_binding = inputs_binding.todense()\n",
    "        \n",
    "        #folding\n",
    "        ################################# TESTING IN PROGRESS #########################################\n",
    "        #linear_sparse = jax.experimental.sparse.sparsify(jax.jit(hk.Linear, static_argnums=0))\n",
    "        #num = jnp.array(jax.lax.tie_in(inputs_folding, number_additive_traits),dtype=jnp.int32)\n",
    "        \n",
    "        #folding_additive_trait_layer = custom_linear_jit(inputs_folding,\n",
    "        #                                                 w_init=None,\n",
    "        #                                                 with_bias=False,\n",
    "        #                                                 rng_key=rng)\n",
    "        \n",
    "        #####################################################################################\n",
    "        inputs_folding = inputs_folding.todense()\n",
    "        inputs_binding = inputs_binding.todense()\n",
    "        folding_additive_trait_layer = hk.Linear(number_additive_traits, \n",
    "                                                 w_init=hk.initializers.VarianceScaling(1.0, \"fan_avg\", \"truncated_normal\"),\n",
    "                                                 with_bias=False\n",
    "                                                )(inputs_folding)\n",
    "        \n",
    "        folding_nonlinear_layer = StateProbFolded()(folding_additive_trait_layer)\n",
    "        \n",
    "        folding_additive_layer = hk.Linear(number_additive_traits,\n",
    "                                           w_init=hk.initializers.VarianceScaling(1.0, \"fan_avg\", \"truncated_normal\"),\n",
    "                                           with_bias=False#,\n",
    "                                           #kernel_regularizer=hk.regularizers.L1L2(l1=l1, l2=l2)\n",
    "                                          )(folding_nonlinear_layer)\n",
    "        \n",
    "        #binding\n",
    "        binding_additive_trait_layer = hk.Linear(number_additive_traits, \n",
    "                                                 w_init=hk.initializers.VarianceScaling(1.0, \"fan_avg\", \"truncated_normal\"), \n",
    "                                                 with_bias=False\n",
    "                                                )(inputs_binding)\n",
    "        \n",
    "        binding_nonlinear_layer = StateProbBound()(binding_additive_trait_layer, folding_additive_trait_layer)\n",
    "        \n",
    "        binding_additive_layer = hk.Linear(number_additive_traits,\n",
    "                                           w_init=hk.initializers.VarianceScaling(1.0, \"fan_avg\", \"truncated_normal\"),\n",
    "                                           with_bias=False\n",
    "                                          )(binding_nonlinear_layer)\n",
    "\n",
    "        #output\n",
    "        multiplicative_layer_folding = folding_additive_layer * input_layer_select_folding\n",
    "        multiplicative_layer_binding = binding_additive_layer * input_layer_select_binding\n",
    "        output_layer = multiplicative_layer_folding + multiplicative_layer_binding\n",
    "\n",
    "        return output_layer\n",
    "\n",
    "    return model_fn\n",
    "\n",
    "\n",
    "def create_model_jax(rng, learn_rate, l1, l2, input_dim_select, input_dim_folding, input_dim_binding, number_additive_traits):\n",
    "    # Create model\n",
    "    model_fn = create_model_fn(number_additive_traits, l1, l2,rng)\n",
    "    model = hk.without_apply_rng(hk.transform(model_fn))\n",
    "\n",
    "    # Create optimizer\n",
    "    opt = optax.chain(\n",
    "        optax.adam(learn_rate),\n",
    "        constrained_gradients(['folding_additive', 'binding_additive'], 0, 1e3),\n",
    "    )\n",
    "\n",
    "    # Create regularizer\n",
    "    #regularizer = hk.regularizers.L1L2(l1=l1, l2=l2)\n",
    "\n",
    "    return model, opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a9bdae",
   "metadata": {},
   "source": [
    "# Grid Search Jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "9c40e191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "757"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data['train']['bind'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "61153b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(input_data, batch_size, rng):\n",
    "    \"\"\"Generate batches for training.\n",
    "\n",
    "    Args:\n",
    "        input_data: A dictionary of NumPy arrays containing the input data.\n",
    "        batch_size: The batch size.\n",
    "        rng: A JAX PRNGKey.\n",
    "\n",
    "    Yields:\n",
    "        A tuple of (select, fold, bind, target) batches.\n",
    "    \"\"\"\n",
    "    num_samples = input_data['select'].shape[0]\n",
    "    indices = jnp.arange(num_samples)\n",
    "\n",
    "    # Shuffle the training data.\n",
    "    rng, _ = jax.random.split(rng)\n",
    "    indices = jax.random.permutation(rng, indices)\n",
    "\n",
    "    # Generate batches.\n",
    "    for start_idx in range(0, num_samples, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, num_samples)\n",
    "        batch_indices = indices[start_idx:end_idx]\n",
    "\n",
    "        batch_select = input_data['select'][batch_indices]\n",
    "        batch_fold = input_data['fold'][batch_indices]\n",
    "        batch_bind = input_data['bind'][batch_indices]\n",
    "        batch_target = input_data['target'][batch_indices]\n",
    "\n",
    "        yield batch_select, batch_fold, batch_bind, batch_target\n",
    "\n",
    "#Fit model for gridsearch\n",
    "def fit_model_grid_jax(param_dict, input_data, n_epochs, rng):\n",
    "\n",
    "    #Summarize results\n",
    "    print(\"Grid search using %s\" % (param_dict))\n",
    "\n",
    "    rng_init, rng_batches = jax.random.split(rng)\n",
    "\n",
    "    #Create model\n",
    "    model, optimizer = create_model_jax(\n",
    "        rng = rng_init,\n",
    "        learn_rate = param_dict['learning_rate'],\n",
    "        l1=param_dict['l1_regularization_factor'],\n",
    "        l2=param_dict['l2_regularization_factor'],\n",
    "        input_dim_select = input_data['train']['select'].shape[1],\n",
    "        input_dim_folding = input_data['train']['fold'].shape[1],\n",
    "        input_dim_binding = input_data['train']['bind'].shape[1],\n",
    "        number_additive_traits = param_dict['number_additive_traits'])\n",
    "\n",
    "    @jax.jit\n",
    "    def loss_fn(params, inputs_select, inputs_folding, inputs_binding, target):\n",
    "        output = model.apply(params, inputs_select, inputs_folding, inputs_binding)\n",
    "        loss = jnp.mean(jnp.abs(output - target))\n",
    "        \n",
    "        # Apply L1 and L2 regularization\n",
    "        l1_loss = 0\n",
    "        l2_loss = 0\n",
    "        for p in jax.tree_util.tree_leaves(params):\n",
    "            if p.ndim > 1:  # exclude bias parameters\n",
    "                l1_loss += jnp.sum(jnp.abs(p))\n",
    "                l2_loss += jnp.sum(jnp.square(p))\n",
    "        loss = loss + param_dict['l1_regularization_factor'] * l1_loss + param_dict['l2_regularization_factor'] * l2_loss\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    @jax.jit\n",
    "    def update(params, opt_state, inputs_select, inputs_folding, inputs_binding, target):\n",
    "        grads = jax.grad(loss_fn)(params, inputs_select, inputs_folding, inputs_binding, target)\n",
    "        updates, new_opt_state = optimizer.update(grads, opt_state)\n",
    "        #print('update done')\n",
    "        new_params = optax.apply_updates(params, updates)\n",
    "        return new_params, new_opt_state\n",
    "\n",
    "    params = model.init(rng, input_data['train']['select'], input_data['train']['fold'], input_data['train']['bind'])\n",
    "    opt_state = optimizer.init(params)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_data in generate_batches(input_data['train'], param_dict['num_samples'], rng_batches):\n",
    "            inputs_select, inputs_folding, inputs_binding, target = batch_data\n",
    "            print(type(inputs_select))\n",
    "            params, opt_state = update(params, opt_state, inputs_select, inputs_folding, inputs_binding, target)\n",
    "            print('batch_done')\n",
    "            \n",
    "        val_loss = loss_fn(params, input_data['valid']['select'], input_data['valid']['fold'], input_data['valid']['bind'], input_data['valid']['target'])\n",
    "    return val_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "188d3f40",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search using {'num_samples': 128, 'learning_rate': 0.0001, 'l1_regularization_factor': 0.0001, 'l2_regularization_factor': 0.0001, 'number_additive_traits': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierredemetz/miniconda3/envs/pierre/lib/python3.8/site-packages/haiku/_src/data_structures.py:143: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.\n",
      "  leaves, treedef = jax.tree_flatten(tree)\n",
      "/Users/pierredemetz/miniconda3/envs/pierre/lib/python3.8/site-packages/haiku/_src/data_structures.py:144: FutureWarning: jax.tree_unflatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_unflatten instead.\n",
      "  return jax.tree_unflatten(treedef, leaves)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'jaxlib.xla_extension.DeviceArray'>\n",
      "batch_done\n",
      "<class 'jaxlib.xla_extension.DeviceArray'>\n",
      "batch_done\n",
      "<class 'jaxlib.xla_extension.DeviceArray'>\n",
      "batch_done\n",
      "<class 'jaxlib.xla_extension.DeviceArray'>\n",
      "batch_done\n",
      "<class 'jaxlib.xla_extension.DeviceArray'>\n",
      "batch_done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[348], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m rngs \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(rng, \u001b[38;5;28mlen\u001b[39m(parameter_grid))\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#print(len(parameter_grid))\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m grid_results \u001b[38;5;241m=\u001b[39m [fit_model_grid_jax(params, model_data_jax, num_epochs_grid, rng_key) \u001b[38;5;28;01mfor\u001b[39;00m params, rng_key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(parameter_grid, rngs)]\n\u001b[1;32m     24\u001b[0m best_params \u001b[38;5;241m=\u001b[39m parameter_grid[np\u001b[38;5;241m.\u001b[39margmin(grid_results)]\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m using \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mmin\u001b[39m(grid_results), best_params))\n",
      "Cell \u001b[0;32mIn[348], line 22\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     20\u001b[0m rngs \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(rng, \u001b[38;5;28mlen\u001b[39m(parameter_grid))\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#print(len(parameter_grid))\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m grid_results \u001b[38;5;241m=\u001b[39m [\u001b[43mfit_model_grid_jax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_data_jax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng_key\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m params, rng_key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(parameter_grid, rngs)]\n\u001b[1;32m     24\u001b[0m best_params \u001b[38;5;241m=\u001b[39m parameter_grid[np\u001b[38;5;241m.\u001b[39margmin(grid_results)]\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m using \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mmin\u001b[39m(grid_results), best_params))\n",
      "Cell \u001b[0;32mIn[341], line 78\u001b[0m, in \u001b[0;36mfit_model_grid_jax\u001b[0;34m(param_dict, input_data, n_epochs, rng)\u001b[0m\n\u001b[1;32m     75\u001b[0m opt_state \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39minit(params)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_data \u001b[38;5;129;01min\u001b[39;00m generate_batches(input_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m], param_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_samples\u001b[39m\u001b[38;5;124m'\u001b[39m], rng_batches):\n\u001b[1;32m     79\u001b[0m         inputs_select, inputs_folding, inputs_binding, target \u001b[38;5;241m=\u001b[39m batch_data\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(inputs_select))\n",
      "Cell \u001b[0;32mIn[341], line 25\u001b[0m, in \u001b[0;36mgenerate_batches\u001b[0;34m(input_data, batch_size, rng)\u001b[0m\n\u001b[1;32m     22\u001b[0m batch_indices \u001b[38;5;241m=\u001b[39m indices[start_idx:end_idx]\n\u001b[1;32m     24\u001b[0m batch_select \u001b[38;5;241m=\u001b[39m input_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselect\u001b[39m\u001b[38;5;124m'\u001b[39m][batch_indices]\n\u001b[0;32m---> 25\u001b[0m batch_fold \u001b[38;5;241m=\u001b[39m \u001b[43minput_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfold\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_indices\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     26\u001b[0m batch_bind \u001b[38;5;241m=\u001b[39m input_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbind\u001b[39m\u001b[38;5;124m'\u001b[39m][batch_indices]\n\u001b[1;32m     27\u001b[0m batch_target \u001b[38;5;241m=\u001b[39m input_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m][batch_indices]\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/experimental/sparse/transform.py:763\u001b[0m, in \u001b[0;36m_sparse_rewriting_take\u001b[0;34m(arr, idx, indices_are_sorted, unique_indices, mode, fill_value)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sparse_rewriting_take\u001b[39m(arr, idx, indices_are_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, unique_indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    761\u001b[0m                            mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    762\u001b[0m   \u001b[38;5;66;03m# Only sparsify the array argument; sparse indices not yet supported\u001b[39;00m\n\u001b[0;32m--> 763\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43msparsify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunctools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    764\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlax_numpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rewriting_take\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_are_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices_are_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munique_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munique_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m   \u001b[38;5;66;03m# Account for a corner case in the rewriting_take implementation.\u001b[39;00m\n\u001b[1;32m    767\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, BCOO) \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39msize(result) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/experimental/sparse/transform.py:425\u001b[0m, in \u001b[0;36m_sparsify_with_interpreter.<locals>.wrapped\u001b[0;34m(*args, **params)\u001b[0m\n\u001b[1;32m    423\u001b[0m spenv \u001b[38;5;241m=\u001b[39m SparsifyEnv()\n\u001b[1;32m    424\u001b[0m spvalues \u001b[38;5;241m=\u001b[39m arrays_to_spvalues(spenv, args)\n\u001b[0;32m--> 425\u001b[0m spvalues_out, out_tree \u001b[38;5;241m=\u001b[39m \u001b[43mf_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspenv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mspvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m out \u001b[38;5;241m=\u001b[39m spvalues_to_arrays(spenv, spvalues_out)\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(out_tree, out)\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/experimental/sparse/transform.py:411\u001b[0m, in \u001b[0;36msparsify_raw.<locals>.wrapped\u001b[0;34m(spenv, *spvalues, **params)\u001b[0m\n\u001b[1;32m    409\u001b[0m wrapped_fun, out_tree \u001b[38;5;241m=\u001b[39m flatten_fun_nokwargs(lu\u001b[38;5;241m.\u001b[39mwrap_init(f, params), in_tree)\n\u001b[1;32m    410\u001b[0m jaxpr, out_avals_flat, consts \u001b[38;5;241m=\u001b[39m pe\u001b[38;5;241m.\u001b[39mtrace_to_jaxpr_dynamic(wrapped_fun, in_avals_flat)\n\u001b[0;32m--> 411\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43meval_sparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspvalues_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspenv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out_avals_flat) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(result):\n\u001b[1;32m    413\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInternal: eval_sparse does not return expected number of arguments. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    414\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot \u001b[39m\u001b[38;5;132;01m{result}\u001b[39;00m\u001b[38;5;124m for avals \u001b[39m\u001b[38;5;132;01m{out_avals_flat}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/experimental/sparse/transform.py:384\u001b[0m, in \u001b[0;36meval_sparse\u001b[0;34m(jaxpr, consts, spvalues, spenv)\u001b[0m\n\u001b[1;32m    382\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m prim \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m sparse_rules:\n\u001b[1;32m    383\u001b[0m     _raise_unimplemented_primitive(prim)\n\u001b[0;32m--> 384\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43msparse_rules\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprim\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspenv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meqn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    386\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m prim \u001b[38;5;129;01mis\u001b[39;00m xla\u001b[38;5;241m.\u001b[39mxla_call_p:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;66;03m# TODO(vanderplas,frostig): workaround for binding call primitives\u001b[39;00m\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;66;03m# within a jaxpr interpreter\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/experimental/sparse/transform.py:623\u001b[0m, in \u001b[0;36m_gather_sparse_rule\u001b[0;34m(spenv, dimension_numbers, slice_sizes, unique_indices, indices_are_sorted, mode, fill_value, *args)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gather_sparse_rule\u001b[39m(spenv, \u001b[38;5;241m*\u001b[39margs, dimension_numbers, slice_sizes, unique_indices,\n\u001b[1;32m    621\u001b[0m                         indices_are_sorted, mode, fill_value):\n\u001b[1;32m    622\u001b[0m   operand, start_indices \u001b[38;5;241m=\u001b[39m spvalues_to_arrays(spenv, args)\n\u001b[0;32m--> 623\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbcoo_gather\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdimension_numbers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdimension_numbers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mslice_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslice_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munique_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munique_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mindices_are_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices_are_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    627\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_spvalues(spenv, (result,))\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/experimental/sparse/bcoo.py:2290\u001b[0m, in \u001b[0;36mbcoo_gather\u001b[0;34m(operand, start_indices, dimension_numbers, slice_sizes, unique_indices, indices_are_sorted, mode, fill_value)\u001b[0m\n\u001b[1;32m   2288\u001b[0m   slc \u001b[38;5;241m=\u001b[39m bcoo_dynamic_slice(operand, indices, slice_sizes\u001b[38;5;241m=\u001b[39mfull_slice_sizes)\n\u001b[1;32m   2289\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m bcoo_squeeze(slc, dimensions\u001b[38;5;241m=\u001b[39mcollapsed_slice_dims)\n\u001b[0;32m-> 2290\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslice_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43min_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_start_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2291\u001b[0m result \u001b[38;5;241m=\u001b[39m bcoo_reshape(result,\n\u001b[1;32m   2292\u001b[0m   new_sizes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m*\u001b[39mstart_indices\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m*\u001b[39mresult\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:]),\n\u001b[1;32m   2293\u001b[0m   dimensions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mrange\u001b[39m(result\u001b[38;5;241m.\u001b[39mndim)))\n\u001b[1;32m   2295\u001b[0m \u001b[38;5;66;03m# Use offset_dims to permute result dimensions\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/_src/api.py:1682\u001b[0m, in \u001b[0;36mvmap.<locals>.vmap_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1679\u001b[0m in_axes_flat \u001b[38;5;241m=\u001b[39m flatten_axes(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvmap in_axes\u001b[39m\u001b[38;5;124m\"\u001b[39m, in_tree, (in_axes, \u001b[38;5;241m0\u001b[39m), kws\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1680\u001b[0m axis_size_ \u001b[38;5;241m=\u001b[39m (axis_size \u001b[38;5;28;01mif\u001b[39;00m axis_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[1;32m   1681\u001b[0m               _mapped_axis_size(fun, in_tree, args_flat, in_axes_flat, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvmap\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 1682\u001b[0m out_flat \u001b[38;5;241m=\u001b[39m \u001b[43mbatching\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_size_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_axes_flat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1684\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mflatten_axes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvmap out_axes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_axes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspmd_axis_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspmd_axis_name\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_flat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1687\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(out_tree(), out_flat)\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/linear_util.py:167\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m gen \u001b[38;5;241m=\u001b[39m gen_static_args \u001b[38;5;241m=\u001b[39m out_store \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m   \u001b[38;5;66;03m# Some transformations yield from inside context managers, so we have to\u001b[39;00m\n\u001b[1;32m    170\u001b[0m   \u001b[38;5;66;03m# interrupt them before reraising the exception. Otherwise they will only\u001b[39;00m\n\u001b[1;32m    171\u001b[0m   \u001b[38;5;66;03m# get garbage-collected at some later time, running their cleanup tasks\u001b[39;00m\n\u001b[1;32m    172\u001b[0m   \u001b[38;5;66;03m# only after this exception is handled, which can corrupt the global\u001b[39;00m\n\u001b[1;32m    173\u001b[0m   \u001b[38;5;66;03m# state.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m   \u001b[38;5;28;01mwhile\u001b[39;00m stack:\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/experimental/sparse/bcoo.py:2288\u001b[0m, in \u001b[0;36mbcoo_gather.<locals>.slice_func\u001b[0;34m(indices)\u001b[0m\n\u001b[1;32m   2287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mslice_func\u001b[39m(indices):\n\u001b[0;32m-> 2288\u001b[0m   slc \u001b[38;5;241m=\u001b[39m \u001b[43mbcoo_dynamic_slice\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_slice_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2289\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m bcoo_squeeze(slc, dimensions\u001b[38;5;241m=\u001b[39mcollapsed_slice_dims)\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/experimental/sparse/bcoo.py:2063\u001b[0m, in \u001b[0;36mbcoo_dynamic_slice\u001b[0;34m(mat, start_indices, slice_sizes)\u001b[0m\n\u001b[1;32m   2061\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m mat\u001b[38;5;241m.\u001b[39mnse \u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mprod(size_sparse):\n\u001b[1;32m   2062\u001b[0m     new_nse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mprod(size_sparse)\n\u001b[0;32m-> 2063\u001b[0m     new_data, new_indices \u001b[38;5;241m=\u001b[39m \u001b[43m_bcoo_sum_duplicates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2064\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnew_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspinfo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBCOOInfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_shape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_nse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2066\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m BCOO((new_data, new_indices), shape\u001b[38;5;241m=\u001b[39mnew_shape)\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/experimental/sparse/bcoo.py:1436\u001b[0m, in \u001b[0;36m_bcoo_sum_duplicates\u001b[0;34m(data, indices, spinfo, nse)\u001b[0m\n\u001b[1;32m   1434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1435\u001b[0m   nse \u001b[38;5;241m=\u001b[39m core\u001b[38;5;241m.\u001b[39mconcrete_or_error(operator\u001b[38;5;241m.\u001b[39mindex, nse, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnse argument of bcoo_sum_duplicates.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1436\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbcoo_sum_duplicates_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspinfo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/core.py:329\u001b[0m, in \u001b[0;36mPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[1;32m    327\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_enable_checks \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    328\u001b[0m           \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(arg, Tracer) \u001b[38;5;129;01mor\u001b[39;00m valid_jaxtype(arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)), args\n\u001b[0;32m--> 329\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfind_top_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/core.py:332\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[0;32m--> 332\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_raise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(full_lower, out) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultiple_results \u001b[38;5;28;01melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/interpreters/batching.py:356\u001b[0m, in \u001b[0;36mBatchTrace.process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    354\u001b[0m   frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_frame(vals_in, dims_in)\n\u001b[1;32m    355\u001b[0m   batched_primitive \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_primitive_batcher(primitive, frame)\n\u001b[0;32m--> 356\u001b[0m   val_out, dim_out \u001b[38;5;241m=\u001b[39m \u001b[43mbatched_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdims_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m src \u001b[38;5;241m=\u001b[39m source_info_util\u001b[38;5;241m.\u001b[39mcurrent()\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m primitive\u001b[38;5;241m.\u001b[39mmultiple_results:\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/experimental/sparse/bcoo.py:1510\u001b[0m, in \u001b[0;36m_bcoo_sum_duplicates_batching_rule\u001b[0;34m(batched_args, batch_dims, spinfo, nse)\u001b[0m\n\u001b[1;32m   1508\u001b[0m   indices \u001b[38;5;241m=\u001b[39m indices[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n\u001b[1;32m   1509\u001b[0m new_spinfo \u001b[38;5;241m=\u001b[39m BCOOInfo(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mmax\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], indices\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;241m*\u001b[39mspinfo\u001b[38;5;241m.\u001b[39mshape))\n\u001b[0;32m-> 1510\u001b[0m data_out, indices_out \u001b[38;5;241m=\u001b[39m \u001b[43mbcoo_sum_duplicates_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspinfo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_spinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m out_axes \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   1512\u001b[0m \u001b[38;5;66;03m# Note: if data is unbatched on input, it will be batched on output.\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m \u001b[38;5;66;03m# However, if indices are unbatched on input, they will be unbatched on output.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/core.py:329\u001b[0m, in \u001b[0;36mPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[1;32m    327\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_enable_checks \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    328\u001b[0m           \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(arg, Tracer) \u001b[38;5;129;01mor\u001b[39;00m valid_jaxtype(arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)), args\n\u001b[0;32m--> 329\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfind_top_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/core.py:332\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[0;32m--> 332\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_raise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(full_lower, out) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultiple_results \u001b[38;5;28;01melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/core.py:712\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_primitive\u001b[39m(\u001b[38;5;28mself\u001b[39m, primitive, tracers, params):\n\u001b[0;32m--> 712\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprimitive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtracers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/experimental/sparse/bcoo.py:1444\u001b[0m, in \u001b[0;36m_bcoo_sum_duplicates_impl\u001b[0;34m(data, indices, spinfo, nse)\u001b[0m\n\u001b[1;32m   1442\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(props\u001b[38;5;241m.\u001b[39mn_batch):\n\u001b[1;32m   1443\u001b[0m   f \u001b[38;5;241m=\u001b[39m vmap(f)\n\u001b[0;32m-> 1444\u001b[0m indices_out, mapping, nse_batched \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1446\u001b[0m   nse \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m props\u001b[38;5;241m.\u001b[39mn_sparse \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m nse_batched\u001b[38;5;241m.\u001b[39mmax()\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/_src/api.py:1682\u001b[0m, in \u001b[0;36mvmap.<locals>.vmap_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1679\u001b[0m in_axes_flat \u001b[38;5;241m=\u001b[39m flatten_axes(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvmap in_axes\u001b[39m\u001b[38;5;124m\"\u001b[39m, in_tree, (in_axes, \u001b[38;5;241m0\u001b[39m), kws\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1680\u001b[0m axis_size_ \u001b[38;5;241m=\u001b[39m (axis_size \u001b[38;5;28;01mif\u001b[39;00m axis_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[1;32m   1681\u001b[0m               _mapped_axis_size(fun, in_tree, args_flat, in_axes_flat, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvmap\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 1682\u001b[0m out_flat \u001b[38;5;241m=\u001b[39m \u001b[43mbatching\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_size_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_axes_flat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1684\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mflatten_axes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvmap out_axes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_axes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspmd_axis_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspmd_axis_name\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_flat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1687\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(out_tree(), out_flat)\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/linear_util.py:167\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m gen \u001b[38;5;241m=\u001b[39m gen_static_args \u001b[38;5;241m=\u001b[39m out_store \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m   \u001b[38;5;66;03m# Some transformations yield from inside context managers, so we have to\u001b[39;00m\n\u001b[1;32m    170\u001b[0m   \u001b[38;5;66;03m# interrupt them before reraising the exception. Otherwise they will only\u001b[39;00m\n\u001b[1;32m    171\u001b[0m   \u001b[38;5;66;03m# get garbage-collected at some later time, running their cleanup tasks\u001b[39;00m\n\u001b[1;32m    172\u001b[0m   \u001b[38;5;66;03m# only after this exception is handled, which can corrupt the global\u001b[39;00m\n\u001b[1;32m    173\u001b[0m   \u001b[38;5;66;03m# state.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m   \u001b[38;5;28;01mwhile\u001b[39;00m stack:\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/experimental/sparse/bcoo.py:1482\u001b[0m, in \u001b[0;36m_bcoo_sum_duplicates_unbatched\u001b[0;34m(indices, shape)\u001b[0m\n\u001b[1;32m   1480\u001b[0m indices \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mwhere(out_of_bounds, fill_value, indices)\n\u001b[1;32m   1481\u001b[0m \u001b[38;5;66;03m# TODO: check if `indices_sorted` is True.\u001b[39;00m\n\u001b[0;32m-> 1482\u001b[0m indices_unique, inv_idx, nse \u001b[38;5;241m=\u001b[39m \u001b[43m_unique\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m  \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_true_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m  \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1485\u001b[0m nse \u001b[38;5;241m=\u001b[39m nse \u001b[38;5;241m-\u001b[39m (indices \u001b[38;5;241m==\u001b[39m fill_value)\u001b[38;5;241m.\u001b[39many()\u001b[38;5;241m.\u001b[39mastype(nse\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m indices_unique, inv_idx, nse\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/_src/numpy/setops.py:260\u001b[0m, in \u001b[0;36m_unique\u001b[0;34m(ar, axis, return_index, return_inverse, return_counts, size, fill_value, return_true_size)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ar\u001b[38;5;241m.\u001b[39mshape[axis] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m size \u001b[38;5;129;01mand\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjnp.unique: for zero-sized input with nonzero size argument, fill_value must be specified\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 260\u001b[0m aux, mask, perm \u001b[38;5;241m=\u001b[39m \u001b[43m_unique_sorted_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    262\u001b[0m   ind \u001b[38;5;241m=\u001b[39m core\u001b[38;5;241m.\u001b[39mconcrete_or_error(\u001b[38;5;28;01mNone\u001b[39;00m, mask,\n\u001b[1;32m    263\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe error arose in jnp.unique(). \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m UNIQUE_SIZE_HINT)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/_src/api.py:626\u001b[0m, in \u001b[0;36m_cpp_jit.<locals>.cache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    623\u001b[0m   out_flat \u001b[38;5;241m=\u001b[39m call_bind_continuation(execute(\u001b[38;5;241m*\u001b[39margs_flat))\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    625\u001b[0m   out_flat \u001b[38;5;241m=\u001b[39m call_bind_continuation(\n\u001b[0;32m--> 626\u001b[0m       \u001b[43mtop_trace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprimitive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    627\u001b[0m out_pytree_def \u001b[38;5;241m=\u001b[39m out_tree()\n\u001b[1;32m    628\u001b[0m out \u001b[38;5;241m=\u001b[39m tree_unflatten(out_pytree_def, out_flat)\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/interpreters/batching.py:377\u001b[0m, in \u001b[0;36mBatchTrace.process_call\u001b[0;34m(self, call_primitive, f, tracers, params)\u001b[0m\n\u001b[1;32m    374\u001b[0m f_, dims_out \u001b[38;5;241m=\u001b[39m batch_subtrace(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmain, \u001b[38;5;28mtuple\u001b[39m(dims))\n\u001b[1;32m    375\u001b[0m f_ \u001b[38;5;241m=\u001b[39m _update_annotation(f_, f\u001b[38;5;241m.\u001b[39min_type, axis_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis_name, dims,\n\u001b[1;32m    376\u001b[0m                         segment_lens)\n\u001b[0;32m--> 377\u001b[0m vals_out \u001b[38;5;241m=\u001b[39m \u001b[43mcall_primitive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msegment_lens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m vals_out, dims_out \u001b[38;5;241m=\u001b[39m reassemble_concat_axes(vals_out, dims_out())\n\u001b[1;32m    379\u001b[0m src \u001b[38;5;241m=\u001b[39m source_info_util\u001b[38;5;241m.\u001b[39mcurrent()\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/core.py:2019\u001b[0m, in \u001b[0;36mCallPrimitive.bind\u001b[0;34m(self, fun, *args, **params)\u001b[0m\n\u001b[1;32m   2016\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, fun, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[1;32m   2017\u001b[0m   call_bind_continuation, top_trace, fun_, tracers, params \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2018\u001b[0m       call_bind_with_continuation(\u001b[38;5;28mself\u001b[39m, fun, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams))\n\u001b[0;32m-> 2019\u001b[0m   outs \u001b[38;5;241m=\u001b[39m \u001b[43mtop_trace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2020\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m call_bind_continuation(outs)\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/core.py:715\u001b[0m, in \u001b[0;36mEvalTrace.process_call\u001b[0;34m(self, primitive, f, tracers, params)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, primitive, f, tracers, params):\n\u001b[0;32m--> 715\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprimitive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtracers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/_src/dispatch.py:254\u001b[0m, in \u001b[0;36m_xla_call_impl\u001b[0;34m(fun, device, backend, name, donated_invars, inline, keep_unused, *args)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# TODO(parkers): Maybe apply this more generally in the case of the c++\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# fallback.\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 254\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompiled_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFloatingPointError\u001b[39;00m:\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_nans \u001b[38;5;129;01mor\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_infs  \u001b[38;5;66;03m# compiled_fun can only raise in this case\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pierre/lib/python3.8/site-packages/jax/_src/dispatch.py:895\u001b[0m, in \u001b[0;36m_execute_compiled\u001b[0;34m(name, compiled, input_handler, output_buffer_counts, result_handler, has_unordered_effects, ordered_effects, kept_var_idx, has_host_callbacks, *args)\u001b[0m\n\u001b[1;32m    893\u001b[0m     runtime_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 895\u001b[0m   out_flat \u001b[38;5;241m=\u001b[39m \u001b[43mcompiled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_flat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m check_special(name, out_flat)\n\u001b[1;32m    897\u001b[0m out_bufs \u001b[38;5;241m=\u001b[39m unflatten(out_flat, output_buffer_counts)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Fit model\n",
    "if len(l1) == 1 and len(l2) == 1 and len(batch_size) == 1 and len(learn_rate) == 1:\n",
    "    best_params = {\n",
    "        \"num_samples\": batch_size[0],\n",
    "        \"learning_rate\": learn_rate[0],\n",
    "        \"l1_regularization_factor\": l1[0],\n",
    "        \"l2_regularization_factor\": l2[0],\n",
    "        \"number_additive_traits\": 1\n",
    "    }\n",
    "else:\n",
    "    parameter_grid = [{\n",
    "        \"num_samples\": i,\n",
    "        \"learning_rate\": j,\n",
    "        \"l1_regularization_factor\": k,\n",
    "        \"l2_regularization_factor\": l,\n",
    "        \"number_additive_traits\": 1\n",
    "    } for i in batch_size for j in learn_rate for k in l1 for l in l2]\n",
    "\n",
    "    rng = jax.random.PRNGKey(random_seed)\n",
    "    rngs = jax.random.split(rng, len(parameter_grid))\n",
    "    #print(len(parameter_grid))\n",
    "    grid_results = [fit_model_grid_jax(params, model_data_jax, num_epochs_grid, rng_key) for params, rng_key in zip(parameter_grid, rngs)]\n",
    "\n",
    "    best_params = parameter_grid[np.argmin(grid_results)]\n",
    "\n",
    "    print(\"Best: %f using %s\" % (min(grid_results), best_params))\n",
    "\n",
    "num_samples = best_params['num_samples']\n",
    "learning_rate = best_params['learning_rate']\n",
    "l1_regularization_factor = best_params['l1_regularization_factor']\n",
    "l2_regularization_factor = best_params['l2_regularization_factor']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2333007",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
